{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI9kYUe28TXm",
        "outputId": "79b8f58f-2dc4-452d-c347-49953496b438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji (from stanza)\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.22.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234911 sha256=c7cc097b22b224106554e359f67d73bdcc9dd26256f4c0d7d9e9c3acb9c3396e\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/3d/88/51a592b9ad17e7899126563698b4e3961983ebe85747228ba6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.2.0 stanza-1.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"
          ]
        }
      ],
      "source": [
        "!pip install stanza\n",
        "!pip install transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "602531fb53ec4904a559f93c968848a3",
            "989e7c16f9834aa2ad6e602d2b068799",
            "fbf96632060c4e8a83945556b9649051",
            "ea28a235f4fe4b32afbc044d7b699c68",
            "1ab7949216f94ec19b9b709ad9905ecb",
            "38f6afb609f348ee8388cd1c6203284b",
            "9e02dd9ed90847c58d486732a1061a81",
            "c2acfc7550f448ce886089ba3c10875c",
            "1207be12c24846e0911e39bd70f67d56",
            "7c25c66eac8e48c897d72e2b736f969d",
            "ccd0b3d913d648bf9f03cb1d1139ca4e",
            "6b25204023a542a2890fd3a21dc29b89",
            "065f0aa230124936a200540fb3db9dd0",
            "785a37bfe75e4027b0fc7c5c926c9014",
            "5202fef1902e4d6b8fe827dad5063700",
            "49f3f24e68b44f08b7ab42a557ca981d",
            "b794350fab52426dbf237c34f3c73c35",
            "a4355184cd314916a38032d317bfe747",
            "f74f9f96ee3346d8931bad9619e41cb2",
            "d00c5b8cbacc4d6dabc21179470a2092",
            "18b5952091a84edab95e3245a9c9fd7c",
            "634d3f9b2a1d44b78eb51de637b1010d"
          ]
        },
        "id": "Iv5WC5Es8XGv",
        "outputId": "8f90b649-6119-4004-e25b-6e3c311c0061"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "602531fb53ec4904a559f93c968848a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Downloading default packages for language: tr (Turkish) ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b25204023a542a2890fd3a21dc29b89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-tr/resolve/v1.5.0/models/default.zip:   0%|          | 0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ],
      "source": [
        "import stanza\n",
        "stanza.download(\"en\")\n",
        "stanza.download(\"es\")\n",
        "stanza.download(\"tr\")\n",
        "\n",
        "!git clone https://github.com/UniversalDependencies/UD_English-EWT.git\n",
        "!git clone https://github.com/UniversalDependencies/UD_Spanish-GSD.git\n",
        "!git clone https://github.com/UniversalDependencies/UD_Turkish-BOUN.git\n",
        "\n",
        "%env UDBASE=./  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### English"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id1rA4oGMz43",
        "outputId": "8b22b3c4-1d44-4810-c0ba-a854a063d348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-13 20:12:38 INFO: Datasets program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/datasets/prepare_depparse_treebank.py UD_English-EWT\n",
            "2023-05-13 20:12:38 DEBUG: Downloading resource file...\n",
            "\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0% 0.00/30.0k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 69.0MB/s]        \n",
            "2023-05-13 20:12:38 DEBUG: Processing parameter \"processors\"...\n",
            "2023-05-13 20:12:38 DEBUG: Found pos: ewt.\n",
            "2023-05-13 20:12:38 DEBUG: Find dependency backward_charlm: 1billion.\n",
            "2023-05-13 20:12:38 DEBUG: Find dependency pretrain: ewt.\n",
            "2023-05-13 20:12:38 DEBUG: Find dependency forward_charlm: 1billion.\n",
            "2023-05-13 20:12:38 INFO: Downloading these customized packages for language: en (English)...\n",
            "==============================\n",
            "| Processor       | Package  |\n",
            "------------------------------\n",
            "| pos             | ewt      |\n",
            "| backward_charlm | 1billion |\n",
            "| pretrain        | ewt      |\n",
            "| forward_charlm  | 1billion |\n",
            "==============================\n",
            "\n",
            "2023-05-13 20:12:38 INFO: File exists: /root/stanza_resources/en/pos/ewt.pt\n",
            "2023-05-13 20:12:38 INFO: File exists: /root/stanza_resources/en/backward_charlm/1billion.pt\n",
            "2023-05-13 20:12:38 INFO: File exists: /root/stanza_resources/en/pretrain/ewt.pt\n",
            "2023-05-13 20:12:38 INFO: File exists: /root/stanza_resources/en/forward_charlm/1billion.pt\n",
            "2023-05-13 20:12:38 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2023-05-13 20:12:38 INFO: Using default pretrain for en:ewt, found in /root/stanza_resources/en/pretrain/ewt.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-13 20:12:38 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n",
            "2023-05-13 20:12:38 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n",
            "Preparing data for UD_English-EWT: en_ewt, en\n",
            "Reading from ./UD_English-EWT/en_ewt-ud-train.conllu and writing to /tmp/tmpp0im_68g/en_ewt.train.gold.conllu\n",
            "Augmented 66 quotes: Counter({'″″': 10, '““': 10, '《》': 8, '«»': 7, '「」': 6, '„”': 6, '\"\"': 6, '„“': 5, '””': 5, '»«': 3})\n",
            "Swapped 'w1, w2' for 'w1 ,w2' 74 times\n",
            "Added 109 new sentences with asdf, zzzz -> asdf,zzzz\n",
            "Reading from ./UD_English-EWT/en_ewt-ud-dev.conllu and writing to /tmp/tmpp0im_68g/en_ewt.dev.gold.conllu\n",
            "Reading from ./UD_English-EWT/en_ewt-ud-test.conllu and writing to /tmp/tmpp0im_68g/en_ewt.test.gold.conllu\n",
            "2023-05-13 20:12:40 INFO: Running tagger to retag /tmp/tmpp0im_68g/en_ewt.train.gold.conllu to data/depparse/en_ewt.train.in.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'en', '--shorthand', 'en_ewt', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/en/pos', '--save_name', 'ewt.pt', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/ewt.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--eval_file', '/tmp/tmpp0im_68g/en_ewt.train.gold.conllu', '--gold_file', '/tmp/tmpp0im_68g/en_ewt.train.gold.conllu', '--output_file', 'data/depparse/en_ewt.train.in.conllu']\n",
            "2023-05-13 20:12:40 INFO: Running tagger in predict mode\n",
            "2023-05-13 20:12:40 INFO: Loading model from: /root/stanza_resources/en/pos/ewt.pt\n",
            "2023-05-13 20:12:41 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/ewt.pt\n",
            "2023-05-13 20:12:41 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n",
            "2023-05-13 20:12:41 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n",
            "2023-05-13 20:12:41 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n",
            "2023-05-13 20:12:49 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 20:12:58 DEBUG: 42 batches created.\n",
            "2023-05-13 20:12:58 INFO: Start evaluation...\n",
            "2023-05-13 20:13:34 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-13 20:13:34 INFO: 99.22\t99.70\t97.61\t96.92\n",
            "2023-05-13 20:13:34 INFO: Tagger score:\n",
            "2023-05-13 20:13:34 INFO: en_ewt 96.92\n",
            "2023-05-13 20:13:34 INFO: Running tagger to retag /tmp/tmpp0im_68g/en_ewt.dev.gold.conllu to data/depparse/en_ewt.dev.gold.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'en', '--shorthand', 'en_ewt', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/en/pos', '--save_name', 'ewt.pt', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/ewt.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--eval_file', '/tmp/tmpp0im_68g/en_ewt.dev.gold.conllu', '--gold_file', '/tmp/tmpp0im_68g/en_ewt.dev.gold.conllu', '--output_file', 'data/depparse/en_ewt.dev.gold.conllu']\n",
            "2023-05-13 20:13:34 INFO: Running tagger in predict mode\n",
            "2023-05-13 20:13:34 INFO: Loading model from: /root/stanza_resources/en/pos/ewt.pt\n",
            "2023-05-13 20:13:34 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/ewt.pt\n",
            "2023-05-13 20:13:34 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n",
            "2023-05-13 20:13:34 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n",
            "2023-05-13 20:13:34 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n",
            "2023-05-13 20:13:34 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 20:13:38 DEBUG: 6 batches created.\n",
            "2023-05-13 20:13:38 INFO: Start evaluation...\n",
            "2023-05-13 20:13:43 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-13 20:13:43 INFO: 96.56\t96.67\t95.46\t93.24\n",
            "2023-05-13 20:13:43 INFO: Tagger score:\n",
            "2023-05-13 20:13:43 INFO: en_ewt 93.24\n",
            "Copying from data/depparse/en_ewt.dev.gold.conllu to data/depparse/en_ewt.dev.in.conllu\n",
            "2023-05-13 20:13:43 INFO: Running tagger to retag /tmp/tmpp0im_68g/en_ewt.test.gold.conllu to data/depparse/en_ewt.test.gold.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'en', '--shorthand', 'en_ewt', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/en/pos', '--save_name', 'ewt.pt', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/ewt.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--eval_file', '/tmp/tmpp0im_68g/en_ewt.test.gold.conllu', '--gold_file', '/tmp/tmpp0im_68g/en_ewt.test.gold.conllu', '--output_file', 'data/depparse/en_ewt.test.gold.conllu']\n",
            "2023-05-13 20:13:43 INFO: Running tagger in predict mode\n",
            "2023-05-13 20:13:43 INFO: Loading model from: /root/stanza_resources/en/pos/ewt.pt\n",
            "2023-05-13 20:13:43 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/ewt.pt\n",
            "2023-05-13 20:13:43 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n",
            "2023-05-13 20:13:43 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n",
            "2023-05-13 20:13:43 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n",
            "2023-05-13 20:13:44 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 20:13:45 DEBUG: 6 batches created.\n",
            "2023-05-13 20:13:45 INFO: Start evaluation...\n",
            "2023-05-13 20:13:50 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-13 20:13:50 INFO: 96.53\t96.53\t95.63\t93.29\n",
            "2023-05-13 20:13:50 INFO: Tagger score:\n",
            "2023-05-13 20:13:50 INFO: en_ewt 93.29\n",
            "Copying from data/depparse/en_ewt.test.gold.conllu to data/depparse/en_ewt.test.in.conllu\n"
          ]
        }
      ],
      "source": [
        "!python3 -m stanza.utils.datasets.prepare_depparse_treebank UD_English-EWT"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsTUK4pI8Y6U",
        "outputId": "bfb1e767-4d6a-43e0-971b-e87a46551595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-13 20:25:08 INFO: Training program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/training/run_depparse.py --train UD_English-EWT --save_dir ./output_stanza_en --max_steps 10000 --cuda\n",
            "2023-05-13 20:25:08 DEBUG: UD_English-EWT: en_ewt\n",
            "2023-05-13 20:25:08 INFO: Save file for en_ewt model: en_ewt_parser.pt\n",
            "2023-05-13 20:25:08 INFO: UD_English-EWT: ./output_stanza_en/en_ewt_parser.pt does not exist, training new model\n",
            "2023-05-13 20:25:08 INFO: Using default pretrain for en:ewt, found in /root/stanza_resources/en/pretrain/ewt.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-13 20:25:08 INFO: Running train depparse for UD_English-EWT with args ['--wordvec_dir', 'extern_data/wordvec', '--train_file', 'data/depparse/en_ewt.train.in.conllu', '--eval_file', 'data/depparse/en_ewt.dev.in.conllu', '--output_file', '/tmp/tmpp1q2jck_', '--gold_file', 'data/depparse/en_ewt.dev.gold.conllu', '--batch_size', '5000', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/ewt.pt', '--max_steps', '10000', '--cuda', '--save_dir', './output_stanza_en', '--save_name', 'en_ewt_parser.pt']\n",
            "2023-05-13 20:25:08 INFO: Running parser in train mode\n",
            "2023-05-13 20:25:08 INFO: Directory ./output_stanza_en does not exist; creating...\n",
            "2023-05-13 20:25:08 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 20:25:11 INFO: Original data size: 12653\n",
            "2023-05-13 20:25:11 INFO: Augmented data size: 12653\n",
            "2023-05-13 20:25:16 INFO: Original length = 12653\n",
            "2023-05-13 20:25:16 INFO: Filtered length = 12653\n",
            "2023-05-13 20:25:19 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/ewt.pt\n",
            "2023-05-13 20:25:22 DEBUG: 45 batches created.\n",
            "2023-05-13 20:25:23 DEBUG: 6 batches created.\n",
            "2023-05-13 20:25:23 INFO: Training parser...\n",
            "2023-05-13 20:25:37 INFO: Finished STEP 20/10000, loss = 6.379848 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:25:47 INFO: Finished STEP 40/10000, loss = 4.457137 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:25:58 INFO: Finished STEP 60/10000, loss = 4.483644 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:26:09 INFO: Finished STEP 80/10000, loss = 4.228587 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:26:20 INFO: Finished STEP 100/10000, loss = 4.908162 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:26:20 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:26:24 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:26:24 INFO: 59.93\t47.66\t50.76\n",
            "2023-05-13 20:26:24 INFO: step 100: train_loss = 10.663746, dev_score = 0.5993\n",
            "2023-05-13 20:26:25 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:26:25 INFO: new best model saved.\n",
            "2023-05-13 20:26:37 INFO: Finished STEP 120/10000, loss = 3.409573 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:26:48 INFO: Finished STEP 140/10000, loss = 3.525182 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:26:58 INFO: Finished STEP 160/10000, loss = 3.314494 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:27:10 INFO: Finished STEP 180/10000, loss = 2.755240 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:27:21 INFO: Finished STEP 200/10000, loss = 3.261696 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:27:21 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:27:25 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:27:25 INFO: 72.93\t64.63\t66.51\n",
            "2023-05-13 20:27:25 INFO: step 200: train_loss = 3.368447, dev_score = 0.7293\n",
            "2023-05-13 20:27:26 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:27:26 INFO: new best model saved.\n",
            "2023-05-13 20:27:37 INFO: Finished STEP 220/10000, loss = 2.380393 (0.448 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:27:48 INFO: Finished STEP 240/10000, loss = 2.684717 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:28:00 INFO: Finished STEP 260/10000, loss = 3.380389 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:28:11 INFO: Finished STEP 280/10000, loss = 2.917936 (0.494 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:28:22 INFO: Finished STEP 300/10000, loss = 2.807660 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:28:22 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:28:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:28:28 INFO: 76.65\t69.31\t71.22\n",
            "2023-05-13 20:28:28 INFO: step 300: train_loss = 2.709145, dev_score = 0.7665\n",
            "2023-05-13 20:28:28 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:28:28 INFO: new best model saved.\n",
            "2023-05-13 20:28:38 INFO: Finished STEP 320/10000, loss = 2.113498 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:28:50 INFO: Finished STEP 340/10000, loss = 2.362883 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:29:01 INFO: Finished STEP 360/10000, loss = 2.534917 (0.432 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:29:11 INFO: Finished STEP 380/10000, loss = 2.031610 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:29:23 INFO: Finished STEP 400/10000, loss = 2.483370 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:29:23 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:29:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:29:27 INFO: 79.82\t73.81\t75.31\n",
            "2023-05-13 20:29:27 INFO: step 400: train_loss = 2.475794, dev_score = 0.7982\n",
            "2023-05-13 20:29:27 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:29:27 INFO: new best model saved.\n",
            "2023-05-13 20:29:39 INFO: Finished STEP 420/10000, loss = 1.623925 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:29:50 INFO: Finished STEP 440/10000, loss = 2.485157 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:30:01 INFO: Finished STEP 460/10000, loss = 2.102503 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:30:13 INFO: Finished STEP 480/10000, loss = 1.835091 (0.410 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:30:24 INFO: Finished STEP 500/10000, loss = 3.195558 (0.421 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:30:24 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:30:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:30:28 INFO: 81.22\t75.45\t77.05\n",
            "2023-05-13 20:30:28 INFO: step 500: train_loss = 2.244572, dev_score = 0.8122\n",
            "2023-05-13 20:30:29 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:30:29 INFO: new best model saved.\n",
            "2023-05-13 20:30:39 INFO: Finished STEP 520/10000, loss = 2.742677 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:30:50 INFO: Finished STEP 540/10000, loss = 2.038460 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:31:02 INFO: Finished STEP 560/10000, loss = 2.023441 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:31:13 INFO: Finished STEP 580/10000, loss = 1.871522 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:31:24 INFO: Finished STEP 600/10000, loss = 2.185944 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:31:24 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:31:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:31:28 INFO: 82.44\t77.24\t78.75\n",
            "2023-05-13 20:31:28 INFO: step 600: train_loss = 2.142418, dev_score = 0.8244\n",
            "2023-05-13 20:31:28 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:31:28 INFO: new best model saved.\n",
            "2023-05-13 20:31:41 INFO: Finished STEP 620/10000, loss = 2.297572 (0.423 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:31:52 INFO: Finished STEP 640/10000, loss = 2.152710 (0.399 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:32:02 INFO: Finished STEP 660/10000, loss = 1.827421 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:32:14 INFO: Finished STEP 680/10000, loss = 2.390427 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:32:25 INFO: Finished STEP 700/10000, loss = 1.381239 (0.410 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:32:25 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:32:29 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:32:29 INFO: 83.02\t78.07\t79.43\n",
            "2023-05-13 20:32:29 INFO: step 700: train_loss = 2.109681, dev_score = 0.8302\n",
            "2023-05-13 20:32:29 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:32:29 INFO: new best model saved.\n",
            "2023-05-13 20:32:40 INFO: Finished STEP 720/10000, loss = 2.585311 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:32:52 INFO: Finished STEP 740/10000, loss = 1.829018 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:33:03 INFO: Finished STEP 760/10000, loss = 2.392033 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:33:15 INFO: Finished STEP 780/10000, loss = 1.969448 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:33:25 INFO: Finished STEP 800/10000, loss = 2.080818 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:33:25 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:33:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:33:31 INFO: 83.64\t78.81\t80.24\n",
            "2023-05-13 20:33:31 INFO: step 800: train_loss = 2.003869, dev_score = 0.8364\n",
            "2023-05-13 20:33:31 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:33:31 INFO: new best model saved.\n",
            "2023-05-13 20:33:42 INFO: Finished STEP 820/10000, loss = 1.489142 (0.419 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:33:53 INFO: Finished STEP 840/10000, loss = 0.830472 (1.444 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:34:04 INFO: Finished STEP 860/10000, loss = 1.785325 (0.488 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:34:14 INFO: Finished STEP 880/10000, loss = 1.344022 (0.515 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:34:26 INFO: Finished STEP 900/10000, loss = 2.146254 (0.426 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:34:26 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:34:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:34:31 INFO: 83.90\t79.24\t80.45\n",
            "2023-05-13 20:34:31 INFO: step 900: train_loss = 1.970089, dev_score = 0.8390\n",
            "2023-05-13 20:34:31 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:34:31 INFO: new best model saved.\n",
            "2023-05-13 20:34:43 INFO: Finished STEP 920/10000, loss = 1.645843 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:34:53 INFO: Finished STEP 940/10000, loss = 2.342582 (0.502 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:35:04 INFO: Finished STEP 960/10000, loss = 2.340235 (0.538 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:35:16 INFO: Finished STEP 980/10000, loss = 2.590597 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:35:28 INFO: Finished STEP 1000/10000, loss = 1.787665 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:35:28 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:35:33 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:35:33 INFO: 84.50\t79.88\t81.14\n",
            "2023-05-13 20:35:33 INFO: step 1000: train_loss = 1.909053, dev_score = 0.8450\n",
            "2023-05-13 20:35:33 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:35:33 INFO: new best model saved.\n",
            "2023-05-13 20:35:44 INFO: Finished STEP 1020/10000, loss = 1.535403 (0.454 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:35:55 INFO: Finished STEP 1040/10000, loss = 1.038547 (0.477 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:36:05 INFO: Finished STEP 1060/10000, loss = 1.335886 (0.444 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:36:16 INFO: Finished STEP 1080/10000, loss = 2.767963 (0.418 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:36:27 INFO: Finished STEP 1100/10000, loss = 1.364813 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:36:27 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:36:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:36:32 INFO: 84.80\t80.30\t81.54\n",
            "2023-05-13 20:36:32 INFO: step 1100: train_loss = 1.866946, dev_score = 0.8480\n",
            "2023-05-13 20:36:32 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:36:32 INFO: new best model saved.\n",
            "2023-05-13 20:36:44 INFO: Finished STEP 1120/10000, loss = 2.163229 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:36:55 INFO: Finished STEP 1140/10000, loss = 1.489530 (0.435 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:37:06 INFO: Finished STEP 1160/10000, loss = 1.285123 (0.444 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:37:17 INFO: Finished STEP 1180/10000, loss = 1.728314 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:37:27 INFO: Finished STEP 1200/10000, loss = 1.436660 (0.417 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:37:27 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:37:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:37:31 INFO: 85.05\t80.90\t81.95\n",
            "2023-05-13 20:37:31 INFO: step 1200: train_loss = 1.835850, dev_score = 0.8505\n",
            "2023-05-13 20:37:31 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:37:31 INFO: new best model saved.\n",
            "2023-05-13 20:37:45 INFO: Finished STEP 1220/10000, loss = 1.637771 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:37:55 INFO: Finished STEP 1240/10000, loss = 9.393840 (0.622 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:38:07 INFO: Finished STEP 1260/10000, loss = 1.342782 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:38:17 INFO: Finished STEP 1280/10000, loss = 1.141234 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:38:28 INFO: Finished STEP 1300/10000, loss = 1.487583 (0.472 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:38:28 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:38:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:38:34 INFO: 85.47\t81.01\t82.29\n",
            "2023-05-13 20:38:34 INFO: step 1300: train_loss = 1.754961, dev_score = 0.8547\n",
            "2023-05-13 20:38:34 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:38:34 INFO: new best model saved.\n",
            "2023-05-13 20:38:46 INFO: Finished STEP 1320/10000, loss = 2.154962 (0.510 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:38:57 INFO: Finished STEP 1340/10000, loss = 1.193374 (0.519 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:39:08 INFO: Finished STEP 1360/10000, loss = 1.051797 (0.445 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:39:19 INFO: Finished STEP 1380/10000, loss = 1.188127 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:39:30 INFO: Finished STEP 1400/10000, loss = 1.982060 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:39:30 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:39:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:39:34 INFO: 85.41\t81.17\t82.24\n",
            "2023-05-13 20:39:34 INFO: step 1400: train_loss = 1.849749, dev_score = 0.8541\n",
            "2023-05-13 20:39:44 INFO: Finished STEP 1420/10000, loss = 1.751192 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:39:56 INFO: Finished STEP 1440/10000, loss = 1.182787 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:40:07 INFO: Finished STEP 1460/10000, loss = 2.167210 (0.548 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:40:19 INFO: Finished STEP 1480/10000, loss = 1.874706 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:40:29 INFO: Finished STEP 1500/10000, loss = 1.758933 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:40:29 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:40:33 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:40:33 INFO: 85.39\t80.99\t82.13\n",
            "2023-05-13 20:40:33 INFO: step 1500: train_loss = 1.788937, dev_score = 0.8539\n",
            "2023-05-13 20:40:45 INFO: Finished STEP 1520/10000, loss = 1.617308 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:40:56 INFO: Finished STEP 1540/10000, loss = 1.985620 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:41:07 INFO: Finished STEP 1560/10000, loss = 1.642818 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:41:19 INFO: Finished STEP 1580/10000, loss = 8.567300 (0.618 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:41:28 INFO: Finished STEP 1600/10000, loss = 1.908000 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:41:28 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:41:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:41:34 INFO: 85.81\t81.71\t82.75\n",
            "2023-05-13 20:41:34 INFO: step 1600: train_loss = 1.733585, dev_score = 0.8581\n",
            "2023-05-13 20:41:34 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:41:34 INFO: new best model saved.\n",
            "2023-05-13 20:41:46 INFO: Finished STEP 1620/10000, loss = 2.217985 (0.557 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:41:56 INFO: Finished STEP 1640/10000, loss = 1.627579 (0.428 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:42:09 INFO: Finished STEP 1660/10000, loss = 2.679182 (0.417 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:42:20 INFO: Finished STEP 1680/10000, loss = 2.153383 (0.414 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:42:30 INFO: Finished STEP 1700/10000, loss = 1.143350 (0.417 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:42:30 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:42:35 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:42:35 INFO: 86.08\t82.03\t83.07\n",
            "2023-05-13 20:42:35 INFO: step 1700: train_loss = 1.671331, dev_score = 0.8608\n",
            "2023-05-13 20:42:35 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:42:35 INFO: new best model saved.\n",
            "2023-05-13 20:42:46 INFO: Finished STEP 1720/10000, loss = 1.334066 (0.426 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:42:58 INFO: Finished STEP 1740/10000, loss = 1.498193 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:43:08 INFO: Finished STEP 1760/10000, loss = 1.210225 (0.436 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:43:20 INFO: Finished STEP 1780/10000, loss = 1.659377 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:43:32 INFO: Finished STEP 1800/10000, loss = 1.850367 (0.426 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:43:32 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:43:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:43:36 INFO: 86.07\t82.02\t83.07\n",
            "2023-05-13 20:43:36 INFO: step 1800: train_loss = 1.740886, dev_score = 0.8607\n",
            "2023-05-13 20:43:47 INFO: Finished STEP 1820/10000, loss = 1.345743 (0.488 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:43:59 INFO: Finished STEP 1840/10000, loss = 1.451136 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:44:10 INFO: Finished STEP 1860/10000, loss = 1.668769 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:44:21 INFO: Finished STEP 1880/10000, loss = 1.318138 (0.460 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:44:32 INFO: Finished STEP 1900/10000, loss = 2.288450 (0.399 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:44:32 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:44:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:44:37 INFO: 86.15\t82.20\t83.16\n",
            "2023-05-13 20:44:37 INFO: step 1900: train_loss = 1.701818, dev_score = 0.8615\n",
            "2023-05-13 20:44:37 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:44:37 INFO: new best model saved.\n",
            "2023-05-13 20:44:48 INFO: Finished STEP 1920/10000, loss = 2.437328 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:44:58 INFO: Finished STEP 1940/10000, loss = 1.380317 (0.419 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:45:11 INFO: Finished STEP 1960/10000, loss = 1.260396 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:45:21 INFO: Finished STEP 1980/10000, loss = 1.859623 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:45:32 INFO: Finished STEP 2000/10000, loss = 1.539045 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:45:32 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:45:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:45:36 INFO: 86.25\t82.24\t83.22\n",
            "2023-05-13 20:45:36 INFO: step 2000: train_loss = 1.691059, dev_score = 0.8625\n",
            "2023-05-13 20:45:36 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:45:36 INFO: new best model saved.\n",
            "2023-05-13 20:45:48 INFO: Finished STEP 2020/10000, loss = 1.276217 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:45:59 INFO: Finished STEP 2040/10000, loss = 1.662949 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:46:11 INFO: Finished STEP 2060/10000, loss = 1.610759 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:46:21 INFO: Finished STEP 2080/10000, loss = 1.157438 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:46:32 INFO: Finished STEP 2100/10000, loss = 1.478093 (0.480 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:46:32 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:46:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:46:37 INFO: 86.31\t82.34\t83.41\n",
            "2023-05-13 20:46:37 INFO: step 2100: train_loss = 1.667433, dev_score = 0.8631\n",
            "2023-05-13 20:46:38 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:46:38 INFO: new best model saved.\n",
            "2023-05-13 20:46:50 INFO: Finished STEP 2120/10000, loss = 1.863780 (0.512 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:47:02 INFO: Finished STEP 2140/10000, loss = 1.095558 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:47:12 INFO: Finished STEP 2160/10000, loss = 1.448738 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:47:23 INFO: Finished STEP 2180/10000, loss = 0.983505 (0.481 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:47:35 INFO: Finished STEP 2200/10000, loss = 1.679406 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:47:35 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:47:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:47:39 INFO: 86.32\t82.36\t83.34\n",
            "2023-05-13 20:47:39 INFO: step 2200: train_loss = 1.669461, dev_score = 0.8632\n",
            "2023-05-13 20:47:40 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:47:40 INFO: new best model saved.\n",
            "2023-05-13 20:47:51 INFO: Finished STEP 2220/10000, loss = 0.919277 (0.674 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:48:02 INFO: Finished STEP 2240/10000, loss = 1.866039 (0.498 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:48:13 INFO: Finished STEP 2260/10000, loss = 1.905392 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:48:24 INFO: Finished STEP 2280/10000, loss = 1.278293 (0.448 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:48:36 INFO: Finished STEP 2300/10000, loss = 1.585964 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:48:36 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:48:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:48:41 INFO: 86.60\t82.57\t83.61\n",
            "2023-05-13 20:48:41 INFO: step 2300: train_loss = 1.620632, dev_score = 0.8660\n",
            "2023-05-13 20:48:41 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:48:41 INFO: new best model saved.\n",
            "2023-05-13 20:48:54 INFO: Finished STEP 2320/10000, loss = 1.645715 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:49:04 INFO: Finished STEP 2340/10000, loss = 1.635250 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:49:16 INFO: Finished STEP 2360/10000, loss = 1.270683 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:49:27 INFO: Finished STEP 2380/10000, loss = 1.688325 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:49:39 INFO: Finished STEP 2400/10000, loss = 3.933084 (0.446 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:49:39 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:49:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:49:43 INFO: 86.53\t82.66\t83.58\n",
            "2023-05-13 20:49:43 INFO: step 2400: train_loss = 1.628690, dev_score = 0.8653\n",
            "2023-05-13 20:49:53 INFO: Finished STEP 2420/10000, loss = 1.794705 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:50:05 INFO: Finished STEP 2440/10000, loss = 1.781286 (0.507 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:50:18 INFO: Finished STEP 2460/10000, loss = 1.242113 (0.464 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:50:28 INFO: Finished STEP 2480/10000, loss = 1.416194 (0.402 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:50:39 INFO: Finished STEP 2500/10000, loss = 1.607432 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:50:39 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:50:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:50:43 INFO: 86.64\t82.70\t83.67\n",
            "2023-05-13 20:50:43 INFO: step 2500: train_loss = 1.622068, dev_score = 0.8664\n",
            "2023-05-13 20:50:44 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:50:44 INFO: new best model saved.\n",
            "2023-05-13 20:50:55 INFO: Finished STEP 2520/10000, loss = 1.625802 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:51:06 INFO: Finished STEP 2540/10000, loss = 1.237588 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:51:17 INFO: Finished STEP 2560/10000, loss = 1.697885 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:51:29 INFO: Finished STEP 2580/10000, loss = 1.017528 (0.515 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:51:41 INFO: Finished STEP 2600/10000, loss = 1.714591 (0.432 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:51:41 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:51:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:51:45 INFO: 86.87\t82.95\t83.95\n",
            "2023-05-13 20:51:45 INFO: step 2600: train_loss = 1.568619, dev_score = 0.8687\n",
            "2023-05-13 20:51:45 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:51:45 INFO: new best model saved.\n",
            "2023-05-13 20:51:55 INFO: Finished STEP 2620/10000, loss = 1.441225 (0.477 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:52:09 INFO: Finished STEP 2640/10000, loss = 1.697792 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:52:19 INFO: Finished STEP 2660/10000, loss = 1.083106 (0.543 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:52:31 INFO: Finished STEP 2680/10000, loss = 1.604019 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:52:41 INFO: Finished STEP 2700/10000, loss = 1.138924 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:52:41 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:52:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:52:46 INFO: 86.95\t83.06\t83.98\n",
            "2023-05-13 20:52:46 INFO: step 2700: train_loss = 1.645331, dev_score = 0.8695\n",
            "2023-05-13 20:52:46 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:52:46 INFO: new best model saved.\n",
            "2023-05-13 20:52:57 INFO: Finished STEP 2720/10000, loss = 8.088378 (0.610 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:53:08 INFO: Finished STEP 2740/10000, loss = 0.000038 (0.094 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:53:19 INFO: Finished STEP 2760/10000, loss = 0.884702 (0.690 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:53:30 INFO: Finished STEP 2780/10000, loss = 1.212889 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:53:43 INFO: Finished STEP 2800/10000, loss = 1.532412 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:53:43 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:53:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:53:47 INFO: 86.88\t82.97\t83.93\n",
            "2023-05-13 20:53:47 INFO: step 2800: train_loss = 1.576253, dev_score = 0.8688\n",
            "2023-05-13 20:53:59 INFO: Finished STEP 2820/10000, loss = 1.087363 (0.430 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:54:10 INFO: Finished STEP 2840/10000, loss = 0.980148 (0.517 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:54:21 INFO: Finished STEP 2860/10000, loss = 1.633692 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:54:32 INFO: Finished STEP 2880/10000, loss = 1.483885 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:54:44 INFO: Finished STEP 2900/10000, loss = 1.275335 (0.449 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:54:44 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:54:49 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:54:49 INFO: 86.75\t82.86\t83.80\n",
            "2023-05-13 20:54:49 INFO: step 2900: train_loss = 1.548370, dev_score = 0.8675\n",
            "2023-05-13 20:54:59 INFO: Finished STEP 2920/10000, loss = 1.457814 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:55:10 INFO: Finished STEP 2940/10000, loss = 1.252830 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:55:21 INFO: Finished STEP 2960/10000, loss = 0.001517 (0.105 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:55:33 INFO: Finished STEP 2980/10000, loss = 1.421493 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:55:44 INFO: Finished STEP 3000/10000, loss = 1.272090 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:55:44 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:55:48 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:55:48 INFO: 86.90\t82.82\t83.90\n",
            "2023-05-13 20:55:48 INFO: step 3000: train_loss = 1.684772, dev_score = 0.8690\n",
            "2023-05-13 20:55:59 INFO: Finished STEP 3020/10000, loss = 1.239496 (0.413 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:56:10 INFO: Finished STEP 3040/10000, loss = 1.274385 (0.468 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:56:22 INFO: Finished STEP 3060/10000, loss = 1.490330 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:56:34 INFO: Finished STEP 3080/10000, loss = 1.471849 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:56:44 INFO: Finished STEP 3100/10000, loss = 1.961884 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:56:44 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:56:48 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:56:48 INFO: 87.09\t83.14\t84.21\n",
            "2023-05-13 20:56:48 INFO: step 3100: train_loss = 1.577139, dev_score = 0.8709\n",
            "2023-05-13 20:56:48 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:56:48 INFO: new best model saved.\n",
            "2023-05-13 20:56:59 INFO: Finished STEP 3120/10000, loss = 1.247407 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:57:10 INFO: Finished STEP 3140/10000, loss = 1.270055 (0.464 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:57:22 INFO: Finished STEP 3160/10000, loss = 1.817820 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:57:34 INFO: Finished STEP 3180/10000, loss = 1.146691 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:57:45 INFO: Finished STEP 3200/10000, loss = 1.275262 (0.399 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:57:45 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:57:49 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:57:49 INFO: 87.09\t83.19\t84.12\n",
            "2023-05-13 20:57:49 INFO: step 3200: train_loss = 1.521028, dev_score = 0.8709\n",
            "2023-05-13 20:58:00 INFO: Finished STEP 3220/10000, loss = 1.107795 (0.420 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:58:12 INFO: Finished STEP 3240/10000, loss = 1.022270 (0.422 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:58:22 INFO: Finished STEP 3260/10000, loss = 1.672290 (0.513 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:58:34 INFO: Finished STEP 3280/10000, loss = 1.350569 (0.433 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:58:45 INFO: Finished STEP 3300/10000, loss = 1.201333 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:58:45 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:58:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:58:50 INFO: 87.30\t83.43\t84.39\n",
            "2023-05-13 20:58:50 INFO: step 3300: train_loss = 1.584384, dev_score = 0.8730\n",
            "2023-05-13 20:58:50 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:58:50 INFO: new best model saved.\n",
            "2023-05-13 20:59:03 INFO: Finished STEP 3320/10000, loss = 0.900118 (1.454 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:59:15 INFO: Finished STEP 3340/10000, loss = 1.192460 (0.450 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:59:26 INFO: Finished STEP 3360/10000, loss = 1.008679 (0.420 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:59:36 INFO: Finished STEP 3380/10000, loss = 1.412831 (0.436 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:59:47 INFO: Finished STEP 3400/10000, loss = 1.821249 (0.525 sec/batch), lr: 0.003000\n",
            "2023-05-13 20:59:47 INFO: Evaluating on dev set...\n",
            "2023-05-13 20:59:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 20:59:51 INFO: 87.32\t83.47\t84.41\n",
            "2023-05-13 20:59:51 INFO: step 3400: train_loss = 1.473686, dev_score = 0.8732\n",
            "2023-05-13 20:59:51 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 20:59:51 INFO: new best model saved.\n",
            "2023-05-13 21:00:03 INFO: Finished STEP 3420/10000, loss = 2.006404 (0.399 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:00:13 INFO: Finished STEP 3440/10000, loss = 1.094201 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:00:25 INFO: Finished STEP 3460/10000, loss = 1.279508 (0.423 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:00:37 INFO: Finished STEP 3480/10000, loss = 0.000278 (0.101 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:00:48 INFO: Finished STEP 3500/10000, loss = 1.452975 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:00:48 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:00:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:00:52 INFO: 87.26\t83.34\t84.28\n",
            "2023-05-13 21:00:52 INFO: step 3500: train_loss = 1.603634, dev_score = 0.8726\n",
            "2023-05-13 21:01:03 INFO: Finished STEP 3520/10000, loss = 1.236594 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:01:15 INFO: Finished STEP 3540/10000, loss = 1.237081 (0.420 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:01:26 INFO: Finished STEP 3560/10000, loss = 1.492049 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:01:36 INFO: Finished STEP 3580/10000, loss = 1.155764 (0.457 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:01:47 INFO: Finished STEP 3600/10000, loss = 1.776028 (0.524 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:01:47 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:01:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:01:53 INFO: 87.28\t83.50\t84.41\n",
            "2023-05-13 21:01:53 INFO: step 3600: train_loss = 1.493031, dev_score = 0.8728\n",
            "2023-05-13 21:02:04 INFO: Finished STEP 3620/10000, loss = 1.105797 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:02:16 INFO: Finished STEP 3640/10000, loss = 4.159317 (0.108 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:02:27 INFO: Finished STEP 3660/10000, loss = 1.472314 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:02:37 INFO: Finished STEP 3680/10000, loss = 1.064740 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:02:48 INFO: Finished STEP 3700/10000, loss = 2.455073 (0.413 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:02:48 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:02:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:02:52 INFO: 87.07\t83.33\t84.38\n",
            "2023-05-13 21:02:52 INFO: step 3700: train_loss = 1.597404, dev_score = 0.8707\n",
            "2023-05-13 21:03:04 INFO: Finished STEP 3720/10000, loss = 1.278179 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:03:15 INFO: Finished STEP 3740/10000, loss = 1.106809 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:03:26 INFO: Finished STEP 3760/10000, loss = 1.639700 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:03:38 INFO: Finished STEP 3780/10000, loss = 1.806500 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:03:49 INFO: Finished STEP 3800/10000, loss = 1.539054 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:03:49 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:03:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:03:53 INFO: 87.14\t83.36\t84.26\n",
            "2023-05-13 21:03:53 INFO: step 3800: train_loss = 1.515112, dev_score = 0.8714\n",
            "2023-05-13 21:04:05 INFO: Finished STEP 3820/10000, loss = 0.998136 (0.450 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:04:16 INFO: Finished STEP 3840/10000, loss = 1.708358 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:04:26 INFO: Finished STEP 3860/10000, loss = 1.612384 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:04:38 INFO: Finished STEP 3880/10000, loss = 1.618711 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:04:50 INFO: Finished STEP 3900/10000, loss = 1.217193 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:04:50 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:04:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:04:54 INFO: 87.16\t83.36\t84.33\n",
            "2023-05-13 21:04:54 INFO: step 3900: train_loss = 1.497252, dev_score = 0.8716\n",
            "2023-05-13 21:05:04 INFO: Finished STEP 3920/10000, loss = 1.331108 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:05:14 INFO: Finished STEP 3940/10000, loss = 1.308715 (0.496 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:05:27 INFO: Finished STEP 3960/10000, loss = 1.548883 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:05:38 INFO: Finished STEP 3980/10000, loss = 1.662669 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:05:49 INFO: Finished STEP 4000/10000, loss = 1.133643 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:05:49 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:05:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:05:53 INFO: 87.20\t83.35\t84.31\n",
            "2023-05-13 21:05:53 INFO: step 4000: train_loss = 1.512249, dev_score = 0.8720\n",
            "2023-05-13 21:06:05 INFO: Finished STEP 4020/10000, loss = 0.814196 (1.441 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:06:15 INFO: Finished STEP 4040/10000, loss = 1.293452 (0.471 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:06:26 INFO: Finished STEP 4060/10000, loss = 1.246710 (0.476 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:06:36 INFO: Finished STEP 4080/10000, loss = 2.418905 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:06:49 INFO: Finished STEP 4100/10000, loss = 1.474117 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:06:49 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:06:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:06:54 INFO: 87.35\t83.53\t84.38\n",
            "2023-05-13 21:06:54 INFO: step 4100: train_loss = 1.490031, dev_score = 0.8735\n",
            "2023-05-13 21:06:55 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:06:55 INFO: new best model saved.\n",
            "2023-05-13 21:07:04 INFO: Finished STEP 4120/10000, loss = 1.146078 (0.410 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:07:17 INFO: Finished STEP 4140/10000, loss = 1.404601 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:07:27 INFO: Finished STEP 4160/10000, loss = 1.563324 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:07:39 INFO: Finished STEP 4180/10000, loss = 1.416074 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:07:50 INFO: Finished STEP 4200/10000, loss = 0.000527 (0.093 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:07:50 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:07:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:07:54 INFO: 87.42\t83.71\t84.59\n",
            "2023-05-13 21:07:54 INFO: step 4200: train_loss = 1.542819, dev_score = 0.8742\n",
            "2023-05-13 21:07:54 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:07:54 INFO: new best model saved.\n",
            "2023-05-13 21:08:05 INFO: Finished STEP 4220/10000, loss = 1.686593 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:08:17 INFO: Finished STEP 4240/10000, loss = 1.452727 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:08:28 INFO: Finished STEP 4260/10000, loss = 1.044517 (0.429 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:08:40 INFO: Finished STEP 4280/10000, loss = 1.414220 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:08:51 INFO: Finished STEP 4300/10000, loss = 1.201637 (0.447 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:08:51 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:08:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:08:54 INFO: 87.33\t83.58\t84.46\n",
            "2023-05-13 21:08:54 INFO: step 4300: train_loss = 1.538292, dev_score = 0.8733\n",
            "2023-05-13 21:09:07 INFO: Finished STEP 4320/10000, loss = 2.246125 (0.418 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:09:18 INFO: Finished STEP 4340/10000, loss = 1.168397 (0.440 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:09:29 INFO: Finished STEP 4360/10000, loss = 1.345654 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:09:40 INFO: Finished STEP 4380/10000, loss = 1.318369 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:09:51 INFO: Finished STEP 4400/10000, loss = 1.460399 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:09:51 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:09:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:09:56 INFO: 87.34\t83.67\t84.49\n",
            "2023-05-13 21:09:56 INFO: step 4400: train_loss = 1.430488, dev_score = 0.8734\n",
            "2023-05-13 21:10:06 INFO: Finished STEP 4420/10000, loss = 1.452310 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:10:18 INFO: Finished STEP 4440/10000, loss = 1.505101 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:10:29 INFO: Finished STEP 4460/10000, loss = 1.881959 (0.547 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:10:40 INFO: Finished STEP 4480/10000, loss = 1.132869 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:10:51 INFO: Finished STEP 4500/10000, loss = 0.950385 (0.438 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:10:51 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:10:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:10:56 INFO: 87.18\t83.44\t84.43\n",
            "2023-05-13 21:10:56 INFO: step 4500: train_loss = 1.458074, dev_score = 0.8718\n",
            "2023-05-13 21:11:06 INFO: Finished STEP 4520/10000, loss = 1.509962 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:11:18 INFO: Finished STEP 4540/10000, loss = 1.273587 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:11:29 INFO: Finished STEP 4560/10000, loss = 5.155042 (0.109 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:11:40 INFO: Finished STEP 4580/10000, loss = 1.579164 (0.437 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:11:51 INFO: Finished STEP 4600/10000, loss = 1.437955 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:11:51 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:11:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:11:56 INFO: 87.36\t83.52\t84.44\n",
            "2023-05-13 21:11:56 INFO: step 4600: train_loss = 1.470723, dev_score = 0.8736\n",
            "2023-05-13 21:12:06 INFO: Finished STEP 4620/10000, loss = 1.330810 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:12:19 INFO: Finished STEP 4640/10000, loss = 1.579770 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:12:30 INFO: Finished STEP 4660/10000, loss = 1.404622 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:12:41 INFO: Finished STEP 4680/10000, loss = 1.554333 (0.430 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:12:52 INFO: Finished STEP 4700/10000, loss = 8.057834 (0.631 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:12:52 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:12:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:12:56 INFO: 87.30\t83.46\t84.35\n",
            "2023-05-13 21:12:56 INFO: step 4700: train_loss = 1.506117, dev_score = 0.8730\n",
            "2023-05-13 21:13:06 INFO: Finished STEP 4720/10000, loss = 0.998808 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:13:18 INFO: Finished STEP 4740/10000, loss = 1.585663 (0.438 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:13:29 INFO: Finished STEP 4760/10000, loss = 1.003912 (0.446 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:13:41 INFO: Finished STEP 4780/10000, loss = 1.245027 (0.431 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:13:53 INFO: Finished STEP 4800/10000, loss = 1.188070 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:13:53 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:13:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:13:57 INFO: 87.28\t83.47\t84.35\n",
            "2023-05-13 21:13:57 INFO: step 4800: train_loss = 1.455830, dev_score = 0.8728\n",
            "2023-05-13 21:14:08 INFO: Finished STEP 4820/10000, loss = 1.137945 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:14:19 INFO: Finished STEP 4840/10000, loss = 1.352397 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:14:29 INFO: Finished STEP 4860/10000, loss = 1.229991 (0.424 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:14:39 INFO: Finished STEP 4880/10000, loss = 1.414662 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:14:50 INFO: Finished STEP 4900/10000, loss = 1.119402 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:14:50 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:14:55 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:14:55 INFO: 87.27\t83.44\t84.35\n",
            "2023-05-13 21:14:55 INFO: step 4900: train_loss = 1.439874, dev_score = 0.8727\n",
            "2023-05-13 21:15:07 INFO: Finished STEP 4920/10000, loss = 1.079184 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:15:18 INFO: Finished STEP 4940/10000, loss = 1.824516 (0.542 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:15:29 INFO: Finished STEP 4960/10000, loss = 1.595619 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:15:41 INFO: Finished STEP 4980/10000, loss = 1.174089 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:15:52 INFO: Finished STEP 5000/10000, loss = 1.836209 (0.416 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:15:52 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:15:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:15:56 INFO: 87.57\t83.78\t84.65\n",
            "2023-05-13 21:15:56 INFO: step 5000: train_loss = 1.468971, dev_score = 0.8757\n",
            "2023-05-13 21:15:56 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:15:56 INFO: new best model saved.\n",
            "2023-05-13 21:16:08 INFO: Finished STEP 5020/10000, loss = 1.114334 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:16:19 INFO: Finished STEP 5040/10000, loss = 1.530330 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:16:29 INFO: Finished STEP 5060/10000, loss = 1.961921 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:16:41 INFO: Finished STEP 5080/10000, loss = 1.053721 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:16:52 INFO: Finished STEP 5100/10000, loss = 1.256469 (0.487 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:16:52 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:16:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:16:57 INFO: 87.47\t83.84\t84.67\n",
            "2023-05-13 21:16:57 INFO: step 5100: train_loss = 1.397774, dev_score = 0.8747\n",
            "2023-05-13 21:17:08 INFO: Finished STEP 5120/10000, loss = 3.615689 (0.440 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:17:20 INFO: Finished STEP 5140/10000, loss = 0.536415 (1.446 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:17:32 INFO: Finished STEP 5160/10000, loss = 1.024736 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:17:42 INFO: Finished STEP 5180/10000, loss = 1.421106 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:17:52 INFO: Finished STEP 5200/10000, loss = 0.982492 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:17:52 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:17:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:17:58 INFO: 87.41\t83.66\t84.56\n",
            "2023-05-13 21:17:58 INFO: step 5200: train_loss = 1.389583, dev_score = 0.8741\n",
            "2023-05-13 21:18:10 INFO: Finished STEP 5220/10000, loss = 1.705679 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:18:20 INFO: Finished STEP 5240/10000, loss = 3.774127 (0.449 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:18:32 INFO: Finished STEP 5260/10000, loss = 1.264790 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:18:42 INFO: Finished STEP 5280/10000, loss = 1.933019 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:18:53 INFO: Finished STEP 5300/10000, loss = 1.092410 (0.414 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:18:53 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:18:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:18:57 INFO: 87.57\t83.69\t84.59\n",
            "2023-05-13 21:18:57 INFO: step 5300: train_loss = 1.515825, dev_score = 0.8757\n",
            "2023-05-13 21:19:09 INFO: Finished STEP 5320/10000, loss = 0.781027 (0.678 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:19:22 INFO: Finished STEP 5340/10000, loss = 1.321142 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:19:33 INFO: Finished STEP 5360/10000, loss = 0.691726 (1.248 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:19:43 INFO: Finished STEP 5380/10000, loss = 0.002887 (0.097 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:19:54 INFO: Finished STEP 5400/10000, loss = 1.166580 (0.457 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:19:54 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:19:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:19:59 INFO: 87.71\t83.93\t84.80\n",
            "2023-05-13 21:19:59 INFO: step 5400: train_loss = 1.412077, dev_score = 0.8771\n",
            "2023-05-13 21:19:59 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:19:59 INFO: new best model saved.\n",
            "2023-05-13 21:20:10 INFO: Finished STEP 5420/10000, loss = 1.348796 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:20:21 INFO: Finished STEP 5440/10000, loss = 1.067676 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:20:33 INFO: Finished STEP 5460/10000, loss = 0.944464 (0.481 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:20:44 INFO: Finished STEP 5480/10000, loss = 1.262618 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:20:56 INFO: Finished STEP 5500/10000, loss = 1.628934 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:20:56 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:20:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:20:59 INFO: 87.51\t83.58\t84.55\n",
            "2023-05-13 21:20:59 INFO: step 5500: train_loss = 1.454865, dev_score = 0.8751\n",
            "2023-05-13 21:21:12 INFO: Finished STEP 5520/10000, loss = 1.159202 (0.463 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:21:22 INFO: Finished STEP 5540/10000, loss = 0.943258 (0.460 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:21:33 INFO: Finished STEP 5560/10000, loss = 0.992621 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:21:44 INFO: Finished STEP 5580/10000, loss = 1.915079 (0.538 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:21:55 INFO: Finished STEP 5600/10000, loss = 3.647956 (0.441 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:21:55 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:21:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:21:59 INFO: 87.56\t83.75\t84.68\n",
            "2023-05-13 21:21:59 INFO: step 5600: train_loss = 1.428001, dev_score = 0.8756\n",
            "2023-05-13 21:22:10 INFO: Finished STEP 5620/10000, loss = 1.656848 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:22:21 INFO: Finished STEP 5640/10000, loss = 0.763987 (0.688 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:22:33 INFO: Finished STEP 5660/10000, loss = 0.000975 (0.098 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:22:44 INFO: Finished STEP 5680/10000, loss = 1.484331 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:22:56 INFO: Finished STEP 5700/10000, loss = 1.546625 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:22:56 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:23:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:23:02 INFO: 87.67\t83.91\t84.88\n",
            "2023-05-13 21:23:02 INFO: step 5700: train_loss = 1.452176, dev_score = 0.8767\n",
            "2023-05-13 21:23:13 INFO: Finished STEP 5720/10000, loss = 2.153994 (0.423 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:23:23 INFO: Finished STEP 5740/10000, loss = 0.975989 (0.447 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:23:34 INFO: Finished STEP 5760/10000, loss = 1.270979 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:23:45 INFO: Finished STEP 5780/10000, loss = 3.650082 (0.445 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:23:56 INFO: Finished STEP 5800/10000, loss = 1.609957 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:23:56 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:24:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:24:00 INFO: 87.74\t84.04\t84.95\n",
            "2023-05-13 21:24:00 INFO: step 5800: train_loss = 1.391162, dev_score = 0.8774\n",
            "2023-05-13 21:24:00 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:24:00 INFO: new best model saved.\n",
            "2023-05-13 21:24:12 INFO: Finished STEP 5820/10000, loss = 1.329332 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:24:24 INFO: Finished STEP 5840/10000, loss = 1.407405 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:24:35 INFO: Finished STEP 5860/10000, loss = 0.937040 (0.435 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:24:45 INFO: Finished STEP 5880/10000, loss = 1.806983 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:24:56 INFO: Finished STEP 5900/10000, loss = 3.993824 (0.102 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:24:56 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:25:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:25:00 INFO: 87.76\t84.13\t84.97\n",
            "2023-05-13 21:25:00 INFO: step 5900: train_loss = 1.415226, dev_score = 0.8776\n",
            "2023-05-13 21:25:01 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:25:01 INFO: new best model saved.\n",
            "2023-05-13 21:25:11 INFO: Finished STEP 5920/10000, loss = 1.058903 (0.442 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:25:23 INFO: Finished STEP 5940/10000, loss = 1.047300 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:25:35 INFO: Finished STEP 5960/10000, loss = 1.348336 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:25:47 INFO: Finished STEP 5980/10000, loss = 0.899556 (0.471 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:25:58 INFO: Finished STEP 6000/10000, loss = 0.596125 (1.236 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:25:58 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:26:03 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:26:03 INFO: 87.65\t83.99\t84.83\n",
            "2023-05-13 21:26:03 INFO: step 6000: train_loss = 1.372585, dev_score = 0.8765\n",
            "2023-05-13 21:26:13 INFO: Finished STEP 6020/10000, loss = 1.370533 (0.418 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:26:24 INFO: Finished STEP 6040/10000, loss = 1.263522 (0.410 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:26:36 INFO: Finished STEP 6060/10000, loss = 1.301483 (0.463 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:26:46 INFO: Finished STEP 6080/10000, loss = 0.000057 (0.095 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:26:57 INFO: Finished STEP 6100/10000, loss = 1.224395 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:26:57 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:27:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:27:02 INFO: 87.52\t83.78\t84.67\n",
            "2023-05-13 21:27:02 INFO: step 6100: train_loss = 1.399355, dev_score = 0.8752\n",
            "2023-05-13 21:27:13 INFO: Finished STEP 6120/10000, loss = 1.055071 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:27:24 INFO: Finished STEP 6140/10000, loss = 1.522529 (0.433 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:27:36 INFO: Finished STEP 6160/10000, loss = 1.162747 (0.410 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:27:48 INFO: Finished STEP 6180/10000, loss = 7.881652 (0.633 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:27:58 INFO: Finished STEP 6200/10000, loss = 0.955073 (0.419 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:27:58 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:28:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:28:04 INFO: 87.66\t83.82\t84.65\n",
            "2023-05-13 21:28:04 INFO: step 6200: train_loss = 1.456971, dev_score = 0.8766\n",
            "2023-05-13 21:28:14 INFO: Finished STEP 6220/10000, loss = 3.725935 (0.441 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:28:25 INFO: Finished STEP 6240/10000, loss = 1.454735 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:28:36 INFO: Finished STEP 6260/10000, loss = 1.554553 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:28:47 INFO: Finished STEP 6280/10000, loss = 1.425292 (0.430 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:29:00 INFO: Finished STEP 6300/10000, loss = 1.034292 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:29:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:29:03 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:29:03 INFO: 87.63\t83.89\t84.77\n",
            "2023-05-13 21:29:03 INFO: step 6300: train_loss = 1.409606, dev_score = 0.8763\n",
            "2023-05-13 21:29:13 INFO: Finished STEP 6320/10000, loss = 1.404496 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:29:26 INFO: Finished STEP 6340/10000, loss = 0.976313 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:29:36 INFO: Finished STEP 6360/10000, loss = 7.817523 (0.624 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:29:48 INFO: Finished STEP 6380/10000, loss = 0.900499 (0.512 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:30:00 INFO: Finished STEP 6400/10000, loss = 1.413696 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:30:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:30:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:30:04 INFO: 87.70\t83.98\t84.86\n",
            "2023-05-13 21:30:04 INFO: step 6400: train_loss = 1.369581, dev_score = 0.8770\n",
            "2023-05-13 21:30:15 INFO: Finished STEP 6420/10000, loss = 1.130439 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:30:25 INFO: Finished STEP 6440/10000, loss = 1.450027 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:30:35 INFO: Finished STEP 6460/10000, loss = 0.957731 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:30:48 INFO: Finished STEP 6480/10000, loss = 1.247999 (0.488 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:30:59 INFO: Finished STEP 6500/10000, loss = 1.167722 (0.413 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:30:59 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:31:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:31:04 INFO: 87.81\t84.15\t85.03\n",
            "2023-05-13 21:31:04 INFO: step 6500: train_loss = 1.410242, dev_score = 0.8781\n",
            "2023-05-13 21:31:04 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:31:04 INFO: new best model saved.\n",
            "2023-05-13 21:31:15 INFO: Finished STEP 6520/10000, loss = 1.408631 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:31:27 INFO: Finished STEP 6540/10000, loss = 1.247183 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:31:37 INFO: Finished STEP 6560/10000, loss = 1.269541 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:31:49 INFO: Finished STEP 6580/10000, loss = 3.623843 (0.101 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:32:00 INFO: Finished STEP 6600/10000, loss = 1.184930 (0.469 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:32:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:32:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:32:05 INFO: 87.73\t84.08\t84.97\n",
            "2023-05-13 21:32:05 INFO: step 6600: train_loss = 1.433383, dev_score = 0.8773\n",
            "2023-05-13 21:32:15 INFO: Finished STEP 6620/10000, loss = 1.120235 (0.471 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:32:28 INFO: Finished STEP 6640/10000, loss = 1.922422 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:32:38 INFO: Finished STEP 6660/10000, loss = 1.091413 (0.417 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:32:49 INFO: Finished STEP 6680/10000, loss = 0.991133 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:33:00 INFO: Finished STEP 6700/10000, loss = 0.936925 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:33:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:33:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:33:04 INFO: 87.82\t84.14\t85.05\n",
            "2023-05-13 21:33:04 INFO: step 6700: train_loss = 1.368526, dev_score = 0.8782\n",
            "2023-05-13 21:33:05 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:33:05 INFO: new best model saved.\n",
            "2023-05-13 21:33:16 INFO: Finished STEP 6720/10000, loss = 0.857463 (0.513 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:33:28 INFO: Finished STEP 6740/10000, loss = 1.163597 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:33:38 INFO: Finished STEP 6760/10000, loss = 1.143231 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:33:49 INFO: Finished STEP 6780/10000, loss = 0.837103 (0.488 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:34:02 INFO: Finished STEP 6800/10000, loss = 2.114416 (0.423 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:34:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:34:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:34:05 INFO: 87.87\t84.21\t85.11\n",
            "2023-05-13 21:34:05 INFO: step 6800: train_loss = 1.376945, dev_score = 0.8787\n",
            "2023-05-13 21:34:05 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:34:05 INFO: new best model saved.\n",
            "2023-05-13 21:34:18 INFO: Finished STEP 6820/10000, loss = 0.985423 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:34:28 INFO: Finished STEP 6840/10000, loss = 1.432887 (0.442 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:34:40 INFO: Finished STEP 6860/10000, loss = 1.383436 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:34:50 INFO: Finished STEP 6880/10000, loss = 1.103437 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:35:02 INFO: Finished STEP 6900/10000, loss = 1.360876 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:35:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:35:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:35:06 INFO: 87.70\t84.03\t84.92\n",
            "2023-05-13 21:35:06 INFO: step 6900: train_loss = 1.380645, dev_score = 0.8770\n",
            "2023-05-13 21:35:17 INFO: Finished STEP 6920/10000, loss = 1.568177 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:35:27 INFO: Finished STEP 6940/10000, loss = 1.353855 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:35:40 INFO: Finished STEP 6960/10000, loss = 1.223768 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:35:51 INFO: Finished STEP 6980/10000, loss = 1.252081 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:36:01 INFO: Finished STEP 7000/10000, loss = 1.262193 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:36:01 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:36:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:36:07 INFO: 87.60\t83.94\t84.83\n",
            "2023-05-13 21:36:07 INFO: step 7000: train_loss = 1.412990, dev_score = 0.8760\n",
            "2023-05-13 21:36:18 INFO: Finished STEP 7020/10000, loss = 1.712153 (0.556 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:36:28 INFO: Finished STEP 7040/10000, loss = 1.113799 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:36:40 INFO: Finished STEP 7060/10000, loss = 0.961039 (0.420 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:36:50 INFO: Finished STEP 7080/10000, loss = 1.268478 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:37:02 INFO: Finished STEP 7100/10000, loss = 1.593932 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:37:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:37:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:37:07 INFO: 87.64\t84.06\t84.92\n",
            "2023-05-13 21:37:07 INFO: step 7100: train_loss = 1.350171, dev_score = 0.8764\n",
            "2023-05-13 21:37:17 INFO: Finished STEP 7120/10000, loss = 1.186057 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:37:30 INFO: Finished STEP 7140/10000, loss = 1.079174 (0.414 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:37:40 INFO: Finished STEP 7160/10000, loss = 0.714548 (0.691 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:37:52 INFO: Finished STEP 7180/10000, loss = 2.067402 (0.419 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:38:02 INFO: Finished STEP 7200/10000, loss = 0.875398 (0.433 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:38:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:38:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:38:06 INFO: 87.82\t84.19\t85.01\n",
            "2023-05-13 21:38:06 INFO: step 7200: train_loss = 1.383199, dev_score = 0.8782\n",
            "2023-05-13 21:38:17 INFO: Finished STEP 7220/10000, loss = 0.988815 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:38:29 INFO: Finished STEP 7240/10000, loss = 1.113204 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:38:40 INFO: Finished STEP 7260/10000, loss = 1.053745 (0.459 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:38:51 INFO: Finished STEP 7280/10000, loss = 1.209868 (0.417 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:39:02 INFO: Finished STEP 7300/10000, loss = 1.628320 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:39:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:39:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:39:07 INFO: 87.91\t84.25\t85.11\n",
            "2023-05-13 21:39:07 INFO: step 7300: train_loss = 1.413172, dev_score = 0.8791\n",
            "2023-05-13 21:39:07 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:39:07 INFO: new best model saved.\n",
            "2023-05-13 21:39:20 INFO: Finished STEP 7320/10000, loss = 1.484968 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:39:30 INFO: Finished STEP 7340/10000, loss = 1.308305 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:39:40 INFO: Finished STEP 7360/10000, loss = 0.895501 (0.445 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:39:52 INFO: Finished STEP 7380/10000, loss = 1.224695 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:40:02 INFO: Finished STEP 7400/10000, loss = 1.317582 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:40:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:40:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:40:06 INFO: 87.97\t84.35\t85.24\n",
            "2023-05-13 21:40:06 INFO: step 7400: train_loss = 1.359512, dev_score = 0.8797\n",
            "2023-05-13 21:40:06 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:40:06 INFO: new best model saved.\n",
            "2023-05-13 21:40:19 INFO: Finished STEP 7420/10000, loss = 1.222122 (0.474 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:40:30 INFO: Finished STEP 7440/10000, loss = 1.196772 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:40:41 INFO: Finished STEP 7460/10000, loss = 1.005708 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:40:52 INFO: Finished STEP 7480/10000, loss = 1.449533 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:41:03 INFO: Finished STEP 7500/10000, loss = 1.245419 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:41:03 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:41:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:41:08 INFO: 87.94\t84.33\t85.16\n",
            "2023-05-13 21:41:08 INFO: step 7500: train_loss = 1.315077, dev_score = 0.8794\n",
            "2023-05-13 21:41:21 INFO: Finished STEP 7520/10000, loss = 1.252602 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:41:31 INFO: Finished STEP 7540/10000, loss = 0.885668 (0.481 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:41:42 INFO: Finished STEP 7560/10000, loss = 0.928268 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:41:53 INFO: Finished STEP 7580/10000, loss = 1.180202 (0.466 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:42:04 INFO: Finished STEP 7600/10000, loss = 1.011050 (0.424 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:42:04 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:42:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:42:08 INFO: 88.08\t84.53\t85.37\n",
            "2023-05-13 21:42:08 INFO: step 7600: train_loss = 1.382570, dev_score = 0.8808\n",
            "2023-05-13 21:42:09 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 21:42:09 INFO: new best model saved.\n",
            "2023-05-13 21:42:20 INFO: Finished STEP 7620/10000, loss = 0.512650 (1.440 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:42:31 INFO: Finished STEP 7640/10000, loss = 1.437299 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:42:43 INFO: Finished STEP 7660/10000, loss = 0.502250 (1.437 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:42:54 INFO: Finished STEP 7680/10000, loss = 0.990097 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:43:05 INFO: Finished STEP 7700/10000, loss = 1.272950 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:43:05 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:43:09 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:43:09 INFO: 87.81\t84.34\t85.08\n",
            "2023-05-13 21:43:09 INFO: step 7700: train_loss = 1.325215, dev_score = 0.8781\n",
            "2023-05-13 21:43:20 INFO: Finished STEP 7720/10000, loss = 0.000335 (0.096 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:43:31 INFO: Finished STEP 7740/10000, loss = 1.110895 (0.416 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:43:42 INFO: Finished STEP 7760/10000, loss = 2.182178 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:43:54 INFO: Finished STEP 7780/10000, loss = 1.296380 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:44:04 INFO: Finished STEP 7800/10000, loss = 0.796783 (0.446 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:44:04 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:44:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:44:10 INFO: 87.85\t84.28\t85.11\n",
            "2023-05-13 21:44:10 INFO: step 7800: train_loss = 1.352566, dev_score = 0.8785\n",
            "2023-05-13 21:44:22 INFO: Finished STEP 7820/10000, loss = 1.142780 (0.419 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:44:32 INFO: Finished STEP 7840/10000, loss = 1.121960 (0.433 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:44:44 INFO: Finished STEP 7860/10000, loss = 2.134519 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:44:55 INFO: Finished STEP 7880/10000, loss = 0.655430 (1.443 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:45:06 INFO: Finished STEP 7900/10000, loss = 1.018512 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:45:06 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:45:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:45:10 INFO: 87.80\t84.12\t84.96\n",
            "2023-05-13 21:45:10 INFO: step 7900: train_loss = 1.353676, dev_score = 0.8780\n",
            "2023-05-13 21:45:21 INFO: Finished STEP 7920/10000, loss = 0.762807 (0.684 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:45:31 INFO: Finished STEP 7940/10000, loss = 1.399621 (0.437 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:45:44 INFO: Finished STEP 7960/10000, loss = 0.930773 (0.429 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:45:54 INFO: Finished STEP 7980/10000, loss = 0.885904 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:46:05 INFO: Finished STEP 8000/10000, loss = 1.491124 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:46:05 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:46:09 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:46:09 INFO: 87.92\t84.36\t85.22\n",
            "2023-05-13 21:46:09 INFO: step 8000: train_loss = 1.366335, dev_score = 0.8792\n",
            "2023-05-13 21:46:20 INFO: Finished STEP 8020/10000, loss = 1.076383 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:46:32 INFO: Finished STEP 8040/10000, loss = 1.547151 (0.506 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:46:43 INFO: Finished STEP 8060/10000, loss = 1.078032 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:46:55 INFO: Finished STEP 8080/10000, loss = 1.226367 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:47:05 INFO: Finished STEP 8100/10000, loss = 1.210612 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:47:05 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:47:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:47:11 INFO: 87.85\t84.20\t85.12\n",
            "2023-05-13 21:47:11 INFO: step 8100: train_loss = 1.350786, dev_score = 0.8785\n",
            "2023-05-13 21:47:23 INFO: Finished STEP 8120/10000, loss = 1.165940 (0.493 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:47:33 INFO: Finished STEP 8140/10000, loss = 1.902572 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:47:45 INFO: Finished STEP 8160/10000, loss = 1.219557 (0.436 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:47:55 INFO: Finished STEP 8180/10000, loss = 1.558572 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:48:06 INFO: Finished STEP 8200/10000, loss = 1.073714 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:48:06 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:48:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:48:10 INFO: 87.93\t84.28\t85.20\n",
            "2023-05-13 21:48:10 INFO: step 8200: train_loss = 1.371349, dev_score = 0.8793\n",
            "2023-05-13 21:48:21 INFO: Finished STEP 8220/10000, loss = 1.524884 (0.501 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:48:33 INFO: Finished STEP 8240/10000, loss = 1.151718 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:48:44 INFO: Finished STEP 8260/10000, loss = 0.791354 (0.492 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:48:55 INFO: Finished STEP 8280/10000, loss = 1.133864 (0.468 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:49:06 INFO: Finished STEP 8300/10000, loss = 3.932057 (0.101 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:49:06 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:49:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:49:11 INFO: 87.88\t84.17\t85.11\n",
            "2023-05-13 21:49:11 INFO: step 8300: train_loss = 1.340830, dev_score = 0.8788\n",
            "2023-05-13 21:49:22 INFO: Finished STEP 8320/10000, loss = 1.182023 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:49:35 INFO: Finished STEP 8340/10000, loss = 1.473139 (0.437 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:49:46 INFO: Finished STEP 8360/10000, loss = 1.344385 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:49:56 INFO: Finished STEP 8380/10000, loss = 3.524260 (0.100 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:50:06 INFO: Finished STEP 8400/10000, loss = 1.199225 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:50:06 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:50:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:50:11 INFO: 87.78\t84.23\t85.08\n",
            "2023-05-13 21:50:11 INFO: step 8400: train_loss = 1.324753, dev_score = 0.8778\n",
            "2023-05-13 21:50:24 INFO: Finished STEP 8420/10000, loss = 1.149363 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:50:34 INFO: Finished STEP 8440/10000, loss = 0.928139 (0.424 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:50:45 INFO: Finished STEP 8460/10000, loss = 1.075327 (0.452 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:50:57 INFO: Finished STEP 8480/10000, loss = 0.992475 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:51:08 INFO: Finished STEP 8500/10000, loss = 1.224659 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:51:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:51:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:51:12 INFO: 87.69\t84.08\t84.99\n",
            "2023-05-13 21:51:12 INFO: step 8500: train_loss = 1.377253, dev_score = 0.8769\n",
            "2023-05-13 21:51:23 INFO: Finished STEP 8520/10000, loss = 1.671992 (0.529 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:51:33 INFO: Finished STEP 8540/10000, loss = 1.256042 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:51:45 INFO: Finished STEP 8560/10000, loss = 2.002849 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:51:55 INFO: Finished STEP 8580/10000, loss = 1.029946 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:52:07 INFO: Finished STEP 8600/10000, loss = 0.804808 (0.515 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:52:07 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:52:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:52:13 INFO: 87.76\t84.07\t84.96\n",
            "2023-05-13 21:52:13 INFO: step 8600: train_loss = 1.297288, dev_score = 0.8776\n",
            "2023-05-13 21:52:24 INFO: Finished STEP 8620/10000, loss = 1.098283 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:52:35 INFO: Finished STEP 8640/10000, loss = 0.807228 (0.486 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:52:47 INFO: Finished STEP 8660/10000, loss = 0.836938 (0.681 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:52:59 INFO: Finished STEP 8680/10000, loss = 1.235363 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:53:08 INFO: Finished STEP 8700/10000, loss = 1.046926 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:53:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:53:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:53:13 INFO: 87.82\t84.18\t85.02\n",
            "2023-05-13 21:53:13 INFO: step 8700: train_loss = 1.343454, dev_score = 0.8782\n",
            "2023-05-13 21:53:25 INFO: Finished STEP 8720/10000, loss = 0.937492 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:53:35 INFO: Finished STEP 8740/10000, loss = 1.699640 (0.417 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:53:45 INFO: Finished STEP 8760/10000, loss = 3.814269 (0.454 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:53:57 INFO: Finished STEP 8780/10000, loss = 1.329575 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:54:08 INFO: Finished STEP 8800/10000, loss = 1.046211 (0.458 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:54:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:54:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:54:12 INFO: 88.01\t84.42\t85.29\n",
            "2023-05-13 21:54:12 INFO: step 8800: train_loss = 1.598500, dev_score = 0.8801\n",
            "2023-05-13 21:54:24 INFO: Finished STEP 8820/10000, loss = 1.428545 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:54:35 INFO: Finished STEP 8840/10000, loss = 2.046346 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:54:47 INFO: Finished STEP 8860/10000, loss = 1.564474 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:54:58 INFO: Finished STEP 8880/10000, loss = 1.439720 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:55:08 INFO: Finished STEP 8900/10000, loss = 1.166112 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:55:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:55:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:55:14 INFO: 88.07\t84.58\t85.41\n",
            "2023-05-13 21:55:14 INFO: step 8900: train_loss = 1.832316, dev_score = 0.8807\n",
            "2023-05-13 21:55:24 INFO: Finished STEP 8920/10000, loss = 1.620398 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:55:36 INFO: Finished STEP 8940/10000, loss = 1.419571 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:55:46 INFO: Finished STEP 8960/10000, loss = 1.234887 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:55:57 INFO: Finished STEP 8980/10000, loss = 0.923017 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:56:09 INFO: Finished STEP 9000/10000, loss = 1.393364 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:56:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:56:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:56:13 INFO: 88.00\t84.48\t85.31\n",
            "2023-05-13 21:56:13 INFO: step 9000: train_loss = 1.326370, dev_score = 0.8800\n",
            "2023-05-13 21:56:23 INFO: Finished STEP 9020/10000, loss = 3.464340 (0.100 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:56:35 INFO: Finished STEP 9040/10000, loss = 1.840179 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:56:46 INFO: Finished STEP 9060/10000, loss = 1.316784 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:56:58 INFO: Finished STEP 9080/10000, loss = 1.184412 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:57:10 INFO: Finished STEP 9100/10000, loss = 1.172135 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:57:10 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:57:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:57:15 INFO: 88.01\t84.40\t85.20\n",
            "2023-05-13 21:57:15 INFO: step 9100: train_loss = 1.309232, dev_score = 0.8801\n",
            "2023-05-13 21:57:25 INFO: Finished STEP 9120/10000, loss = 1.530350 (0.497 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:57:35 INFO: Finished STEP 9140/10000, loss = 1.254210 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:57:46 INFO: Finished STEP 9160/10000, loss = 1.168994 (0.419 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:57:58 INFO: Finished STEP 9180/10000, loss = 0.949209 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:58:09 INFO: Finished STEP 9200/10000, loss = 1.189593 (0.478 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:58:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:58:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:58:12 INFO: 88.02\t84.44\t85.29\n",
            "2023-05-13 21:58:12 INFO: step 9200: train_loss = 1.365973, dev_score = 0.8802\n",
            "2023-05-13 21:58:23 INFO: Finished STEP 9220/10000, loss = 1.493250 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:58:37 INFO: Finished STEP 9240/10000, loss = 0.958819 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:58:47 INFO: Finished STEP 9260/10000, loss = 1.040985 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:58:58 INFO: Finished STEP 9280/10000, loss = 0.751841 (0.480 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:59:09 INFO: Finished STEP 9300/10000, loss = 0.959305 (0.419 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:59:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 21:59:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 21:59:13 INFO: 87.94\t84.19\t85.03\n",
            "2023-05-13 21:59:13 INFO: step 9300: train_loss = 1.380389, dev_score = 0.8794\n",
            "2023-05-13 21:59:25 INFO: Finished STEP 9320/10000, loss = 0.773407 (0.684 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:59:35 INFO: Finished STEP 9340/10000, loss = 1.409438 (0.436 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:59:46 INFO: Finished STEP 9360/10000, loss = 1.081143 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-13 21:59:58 INFO: Finished STEP 9380/10000, loss = 1.383669 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:00:09 INFO: Finished STEP 9400/10000, loss = 1.464849 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:00:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:00:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:00:15 INFO: 88.03\t84.45\t85.25\n",
            "2023-05-13 22:00:15 INFO: step 9400: train_loss = 1.302879, dev_score = 0.8803\n",
            "2023-05-13 22:00:26 INFO: Finished STEP 9420/10000, loss = 1.256844 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:00:37 INFO: Finished STEP 9440/10000, loss = 1.328505 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:00:49 INFO: Finished STEP 9460/10000, loss = 2.107450 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:00:59 INFO: Finished STEP 9480/10000, loss = 1.431475 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:01:10 INFO: Finished STEP 9500/10000, loss = 1.264278 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:01:10 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:01:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:01:14 INFO: 87.93\t84.35\t85.19\n",
            "2023-05-13 22:01:14 INFO: step 9500: train_loss = 1.301875, dev_score = 0.8793\n",
            "2023-05-13 22:01:25 INFO: Finished STEP 9520/10000, loss = 1.203969 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:01:36 INFO: Finished STEP 9540/10000, loss = 0.745046 (0.704 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:01:48 INFO: Finished STEP 9560/10000, loss = 0.879087 (0.446 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:01:59 INFO: Finished STEP 9580/10000, loss = 0.659937 (1.272 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:02:09 INFO: Finished STEP 9600/10000, loss = 0.923910 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:02:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:02:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:02:13 INFO: 88.14\t84.55\t85.34\n",
            "2023-05-13 22:02:13 INFO: step 9600: train_loss = 1.366509, dev_score = 0.8814\n",
            "2023-05-13 22:02:13 INFO: Model saved to ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 22:02:13 INFO: new best model saved.\n",
            "2023-05-13 22:02:24 INFO: Finished STEP 9620/10000, loss = 1.067340 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:02:37 INFO: Finished STEP 9640/10000, loss = 1.127350 (0.423 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:02:49 INFO: Finished STEP 9660/10000, loss = 1.046657 (0.457 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:02:59 INFO: Finished STEP 9680/10000, loss = 0.923893 (0.436 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:03:11 INFO: Finished STEP 9700/10000, loss = 1.337571 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:03:11 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:03:16 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:03:16 INFO: 87.91\t84.32\t85.11\n",
            "2023-05-13 22:03:16 INFO: step 9700: train_loss = 1.302091, dev_score = 0.8791\n",
            "2023-05-13 22:03:25 INFO: Finished STEP 9720/10000, loss = 1.459485 (0.433 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:03:37 INFO: Finished STEP 9740/10000, loss = 1.098559 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:03:49 INFO: Finished STEP 9760/10000, loss = 1.474581 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:03:59 INFO: Finished STEP 9780/10000, loss = 1.495307 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:04:11 INFO: Finished STEP 9800/10000, loss = 1.440013 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:04:11 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:04:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:04:15 INFO: 88.00\t84.36\t85.15\n",
            "2023-05-13 22:04:15 INFO: step 9800: train_loss = 1.301847, dev_score = 0.8800\n",
            "2023-05-13 22:04:26 INFO: Finished STEP 9820/10000, loss = 1.369552 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:04:37 INFO: Finished STEP 9840/10000, loss = 1.128193 (0.476 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:04:47 INFO: Finished STEP 9860/10000, loss = 4.717268 (0.106 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:04:58 INFO: Finished STEP 9880/10000, loss = 1.112529 (0.440 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:05:11 INFO: Finished STEP 9900/10000, loss = 0.926353 (0.445 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:05:11 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:05:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:05:14 INFO: 88.07\t84.48\t85.28\n",
            "2023-05-13 22:05:14 INFO: step 9900: train_loss = 1.335017, dev_score = 0.8807\n",
            "2023-05-13 22:05:27 INFO: Finished STEP 9920/10000, loss = 1.074733 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:05:37 INFO: Finished STEP 9940/10000, loss = 1.408414 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:05:48 INFO: Finished STEP 9960/10000, loss = 1.684071 (0.546 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:06:00 INFO: Finished STEP 9980/10000, loss = 0.772184 (0.671 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:06:10 INFO: Finished STEP 10000/10000, loss = 1.302424 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:06:10 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:06:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:06:15 INFO: 88.04\t84.53\t85.32\n",
            "2023-05-13 22:06:15 INFO: step 10000: train_loss = 1.312680, dev_score = 0.8804\n",
            "2023-05-13 22:06:15 INFO: Training ended with 10000 steps.\n",
            "2023-05-13 22:06:15 INFO: Best dev F1 = 88.14, at iteration = 9600\n",
            "2023-05-13 22:06:15 INFO: Using default pretrain for en:ewt, found in /root/stanza_resources/en/pretrain/ewt.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-13 22:06:15 INFO: Running dev depparse for UD_English-EWT with args ['--wordvec_dir', 'extern_data/wordvec', '--eval_file', 'data/depparse/en_ewt.dev.in.conllu', '--output_file', '/tmp/tmpp1q2jck_', '--gold_file', 'data/depparse/en_ewt.dev.gold.conllu', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/ewt.pt', '--max_steps', '10000', '--cuda', '--save_dir', './output_stanza_en', '--save_name', 'en_ewt_parser.pt']\n",
            "2023-05-13 22:06:15 INFO: Running parser in predict mode\n",
            "2023-05-13 22:06:15 INFO: Loading model from: ./output_stanza_en/en_ewt_parser.pt\n",
            "2023-05-13 22:06:15 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/ewt.pt\n",
            "2023-05-13 22:06:15 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 22:06:16 DEBUG: 6 batches created.\n",
            "2023-05-13 22:06:16 INFO: Start evaluation...\n",
            "2023-05-13 22:06:20 INFO: F1 scores for each dependency:\n",
            "  Note that unlabeled attachment errors hurt the labeled attachment scores\n",
            "         acl: p 0.7320 r 0.6707 f1 0.7000 (167 actual)\n",
            "   acl:relcl: p 0.7981 r 0.7650 f1 0.7812 (217 actual)\n",
            "       advcl: p 0.7283 r 0.7222 f1 0.7252 (360 actual)\n",
            " advcl:relcl: p 0.4000 r 0.2222 f1 0.2857 (9 actual)\n",
            "      advmod: p 0.8735 r 0.8650 f1 0.8692 (1341 actual)\n",
            "        amod: p 0.8961 r 0.9055 f1 0.9008 (1334 actual)\n",
            "       appos: p 0.5600 r 0.5632 f1 0.5616 (174 actual)\n",
            "         aux: p 0.9620 r 0.9774 f1 0.9696 (751 actual)\n",
            "    aux:pass: p 0.9379 r 0.9497 f1 0.9437 (159 actual)\n",
            "        case: p 0.9322 r 0.9507 f1 0.9414 (2010 actual)\n",
            "          cc: p 0.9196 r 0.9173 f1 0.9185 (786 actual)\n",
            "  cc:preconj: p 0.8750 r 0.5000 f1 0.6364 (14 actual)\n",
            "       ccomp: p 0.7639 r 0.8168 f1 0.7895 (202 actual)\n",
            "    compound: p 0.7943 r 0.7985 f1 0.7964 (948 actual)\n",
            "compound:prt: p 0.7463 r 0.6757 f1 0.7092 (74 actual)\n",
            "        conj: p 0.7701 r 0.7768 f1 0.7734 (914 actual)\n",
            "         cop: p 0.9392 r 0.9407 f1 0.9400 (624 actual)\n",
            "       csubj: p 0.5500 r 0.5641 f1 0.5570 (39 actual)\n",
            " csubj:outer: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "         dep: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "         det: p 0.9710 r 0.9715 f1 0.9713 (1827 actual)\n",
            "  det:predet: p 0.8889 r 1.0000 f1 0.9412 (24 actual)\n",
            "   discourse: p 0.7885 r 0.6613 f1 0.7193 (124 actual)\n",
            "  dislocated: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "        expl: p 0.8765 r 0.8256 f1 0.8503 (86 actual)\n",
            "       fixed: p 0.9492 r 0.9492 f1 0.9492 (59 actual)\n",
            "        flat: p 0.8403 r 0.8969 f1 0.8677 (223 actual)\n",
            "flat:foreign: p 0.0000 r 0.0000 f1 0.0000 (13 actual)\n",
            "    goeswith: p 0.9091 r 0.9091 f1 0.9091 (22 actual)\n",
            "        iobj: p 0.8939 r 0.8082 f1 0.8489 (73 actual)\n",
            "        list: p 0.2787 r 0.2267 f1 0.2500 (75 actual)\n",
            "        mark: p 0.9570 r 0.9406 f1 0.9488 (758 actual)\n",
            "        nmod: p 0.8130 r 0.7559 f1 0.7834 (811 actual)\n",
            "  nmod:npmod: p 0.8000 r 0.4444 f1 0.5714 (9 actual)\n",
            "   nmod:poss: p 0.9589 r 0.9638 f1 0.9613 (387 actual)\n",
            "   nmod:tmod: p 0.6774 r 0.6176 f1 0.6462 (34 actual)\n",
            "       nsubj: p 0.9362 r 0.9400 f1 0.9381 (1966 actual)\n",
            " nsubj:outer: p 0.6250 r 0.6818 f1 0.6522 (22 actual)\n",
            "  nsubj:pass: p 0.8710 r 0.9000 f1 0.8852 (150 actual)\n",
            "      nummod: p 0.8592 r 0.8686 f1 0.8639 (274 actual)\n",
            "         obj: p 0.8963 r 0.9325 f1 0.9140 (1214 actual)\n",
            "         obl: p 0.7775 r 0.8287 f1 0.8022 (1033 actual)\n",
            "   obl:npmod: p 0.6944 r 0.4902 f1 0.5747 (51 actual)\n",
            "    obl:tmod: p 0.7164 r 0.7500 f1 0.7328 (64 actual)\n",
            "      orphan: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "   parataxis: p 0.6162 r 0.4880 f1 0.5446 (250 actual)\n",
            "       punct: p 0.8615 r 0.8649 f1 0.8632 (3064 actual)\n",
            "  reparandum: p 0.0000 r 0.0000 f1 0.0000 (7 actual)\n",
            "        root: p 0.9390 r 0.9390 f1 0.9390 (2001 actual)\n",
            "    vocative: p 0.5455 r 0.5455 f1 0.5455 (22 actual)\n",
            "       xcomp: p 0.8613 r 0.8750 f1 0.8681 (376 actual)\n",
            "2023-05-13 22:06:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:06:21 INFO: 88.14\t84.55\t85.34\n",
            "2023-05-13 22:06:21 INFO: Parser score:\n",
            "2023-05-13 22:06:21 INFO: en_ewt 88.14\n",
            "2023-05-13 22:06:24 INFO: Finished running dev set on\n",
            "UD_English-EWT\n",
            "  UAS   LAS  CLAS  MLAS  BLEX\n",
            "90.48 88.14 85.34 84.55 85.34\n",
            "6078.980213403702\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "!python3 -m stanza.utils.training.run_depparse --train UD_English-EWT --save_dir ./output_stanza_en --max_steps 10000 --cuda\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spanish"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYS5fhOiKYEr",
        "outputId": "d4725e1d-7173-472e-e4f6-426ebc7112fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-13 22:10:09 INFO: Datasets program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/datasets/prepare_depparse_treebank.py UD_Spanish-GSD\n",
            "2023-05-13 22:10:09 DEBUG: Downloading resource file...\n",
            "\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0% 0.00/30.0k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 69.6MB/s]        \n",
            "2023-05-13 22:10:09 DEBUG: Processing parameter \"processors\"...\n",
            "2023-05-13 22:10:09 DEBUG: Found pos: gsd.\n",
            "2023-05-13 22:10:09 DEBUG: Find dependency backward_charlm: newswiki.\n",
            "2023-05-13 22:10:09 DEBUG: Find dependency forward_charlm: newswiki.\n",
            "2023-05-13 22:10:09 DEBUG: Find dependency pretrain: gsd.\n",
            "2023-05-13 22:10:09 INFO: Downloading these customized packages for language: es (Spanish)...\n",
            "==============================\n",
            "| Processor       | Package  |\n",
            "------------------------------\n",
            "| pos             | gsd      |\n",
            "| backward_charlm | newswiki |\n",
            "| forward_charlm  | newswiki |\n",
            "| pretrain        | gsd      |\n",
            "==============================\n",
            "\n",
            "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/pos/gsd.pt: 100% 34.4M/34.4M [00:01<00:00, 24.8MB/s]\n",
            "2023-05-13 22:10:12 INFO: File exists: /root/stanza_resources/es/backward_charlm/newswiki.pt\n",
            "2023-05-13 22:10:12 INFO: File exists: /root/stanza_resources/es/forward_charlm/newswiki.pt\n",
            "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/pretrain/gsd.pt: 100% 107M/107M [00:03<00:00, 34.6MB/s]\n",
            "2023-05-13 22:10:16 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2023-05-13 22:10:16 INFO: Using default pretrain for es:gsd, found in /root/stanza_resources/es/pretrain/gsd.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-13 22:10:16 INFO: Using model /root/stanza_resources/es/forward_charlm/newswiki.pt for forward charlm\n",
            "2023-05-13 22:10:16 INFO: Using model /root/stanza_resources/es/backward_charlm/newswiki.pt for backward charlm\n",
            "Preparing data for UD_Spanish-GSD: es_gsd, es\n",
            "Reading from ./UD_Spanish-GSD/es_gsd-ud-train.conllu and writing to /tmp/tmpjpwrv6rv/es_gsd.train.gold.conllu\n",
            "Augmented 146 quotes: Counter({'\"\"': 19, '″″': 18, '””': 17, '„”': 16, '《》': 15, '「」': 15, '““': 14, '«»': 13, '„“': 11, '»«': 8})\n",
            "Swapped 'w1, w2' for 'w1 ,w2' 190 times\n",
            "Added 219 new sentences with asdf, zzzz -> asdf,zzzz\n",
            "Added 13 sentences with the leading ¿ removed\n",
            "Reading from ./UD_Spanish-GSD/es_gsd-ud-dev.conllu and writing to /tmp/tmpjpwrv6rv/es_gsd.dev.gold.conllu\n",
            "Reading from ./UD_Spanish-GSD/es_gsd-ud-test.conllu and writing to /tmp/tmpjpwrv6rv/es_gsd.test.gold.conllu\n",
            "2023-05-13 22:10:21 INFO: Running tagger to retag /tmp/tmpjpwrv6rv/es_gsd.train.gold.conllu to data/depparse/es_gsd.train.in.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'es', '--shorthand', 'es_gsd', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/es/pos', '--save_name', 'gsd.pt', '--wordvec_pretrain_file', '/root/stanza_resources/es/pretrain/gsd.pt', '--charlm', '--charlm_shorthand', 'es_newswiki', '--charlm_forward_file', '/root/stanza_resources/es/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/es/backward_charlm/newswiki.pt', '--eval_file', '/tmp/tmpjpwrv6rv/es_gsd.train.gold.conllu', '--gold_file', '/tmp/tmpjpwrv6rv/es_gsd.train.gold.conllu', '--output_file', 'data/depparse/es_gsd.train.in.conllu']\n",
            "2023-05-13 22:10:21 INFO: Running tagger in predict mode\n",
            "2023-05-13 22:10:21 INFO: Loading model from: /root/stanza_resources/es/pos/gsd.pt\n",
            "2023-05-13 22:10:21 DEBUG: Loaded pretrain from /root/stanza_resources/es/pretrain/gsd.pt\n",
            "2023-05-13 22:10:21 DEBUG: POS model loading charmodels: /root/stanza_resources/es/forward_charlm/newswiki.pt and /root/stanza_resources/es/backward_charlm/newswiki.pt\n",
            "2023-05-13 22:10:21 DEBUG: Loading charlm from /root/stanza_resources/es/forward_charlm/newswiki.pt\n",
            "2023-05-13 22:10:22 DEBUG: Loading charlm from /root/stanza_resources/es/backward_charlm/newswiki.pt\n",
            "2023-05-13 22:10:24 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 22:10:39 DEBUG: 79 batches created.\n",
            "2023-05-13 22:10:39 INFO: Start evaluation...\n",
            "2023-05-13 22:11:35 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-13 22:11:35 INFO: 98.22\t100.00\t97.73\t96.50\n",
            "2023-05-13 22:11:35 INFO: Tagger score:\n",
            "2023-05-13 22:11:35 INFO: es_gsd 96.50\n",
            "2023-05-13 22:11:36 INFO: Running tagger to retag /tmp/tmpjpwrv6rv/es_gsd.dev.gold.conllu to data/depparse/es_gsd.dev.gold.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'es', '--shorthand', 'es_gsd', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/es/pos', '--save_name', 'gsd.pt', '--wordvec_pretrain_file', '/root/stanza_resources/es/pretrain/gsd.pt', '--charlm', '--charlm_shorthand', 'es_newswiki', '--charlm_forward_file', '/root/stanza_resources/es/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/es/backward_charlm/newswiki.pt', '--eval_file', '/tmp/tmpjpwrv6rv/es_gsd.dev.gold.conllu', '--gold_file', '/tmp/tmpjpwrv6rv/es_gsd.dev.gold.conllu', '--output_file', 'data/depparse/es_gsd.dev.gold.conllu']\n",
            "2023-05-13 22:11:36 INFO: Running tagger in predict mode\n",
            "2023-05-13 22:11:36 INFO: Loading model from: /root/stanza_resources/es/pos/gsd.pt\n",
            "2023-05-13 22:11:36 DEBUG: Loaded pretrain from /root/stanza_resources/es/pretrain/gsd.pt\n",
            "2023-05-13 22:11:36 DEBUG: POS model loading charmodels: /root/stanza_resources/es/forward_charlm/newswiki.pt and /root/stanza_resources/es/backward_charlm/newswiki.pt\n",
            "2023-05-13 22:11:36 DEBUG: Loading charlm from /root/stanza_resources/es/forward_charlm/newswiki.pt\n",
            "2023-05-13 22:11:36 DEBUG: Loading charlm from /root/stanza_resources/es/backward_charlm/newswiki.pt\n",
            "2023-05-13 22:11:36 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 22:11:37 DEBUG: 8 batches created.\n",
            "2023-05-13 22:11:37 INFO: Start evaluation...\n",
            "2023-05-13 22:11:47 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-13 22:11:47 INFO: 97.18\t100.00\t96.75\t94.83\n",
            "2023-05-13 22:11:47 INFO: Tagger score:\n",
            "2023-05-13 22:11:47 INFO: es_gsd 94.83\n",
            "Copying from data/depparse/es_gsd.dev.gold.conllu to data/depparse/es_gsd.dev.in.conllu\n",
            "2023-05-13 22:11:47 INFO: Running tagger to retag /tmp/tmpjpwrv6rv/es_gsd.test.gold.conllu to data/depparse/es_gsd.test.gold.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'es', '--shorthand', 'es_gsd', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/es/pos', '--save_name', 'gsd.pt', '--wordvec_pretrain_file', '/root/stanza_resources/es/pretrain/gsd.pt', '--charlm', '--charlm_shorthand', 'es_newswiki', '--charlm_forward_file', '/root/stanza_resources/es/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/es/backward_charlm/newswiki.pt', '--eval_file', '/tmp/tmpjpwrv6rv/es_gsd.test.gold.conllu', '--gold_file', '/tmp/tmpjpwrv6rv/es_gsd.test.gold.conllu', '--output_file', 'data/depparse/es_gsd.test.gold.conllu']\n",
            "2023-05-13 22:11:47 INFO: Running tagger in predict mode\n",
            "2023-05-13 22:11:47 INFO: Loading model from: /root/stanza_resources/es/pos/gsd.pt\n",
            "2023-05-13 22:11:47 DEBUG: Loaded pretrain from /root/stanza_resources/es/pretrain/gsd.pt\n",
            "2023-05-13 22:11:47 DEBUG: POS model loading charmodels: /root/stanza_resources/es/forward_charlm/newswiki.pt and /root/stanza_resources/es/backward_charlm/newswiki.pt\n",
            "2023-05-13 22:11:47 DEBUG: Loading charlm from /root/stanza_resources/es/forward_charlm/newswiki.pt\n",
            "2023-05-13 22:11:47 DEBUG: Loading charlm from /root/stanza_resources/es/backward_charlm/newswiki.pt\n",
            "2023-05-13 22:11:47 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 22:11:47 DEBUG: 3 batches created.\n",
            "2023-05-13 22:11:47 INFO: Start evaluation...\n",
            "2023-05-13 22:11:50 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-13 22:11:50 INFO: 97.18\t100.00\t96.00\t94.28\n",
            "2023-05-13 22:11:50 INFO: Tagger score:\n",
            "2023-05-13 22:11:50 INFO: es_gsd 94.28\n",
            "Copying from data/depparse/es_gsd.test.gold.conllu to data/depparse/es_gsd.test.in.conllu\n"
          ]
        }
      ],
      "source": [
        "!python3 -m stanza.utils.datasets.prepare_depparse_treebank UD_Spanish-GSD"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3-ZarvfyaAP",
        "outputId": "11471e40-cbc5-4b3a-b4e5-a646c83ceeee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-13 22:12:10 INFO: Training program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/training/run_depparse.py --train UD_Spanish-GSD --save_dir ./output_stanza_es --max_steps 10000 --cuda\n",
            "2023-05-13 22:12:10 DEBUG: UD_Spanish-GSD: es_gsd\n",
            "2023-05-13 22:12:10 INFO: Save file for es_gsd model: es_gsd_parser.pt\n",
            "2023-05-13 22:12:10 INFO: UD_Spanish-GSD: ./output_stanza_es/es_gsd_parser.pt does not exist, training new model\n",
            "2023-05-13 22:12:10 INFO: Using default pretrain for es:gsd, found in /root/stanza_resources/es/pretrain/gsd.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-13 22:12:10 INFO: Running train depparse for UD_Spanish-GSD with args ['--wordvec_dir', 'extern_data/wordvec', '--train_file', 'data/depparse/es_gsd.train.in.conllu', '--eval_file', 'data/depparse/es_gsd.dev.in.conllu', '--output_file', '/tmp/tmpx9o7p3ki', '--gold_file', 'data/depparse/es_gsd.dev.gold.conllu', '--batch_size', '5000', '--lang', 'es', '--shorthand', 'es_gsd', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/es/pretrain/gsd.pt', '--max_steps', '10000', '--cuda', '--save_dir', './output_stanza_es', '--save_name', 'es_gsd_parser.pt']\n",
            "2023-05-13 22:12:10 INFO: Running parser in train mode\n",
            "2023-05-13 22:12:10 INFO: Directory ./output_stanza_es does not exist; creating...\n",
            "2023-05-13 22:12:10 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 22:12:13 INFO: Original data size: 14419\n",
            "2023-05-13 22:12:14 INFO: Augmented data size: 15676\n",
            "2023-05-13 22:12:22 INFO: Original length = 15676\n",
            "2023-05-13 22:12:23 INFO: Filtered length = 15676\n",
            "2023-05-13 22:12:24 DEBUG: Loaded pretrain from /root/stanza_resources/es/pretrain/gsd.pt\n",
            "2023-05-13 22:12:29 DEBUG: 89 batches created.\n",
            "2023-05-13 22:12:31 DEBUG: 8 batches created.\n",
            "2023-05-13 22:12:31 INFO: Training parser...\n",
            "2023-05-13 22:12:44 INFO: Finished STEP 20/10000, loss = 6.671104 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:12:53 INFO: Finished STEP 40/10000, loss = 5.877586 (0.331 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:13:01 INFO: Finished STEP 60/10000, loss = 5.045940 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:13:10 INFO: Finished STEP 80/10000, loss = 4.947577 (0.335 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:13:19 INFO: Finished STEP 100/10000, loss = 4.529247 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:13:19 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:13:26 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:13:26 INFO: 54.13\t33.94\t38.45\n",
            "2023-05-13 22:13:26 INFO: step 100: train_loss = 9.854828, dev_score = 0.5413\n",
            "2023-05-13 22:13:26 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:13:26 INFO: new best model saved.\n",
            "2023-05-13 22:13:35 INFO: Finished STEP 120/10000, loss = 4.009996 (0.339 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:13:44 INFO: Finished STEP 140/10000, loss = 3.485797 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:13:53 INFO: Finished STEP 160/10000, loss = 3.462825 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:14:03 INFO: Finished STEP 180/10000, loss = 2.553012 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:14:12 INFO: Finished STEP 200/10000, loss = 3.053075 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:14:12 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:14:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:14:20 INFO: 76.61\t63.64\t65.90\n",
            "2023-05-13 22:14:20 INFO: step 200: train_loss = 3.475863, dev_score = 0.7661\n",
            "2023-05-13 22:14:20 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:14:20 INFO: new best model saved.\n",
            "2023-05-13 22:14:29 INFO: Finished STEP 220/10000, loss = 2.551997 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:14:38 INFO: Finished STEP 240/10000, loss = 3.296316 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:14:47 INFO: Finished STEP 260/10000, loss = 6.238370 (0.447 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:14:56 INFO: Finished STEP 280/10000, loss = 2.920408 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:15:05 INFO: Finished STEP 300/10000, loss = 2.300397 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:15:05 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:15:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:15:11 INFO: 80.31\t68.46\t70.39\n",
            "2023-05-13 22:15:11 INFO: step 300: train_loss = 2.641111, dev_score = 0.8031\n",
            "2023-05-13 22:15:11 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:15:11 INFO: new best model saved.\n",
            "2023-05-13 22:15:22 INFO: Finished STEP 320/10000, loss = 2.229261 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:15:31 INFO: Finished STEP 340/10000, loss = 1.571534 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:15:41 INFO: Finished STEP 360/10000, loss = 1.900775 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:15:50 INFO: Finished STEP 380/10000, loss = 2.553477 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:15:59 INFO: Finished STEP 400/10000, loss = 2.187742 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:15:59 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:16:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:16:05 INFO: 82.30\t71.45\t73.34\n",
            "2023-05-13 22:16:05 INFO: step 400: train_loss = 2.214387, dev_score = 0.8230\n",
            "2023-05-13 22:16:05 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:16:05 INFO: new best model saved.\n",
            "2023-05-13 22:16:16 INFO: Finished STEP 420/10000, loss = 1.849728 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:16:25 INFO: Finished STEP 440/10000, loss = 2.017900 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:16:35 INFO: Finished STEP 460/10000, loss = 1.986885 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:16:43 INFO: Finished STEP 480/10000, loss = 2.772356 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:16:53 INFO: Finished STEP 500/10000, loss = 2.479062 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:16:53 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:16:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:16:57 INFO: 83.88\t73.95\t75.76\n",
            "2023-05-13 22:16:57 INFO: step 500: train_loss = 2.142934, dev_score = 0.8388\n",
            "2023-05-13 22:16:58 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:16:58 INFO: new best model saved.\n",
            "2023-05-13 22:17:08 INFO: Finished STEP 520/10000, loss = 1.976059 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:17:18 INFO: Finished STEP 540/10000, loss = 1.660516 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:17:27 INFO: Finished STEP 560/10000, loss = 1.386181 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:17:36 INFO: Finished STEP 580/10000, loss = 2.184706 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:17:46 INFO: Finished STEP 600/10000, loss = 2.268973 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:17:46 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:17:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:17:50 INFO: 84.67\t75.21\t76.91\n",
            "2023-05-13 22:17:50 INFO: step 600: train_loss = 1.967280, dev_score = 0.8467\n",
            "2023-05-13 22:17:50 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:17:50 INFO: new best model saved.\n",
            "2023-05-13 22:18:01 INFO: Finished STEP 620/10000, loss = 1.839164 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:18:10 INFO: Finished STEP 640/10000, loss = 1.839019 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:18:19 INFO: Finished STEP 660/10000, loss = 1.606313 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:18:29 INFO: Finished STEP 680/10000, loss = 1.984201 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:18:39 INFO: Finished STEP 700/10000, loss = 1.774786 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:18:39 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:18:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:18:43 INFO: 85.18\t76.13\t77.65\n",
            "2023-05-13 22:18:43 INFO: step 700: train_loss = 1.912537, dev_score = 0.8518\n",
            "2023-05-13 22:18:43 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:18:43 INFO: new best model saved.\n",
            "2023-05-13 22:18:54 INFO: Finished STEP 720/10000, loss = 1.244973 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:19:03 INFO: Finished STEP 740/10000, loss = 1.846533 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:19:12 INFO: Finished STEP 760/10000, loss = 2.082174 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:19:22 INFO: Finished STEP 780/10000, loss = 1.569109 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:19:31 INFO: Finished STEP 800/10000, loss = 2.363175 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:19:31 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:19:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:19:37 INFO: 85.73\t76.83\t78.42\n",
            "2023-05-13 22:19:37 INFO: step 800: train_loss = 1.843243, dev_score = 0.8573\n",
            "2023-05-13 22:19:37 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:19:37 INFO: new best model saved.\n",
            "2023-05-13 22:19:46 INFO: Finished STEP 820/10000, loss = 1.582572 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:19:55 INFO: Finished STEP 840/10000, loss = 1.918920 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:20:04 INFO: Finished STEP 860/10000, loss = 1.780134 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:20:14 INFO: Finished STEP 880/10000, loss = 2.116879 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:20:23 INFO: Finished STEP 900/10000, loss = 2.316946 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:20:23 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:20:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:20:28 INFO: 85.98\t77.17\t78.73\n",
            "2023-05-13 22:20:28 INFO: step 900: train_loss = 1.813147, dev_score = 0.8598\n",
            "2023-05-13 22:20:29 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:20:29 INFO: new best model saved.\n",
            "2023-05-13 22:20:40 INFO: Finished STEP 920/10000, loss = 1.541463 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:20:49 INFO: Finished STEP 940/10000, loss = 1.366921 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:20:58 INFO: Finished STEP 960/10000, loss = 1.691147 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:21:07 INFO: Finished STEP 980/10000, loss = 2.577523 (0.101 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:21:16 INFO: Finished STEP 1000/10000, loss = 2.042458 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:21:16 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:21:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:21:22 INFO: 86.30\t77.65\t79.22\n",
            "2023-05-13 22:21:22 INFO: step 1000: train_loss = 1.770660, dev_score = 0.8630\n",
            "2023-05-13 22:21:22 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:21:22 INFO: new best model saved.\n",
            "2023-05-13 22:21:33 INFO: Finished STEP 1020/10000, loss = 1.660678 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:21:42 INFO: Finished STEP 1040/10000, loss = 1.542805 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:21:51 INFO: Finished STEP 1060/10000, loss = 1.926108 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:22:01 INFO: Finished STEP 1080/10000, loss = 1.785169 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:22:10 INFO: Finished STEP 1100/10000, loss = 1.271256 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:22:10 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:22:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:22:14 INFO: 86.62\t78.32\t79.86\n",
            "2023-05-13 22:22:14 INFO: step 1100: train_loss = 1.702944, dev_score = 0.8662\n",
            "2023-05-13 22:22:15 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:22:15 INFO: new best model saved.\n",
            "2023-05-13 22:22:25 INFO: Finished STEP 1120/10000, loss = 1.532806 (0.337 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:22:35 INFO: Finished STEP 1140/10000, loss = 1.654448 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:22:44 INFO: Finished STEP 1160/10000, loss = 1.267220 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:22:53 INFO: Finished STEP 1180/10000, loss = 1.714398 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:23:02 INFO: Finished STEP 1200/10000, loss = 1.420856 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:23:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:23:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:23:07 INFO: 86.71\t78.40\t79.99\n",
            "2023-05-13 22:23:07 INFO: step 1200: train_loss = 1.696353, dev_score = 0.8671\n",
            "2023-05-13 22:23:07 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:23:07 INFO: new best model saved.\n",
            "2023-05-13 22:23:18 INFO: Finished STEP 1220/10000, loss = 1.658386 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:23:27 INFO: Finished STEP 1240/10000, loss = 1.888204 (0.339 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:23:36 INFO: Finished STEP 1260/10000, loss = 1.693269 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:23:46 INFO: Finished STEP 1280/10000, loss = 1.654303 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:23:55 INFO: Finished STEP 1300/10000, loss = 1.133593 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:23:55 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:23:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:23:59 INFO: 86.81\t78.48\t80.04\n",
            "2023-05-13 22:23:59 INFO: step 1300: train_loss = 1.677051, dev_score = 0.8681\n",
            "2023-05-13 22:24:00 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:24:00 INFO: new best model saved.\n",
            "2023-05-13 22:24:11 INFO: Finished STEP 1320/10000, loss = 1.775380 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:24:19 INFO: Finished STEP 1340/10000, loss = 1.158187 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:24:29 INFO: Finished STEP 1360/10000, loss = 1.568878 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:24:38 INFO: Finished STEP 1380/10000, loss = 1.686142 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:24:47 INFO: Finished STEP 1400/10000, loss = 2.127202 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:24:47 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:24:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:24:52 INFO: 86.87\t78.63\t80.04\n",
            "2023-05-13 22:24:52 INFO: step 1400: train_loss = 1.696435, dev_score = 0.8687\n",
            "2023-05-13 22:24:52 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:24:52 INFO: new best model saved.\n",
            "2023-05-13 22:25:03 INFO: Finished STEP 1420/10000, loss = 1.617369 (0.333 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:25:12 INFO: Finished STEP 1440/10000, loss = 1.850959 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:25:21 INFO: Finished STEP 1460/10000, loss = 1.387400 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:25:31 INFO: Finished STEP 1480/10000, loss = 1.635948 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:25:40 INFO: Finished STEP 1500/10000, loss = 1.233773 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:25:40 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:25:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:25:45 INFO: 87.20\t79.07\t80.55\n",
            "2023-05-13 22:25:45 INFO: step 1500: train_loss = 1.654189, dev_score = 0.8720\n",
            "2023-05-13 22:25:45 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:25:45 INFO: new best model saved.\n",
            "2023-05-13 22:25:56 INFO: Finished STEP 1520/10000, loss = 1.818554 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:26:05 INFO: Finished STEP 1540/10000, loss = 1.018256 (0.416 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:26:14 INFO: Finished STEP 1560/10000, loss = 1.153165 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:26:23 INFO: Finished STEP 1580/10000, loss = 1.927892 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:26:32 INFO: Finished STEP 1600/10000, loss = 1.067369 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:26:32 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:26:38 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:26:38 INFO: 87.16\t79.16\t80.62\n",
            "2023-05-13 22:26:38 INFO: step 1600: train_loss = 1.632780, dev_score = 0.8716\n",
            "2023-05-13 22:26:47 INFO: Finished STEP 1620/10000, loss = 1.425986 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:26:58 INFO: Finished STEP 1640/10000, loss = 1.677382 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:27:07 INFO: Finished STEP 1660/10000, loss = 1.206588 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:27:16 INFO: Finished STEP 1680/10000, loss = 1.270458 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:27:25 INFO: Finished STEP 1700/10000, loss = 1.632903 (0.337 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:27:25 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:27:29 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:27:29 INFO: 87.50\t79.63\t81.03\n",
            "2023-05-13 22:27:29 INFO: step 1700: train_loss = 1.623627, dev_score = 0.8750\n",
            "2023-05-13 22:27:29 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:27:29 INFO: new best model saved.\n",
            "2023-05-13 22:27:39 INFO: Finished STEP 1720/10000, loss = 1.598758 (0.335 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:27:48 INFO: Finished STEP 1740/10000, loss = 1.329503 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:27:59 INFO: Finished STEP 1760/10000, loss = 2.500075 (0.101 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:28:08 INFO: Finished STEP 1780/10000, loss = 1.533424 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:28:17 INFO: Finished STEP 1800/10000, loss = 1.627562 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:28:17 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:28:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:28:22 INFO: 87.40\t79.45\t80.92\n",
            "2023-05-13 22:28:22 INFO: step 1800: train_loss = 1.609430, dev_score = 0.8740\n",
            "2023-05-13 22:28:31 INFO: Finished STEP 1820/10000, loss = 1.882517 (0.338 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:28:42 INFO: Finished STEP 1840/10000, loss = 1.434701 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:28:51 INFO: Finished STEP 1860/10000, loss = 1.564670 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:29:00 INFO: Finished STEP 1880/10000, loss = 1.371515 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:29:09 INFO: Finished STEP 1900/10000, loss = 1.402519 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:29:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:29:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:29:14 INFO: 87.62\t79.78\t81.17\n",
            "2023-05-13 22:29:14 INFO: step 1900: train_loss = 1.607158, dev_score = 0.8762\n",
            "2023-05-13 22:29:14 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:29:14 INFO: new best model saved.\n",
            "2023-05-13 22:29:23 INFO: Finished STEP 1920/10000, loss = 1.369931 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:29:34 INFO: Finished STEP 1940/10000, loss = 1.455190 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:29:43 INFO: Finished STEP 1960/10000, loss = 1.513468 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:29:53 INFO: Finished STEP 1980/10000, loss = 1.532181 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:30:02 INFO: Finished STEP 2000/10000, loss = 1.659531 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:30:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:30:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:30:07 INFO: 87.56\t79.63\t81.00\n",
            "2023-05-13 22:30:07 INFO: step 2000: train_loss = 1.552660, dev_score = 0.8756\n",
            "2023-05-13 22:30:16 INFO: Finished STEP 2020/10000, loss = 1.444106 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:30:25 INFO: Finished STEP 2040/10000, loss = 1.418336 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:30:36 INFO: Finished STEP 2060/10000, loss = 2.204488 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:30:45 INFO: Finished STEP 2080/10000, loss = 1.550438 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:30:54 INFO: Finished STEP 2100/10000, loss = 1.685048 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:30:54 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:30:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:30:59 INFO: 87.61\t79.86\t81.21\n",
            "2023-05-13 22:30:59 INFO: step 2100: train_loss = 1.535477, dev_score = 0.8761\n",
            "2023-05-13 22:31:08 INFO: Finished STEP 2120/10000, loss = 1.609082 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:31:18 INFO: Finished STEP 2140/10000, loss = 1.183179 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:31:29 INFO: Finished STEP 2160/10000, loss = 0.992231 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:31:38 INFO: Finished STEP 2180/10000, loss = 1.692950 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:31:47 INFO: Finished STEP 2200/10000, loss = 1.395063 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:31:47 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:31:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:31:51 INFO: 87.60\t79.75\t81.05\n",
            "2023-05-13 22:31:51 INFO: step 2200: train_loss = 1.579943, dev_score = 0.8760\n",
            "2023-05-13 22:32:00 INFO: Finished STEP 2220/10000, loss = 1.328814 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:32:09 INFO: Finished STEP 2240/10000, loss = 1.804879 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:32:20 INFO: Finished STEP 2260/10000, loss = 1.218709 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:32:29 INFO: Finished STEP 2280/10000, loss = 2.193101 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:32:39 INFO: Finished STEP 2300/10000, loss = 1.072498 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:32:39 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:32:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:32:43 INFO: 87.81\t80.09\t81.50\n",
            "2023-05-13 22:32:43 INFO: step 2300: train_loss = 1.543571, dev_score = 0.8781\n",
            "2023-05-13 22:32:43 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:32:43 INFO: new best model saved.\n",
            "2023-05-13 22:32:52 INFO: Finished STEP 2320/10000, loss = 1.163253 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:33:01 INFO: Finished STEP 2340/10000, loss = 1.499621 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:33:12 INFO: Finished STEP 2360/10000, loss = 1.694819 (0.337 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:33:21 INFO: Finished STEP 2380/10000, loss = 1.350572 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:33:31 INFO: Finished STEP 2400/10000, loss = 1.500682 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:33:31 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:33:35 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:33:35 INFO: 87.76\t79.95\t81.32\n",
            "2023-05-13 22:33:35 INFO: step 2400: train_loss = 1.508502, dev_score = 0.8776\n",
            "2023-05-13 22:33:44 INFO: Finished STEP 2420/10000, loss = 1.690972 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:33:53 INFO: Finished STEP 2440/10000, loss = 1.040714 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:34:04 INFO: Finished STEP 2460/10000, loss = 1.307271 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:34:13 INFO: Finished STEP 2480/10000, loss = 1.674806 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:34:22 INFO: Finished STEP 2500/10000, loss = 1.220146 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:34:22 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:34:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:34:28 INFO: 88.02\t80.43\t81.80\n",
            "2023-05-13 22:34:28 INFO: step 2500: train_loss = 1.501982, dev_score = 0.8802\n",
            "2023-05-13 22:34:28 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:34:28 INFO: new best model saved.\n",
            "2023-05-13 22:34:37 INFO: Finished STEP 2520/10000, loss = 2.074287 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:34:48 INFO: Finished STEP 2540/10000, loss = 0.979656 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:34:57 INFO: Finished STEP 2560/10000, loss = 1.301274 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:35:06 INFO: Finished STEP 2580/10000, loss = 1.750623 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:35:15 INFO: Finished STEP 2600/10000, loss = 1.562708 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:35:15 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:35:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:35:20 INFO: 88.08\t80.34\t81.72\n",
            "2023-05-13 22:35:20 INFO: step 2600: train_loss = 1.525646, dev_score = 0.8808\n",
            "2023-05-13 22:35:20 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:35:20 INFO: new best model saved.\n",
            "2023-05-13 22:35:29 INFO: Finished STEP 2620/10000, loss = 1.269943 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:35:41 INFO: Finished STEP 2640/10000, loss = 1.463511 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:35:50 INFO: Finished STEP 2660/10000, loss = 2.056383 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:35:59 INFO: Finished STEP 2680/10000, loss = 1.293315 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:36:08 INFO: Finished STEP 2700/10000, loss = 1.788002 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:36:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:36:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:36:12 INFO: 87.82\t79.94\t81.35\n",
            "2023-05-13 22:36:12 INFO: step 2700: train_loss = 1.472674, dev_score = 0.8782\n",
            "2023-05-13 22:36:22 INFO: Finished STEP 2720/10000, loss = 1.498063 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:36:31 INFO: Finished STEP 2740/10000, loss = 1.563360 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:36:42 INFO: Finished STEP 2760/10000, loss = 1.106202 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:36:51 INFO: Finished STEP 2780/10000, loss = 1.363995 (0.336 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:37:00 INFO: Finished STEP 2800/10000, loss = 1.786407 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:37:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:37:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:37:04 INFO: 88.11\t80.53\t81.86\n",
            "2023-05-13 22:37:04 INFO: step 2800: train_loss = 1.528048, dev_score = 0.8811\n",
            "2023-05-13 22:37:04 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:37:04 INFO: new best model saved.\n",
            "2023-05-13 22:37:14 INFO: Finished STEP 2820/10000, loss = 1.717662 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:37:25 INFO: Finished STEP 2840/10000, loss = 1.512150 (0.410 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:37:34 INFO: Finished STEP 2860/10000, loss = 1.570460 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:37:43 INFO: Finished STEP 2880/10000, loss = 1.096848 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:37:52 INFO: Finished STEP 2900/10000, loss = 0.862335 (0.433 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:37:52 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:37:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:37:57 INFO: 88.14\t80.56\t81.91\n",
            "2023-05-13 22:37:57 INFO: step 2900: train_loss = 1.470307, dev_score = 0.8814\n",
            "2023-05-13 22:37:57 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:37:57 INFO: new best model saved.\n",
            "2023-05-13 22:38:06 INFO: Finished STEP 2920/10000, loss = 1.270334 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:38:17 INFO: Finished STEP 2940/10000, loss = 1.643436 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:38:26 INFO: Finished STEP 2960/10000, loss = 1.539178 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:38:35 INFO: Finished STEP 2980/10000, loss = 1.489924 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:38:44 INFO: Finished STEP 3000/10000, loss = 1.172319 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:38:44 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:38:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:38:50 INFO: 88.15\t80.52\t81.89\n",
            "2023-05-13 22:38:50 INFO: step 3000: train_loss = 1.496178, dev_score = 0.8815\n",
            "2023-05-13 22:38:50 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:38:50 INFO: new best model saved.\n",
            "2023-05-13 22:38:59 INFO: Finished STEP 3020/10000, loss = 2.068335 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:39:10 INFO: Finished STEP 3040/10000, loss = 1.309210 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:39:20 INFO: Finished STEP 3060/10000, loss = 1.219488 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:39:29 INFO: Finished STEP 3080/10000, loss = 1.335030 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:39:38 INFO: Finished STEP 3100/10000, loss = 1.445517 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:39:38 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:39:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:39:43 INFO: 88.17\t80.66\t82.01\n",
            "2023-05-13 22:39:43 INFO: step 3100: train_loss = 1.484669, dev_score = 0.8817\n",
            "2023-05-13 22:39:44 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:39:44 INFO: new best model saved.\n",
            "2023-05-13 22:39:53 INFO: Finished STEP 3120/10000, loss = 1.803111 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:40:02 INFO: Finished STEP 3140/10000, loss = 1.630423 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:40:13 INFO: Finished STEP 3160/10000, loss = 1.643097 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:40:22 INFO: Finished STEP 3180/10000, loss = 1.098059 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:40:31 INFO: Finished STEP 3200/10000, loss = 1.774122 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:40:31 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:40:35 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:40:35 INFO: 88.32\t80.85\t82.19\n",
            "2023-05-13 22:40:35 INFO: step 3200: train_loss = 1.450664, dev_score = 0.8832\n",
            "2023-05-13 22:40:36 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:40:36 INFO: new best model saved.\n",
            "2023-05-13 22:40:45 INFO: Finished STEP 3220/10000, loss = 1.565522 (0.336 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:40:54 INFO: Finished STEP 3240/10000, loss = 1.301359 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:41:05 INFO: Finished STEP 3260/10000, loss = 1.386893 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:41:14 INFO: Finished STEP 3280/10000, loss = 1.704889 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:41:24 INFO: Finished STEP 3300/10000, loss = 1.241504 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:41:24 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:41:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:41:28 INFO: 88.33\t80.82\t82.23\n",
            "2023-05-13 22:41:28 INFO: step 3300: train_loss = 1.455778, dev_score = 0.8833\n",
            "2023-05-13 22:41:28 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:41:28 INFO: new best model saved.\n",
            "2023-05-13 22:41:37 INFO: Finished STEP 3320/10000, loss = 1.710723 (0.339 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:41:47 INFO: Finished STEP 3340/10000, loss = 1.526958 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:41:58 INFO: Finished STEP 3360/10000, loss = 2.048532 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:42:07 INFO: Finished STEP 3380/10000, loss = 1.452283 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:42:16 INFO: Finished STEP 3400/10000, loss = 1.316297 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:42:16 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:42:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:42:20 INFO: 88.33\t80.80\t82.17\n",
            "2023-05-13 22:42:20 INFO: step 3400: train_loss = 1.429649, dev_score = 0.8833\n",
            "2023-05-13 22:42:21 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:42:21 INFO: new best model saved.\n",
            "2023-05-13 22:42:30 INFO: Finished STEP 3420/10000, loss = 1.472372 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:42:39 INFO: Finished STEP 3440/10000, loss = 1.305036 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:42:50 INFO: Finished STEP 3460/10000, loss = 1.452189 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:42:59 INFO: Finished STEP 3480/10000, loss = 1.344678 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:43:08 INFO: Finished STEP 3500/10000, loss = 1.130176 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:43:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:43:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:43:13 INFO: 88.30\t80.68\t82.06\n",
            "2023-05-13 22:43:13 INFO: step 3500: train_loss = 1.499127, dev_score = 0.8830\n",
            "2023-05-13 22:43:22 INFO: Finished STEP 3520/10000, loss = 1.089770 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:43:31 INFO: Finished STEP 3540/10000, loss = 1.331631 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:43:42 INFO: Finished STEP 3560/10000, loss = 1.601190 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:43:52 INFO: Finished STEP 3580/10000, loss = 1.569564 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:44:00 INFO: Finished STEP 3600/10000, loss = 1.507672 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:44:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:44:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:44:06 INFO: 88.41\t80.97\t82.31\n",
            "2023-05-13 22:44:06 INFO: step 3600: train_loss = 1.400886, dev_score = 0.8841\n",
            "2023-05-13 22:44:06 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:44:06 INFO: new best model saved.\n",
            "2023-05-13 22:44:15 INFO: Finished STEP 3620/10000, loss = 1.477127 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:44:25 INFO: Finished STEP 3640/10000, loss = 1.522071 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:44:36 INFO: Finished STEP 3660/10000, loss = 1.851843 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:44:46 INFO: Finished STEP 3680/10000, loss = 0.921290 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:44:55 INFO: Finished STEP 3700/10000, loss = 1.639905 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:44:55 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:44:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:44:59 INFO: 88.39\t80.93\t82.23\n",
            "2023-05-13 22:44:59 INFO: step 3700: train_loss = 1.443291, dev_score = 0.8839\n",
            "2023-05-13 22:45:08 INFO: Finished STEP 3720/10000, loss = 1.323203 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:45:18 INFO: Finished STEP 3740/10000, loss = 1.010174 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:45:29 INFO: Finished STEP 3760/10000, loss = 1.335275 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:45:38 INFO: Finished STEP 3780/10000, loss = 1.241811 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:45:47 INFO: Finished STEP 3800/10000, loss = 1.728876 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:45:47 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:45:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:45:51 INFO: 88.38\t80.85\t82.26\n",
            "2023-05-13 22:45:51 INFO: step 3800: train_loss = 1.481116, dev_score = 0.8838\n",
            "2023-05-13 22:46:01 INFO: Finished STEP 3820/10000, loss = 1.416238 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:46:10 INFO: Finished STEP 3840/10000, loss = 1.520806 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:46:19 INFO: Finished STEP 3860/10000, loss = 1.149456 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:46:29 INFO: Finished STEP 3880/10000, loss = 1.710062 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:46:39 INFO: Finished STEP 3900/10000, loss = 1.519438 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:46:39 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:46:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:46:43 INFO: 88.35\t80.82\t82.16\n",
            "2023-05-13 22:46:43 INFO: step 3900: train_loss = 1.441213, dev_score = 0.8835\n",
            "2023-05-13 22:46:52 INFO: Finished STEP 3920/10000, loss = 1.350181 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:47:01 INFO: Finished STEP 3940/10000, loss = 1.445796 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:47:11 INFO: Finished STEP 3960/10000, loss = 1.497050 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:47:21 INFO: Finished STEP 3980/10000, loss = 1.552679 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:47:31 INFO: Finished STEP 4000/10000, loss = 0.949900 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:47:31 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:47:35 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:47:35 INFO: 88.46\t81.13\t82.47\n",
            "2023-05-13 22:47:35 INFO: step 4000: train_loss = 1.419808, dev_score = 0.8846\n",
            "2023-05-13 22:47:35 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:47:35 INFO: new best model saved.\n",
            "2023-05-13 22:47:44 INFO: Finished STEP 4020/10000, loss = 1.155942 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:47:53 INFO: Finished STEP 4040/10000, loss = 1.066637 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:48:03 INFO: Finished STEP 4060/10000, loss = 1.361921 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:48:12 INFO: Finished STEP 4080/10000, loss = 1.430948 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:48:21 INFO: Finished STEP 4100/10000, loss = 1.504925 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:48:21 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:48:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:48:28 INFO: 88.56\t81.18\t82.54\n",
            "2023-05-13 22:48:28 INFO: step 4100: train_loss = 1.455079, dev_score = 0.8856\n",
            "2023-05-13 22:48:28 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:48:28 INFO: new best model saved.\n",
            "2023-05-13 22:48:38 INFO: Finished STEP 4120/10000, loss = 1.155740 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:48:47 INFO: Finished STEP 4140/10000, loss = 0.789913 (0.414 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:48:57 INFO: Finished STEP 4160/10000, loss = 1.024150 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:49:05 INFO: Finished STEP 4180/10000, loss = 1.410888 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:49:15 INFO: Finished STEP 4200/10000, loss = 1.644309 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:49:15 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:49:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:49:22 INFO: 88.48\t81.03\t82.39\n",
            "2023-05-13 22:49:22 INFO: step 4200: train_loss = 1.400646, dev_score = 0.8848\n",
            "2023-05-13 22:49:31 INFO: Finished STEP 4220/10000, loss = 1.118401 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:49:40 INFO: Finished STEP 4240/10000, loss = 1.260946 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:49:50 INFO: Finished STEP 4260/10000, loss = 1.282516 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:49:58 INFO: Finished STEP 4280/10000, loss = 1.273537 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:50:08 INFO: Finished STEP 4300/10000, loss = 1.297174 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:50:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:50:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:50:14 INFO: 88.47\t81.07\t82.40\n",
            "2023-05-13 22:50:14 INFO: step 4300: train_loss = 1.428100, dev_score = 0.8847\n",
            "2023-05-13 22:50:23 INFO: Finished STEP 4320/10000, loss = 1.329793 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:50:32 INFO: Finished STEP 4340/10000, loss = 1.411460 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:50:41 INFO: Finished STEP 4360/10000, loss = 1.771771 (0.313 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:50:50 INFO: Finished STEP 4380/10000, loss = 1.331637 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:51:00 INFO: Finished STEP 4400/10000, loss = 1.261716 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:51:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:51:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:51:06 INFO: 88.62\t81.18\t82.53\n",
            "2023-05-13 22:51:06 INFO: step 4400: train_loss = 1.373764, dev_score = 0.8862\n",
            "2023-05-13 22:51:06 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:51:06 INFO: new best model saved.\n",
            "2023-05-13 22:51:15 INFO: Finished STEP 4420/10000, loss = 1.389443 (0.338 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:51:24 INFO: Finished STEP 4440/10000, loss = 1.543274 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:51:33 INFO: Finished STEP 4460/10000, loss = 1.240501 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:51:42 INFO: Finished STEP 4480/10000, loss = 1.462555 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:51:51 INFO: Finished STEP 4500/10000, loss = 1.409788 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:51:51 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:51:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:51:58 INFO: 88.53\t81.18\t82.50\n",
            "2023-05-13 22:51:58 INFO: step 4500: train_loss = 1.423965, dev_score = 0.8853\n",
            "2023-05-13 22:52:08 INFO: Finished STEP 4520/10000, loss = 1.307921 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:52:17 INFO: Finished STEP 4540/10000, loss = 1.277341 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:52:26 INFO: Finished STEP 4560/10000, loss = 1.332483 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:52:36 INFO: Finished STEP 4580/10000, loss = 1.379419 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:52:45 INFO: Finished STEP 4600/10000, loss = 1.096219 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:52:45 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:52:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:52:52 INFO: 88.58\t81.16\t82.52\n",
            "2023-05-13 22:52:52 INFO: step 4600: train_loss = 1.391837, dev_score = 0.8858\n",
            "2023-05-13 22:53:01 INFO: Finished STEP 4620/10000, loss = 1.300473 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:53:09 INFO: Finished STEP 4640/10000, loss = 1.353962 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:53:19 INFO: Finished STEP 4660/10000, loss = 1.611987 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:53:28 INFO: Finished STEP 4680/10000, loss = 1.578921 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:53:37 INFO: Finished STEP 4700/10000, loss = 1.447148 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:53:37 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:53:44 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:53:44 INFO: 88.66\t81.27\t82.56\n",
            "2023-05-13 22:53:44 INFO: step 4700: train_loss = 1.393547, dev_score = 0.8866\n",
            "2023-05-13 22:53:44 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:53:44 INFO: new best model saved.\n",
            "2023-05-13 22:53:54 INFO: Finished STEP 4720/10000, loss = 1.452255 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:54:03 INFO: Finished STEP 4740/10000, loss = 1.849414 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:54:12 INFO: Finished STEP 4760/10000, loss = 1.020475 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:54:21 INFO: Finished STEP 4780/10000, loss = 1.396049 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:54:31 INFO: Finished STEP 4800/10000, loss = 1.298521 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:54:31 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:54:35 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:54:35 INFO: 88.75\t81.39\t82.79\n",
            "2023-05-13 22:54:35 INFO: step 4800: train_loss = 1.396547, dev_score = 0.8875\n",
            "2023-05-13 22:54:35 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:54:35 INFO: new best model saved.\n",
            "2023-05-13 22:54:46 INFO: Finished STEP 4820/10000, loss = 2.049757 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:54:56 INFO: Finished STEP 4840/10000, loss = 1.426475 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:55:05 INFO: Finished STEP 4860/10000, loss = 1.290570 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:55:14 INFO: Finished STEP 4880/10000, loss = 1.231345 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:55:24 INFO: Finished STEP 4900/10000, loss = 1.343067 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:55:24 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:55:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:55:28 INFO: 88.56\t81.13\t82.48\n",
            "2023-05-13 22:55:28 INFO: step 4900: train_loss = 1.409680, dev_score = 0.8856\n",
            "2023-05-13 22:55:39 INFO: Finished STEP 4920/10000, loss = 1.487393 (0.339 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:55:48 INFO: Finished STEP 4940/10000, loss = 1.274797 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:55:57 INFO: Finished STEP 4960/10000, loss = 1.280634 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:56:07 INFO: Finished STEP 4980/10000, loss = 1.068915 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:56:15 INFO: Finished STEP 5000/10000, loss = 1.630385 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:56:15 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:56:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:56:22 INFO: 88.62\t81.30\t82.58\n",
            "2023-05-13 22:56:22 INFO: step 5000: train_loss = 1.406420, dev_score = 0.8862\n",
            "2023-05-13 22:56:31 INFO: Finished STEP 5020/10000, loss = 1.229257 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:56:40 INFO: Finished STEP 5040/10000, loss = 1.297899 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:56:49 INFO: Finished STEP 5060/10000, loss = 1.421265 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:56:59 INFO: Finished STEP 5080/10000, loss = 1.382580 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:57:08 INFO: Finished STEP 5100/10000, loss = 1.341766 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:57:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:57:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:57:13 INFO: 88.75\t81.44\t82.77\n",
            "2023-05-13 22:57:13 INFO: step 5100: train_loss = 1.375770, dev_score = 0.8875\n",
            "2023-05-13 22:57:14 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:57:14 INFO: new best model saved.\n",
            "2023-05-13 22:57:25 INFO: Finished STEP 5120/10000, loss = 1.433357 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:57:34 INFO: Finished STEP 5140/10000, loss = 1.380004 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:57:44 INFO: Finished STEP 5160/10000, loss = 0.952051 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:57:53 INFO: Finished STEP 5180/10000, loss = 1.359422 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:58:02 INFO: Finished STEP 5200/10000, loss = 1.465527 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:58:02 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:58:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:58:10 INFO: 88.76\t81.47\t82.79\n",
            "2023-05-13 22:58:10 INFO: step 5200: train_loss = 1.384678, dev_score = 0.8876\n",
            "2023-05-13 22:58:10 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:58:10 INFO: new best model saved.\n",
            "2023-05-13 22:58:18 INFO: Finished STEP 5220/10000, loss = 1.572341 (0.338 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:58:28 INFO: Finished STEP 5240/10000, loss = 1.589612 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:58:38 INFO: Finished STEP 5260/10000, loss = 1.632326 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:58:46 INFO: Finished STEP 5280/10000, loss = 1.190251 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:58:56 INFO: Finished STEP 5300/10000, loss = 1.247833 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:58:56 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:59:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:59:02 INFO: 88.82\t81.60\t82.92\n",
            "2023-05-13 22:59:02 INFO: step 5300: train_loss = 1.337321, dev_score = 0.8882\n",
            "2023-05-13 22:59:02 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:59:02 INFO: new best model saved.\n",
            "2023-05-13 22:59:12 INFO: Finished STEP 5320/10000, loss = 1.163540 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:59:21 INFO: Finished STEP 5340/10000, loss = 1.806165 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:59:31 INFO: Finished STEP 5360/10000, loss = 0.907390 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:59:40 INFO: Finished STEP 5380/10000, loss = 1.452360 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:59:49 INFO: Finished STEP 5400/10000, loss = 1.832306 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-13 22:59:49 INFO: Evaluating on dev set...\n",
            "2023-05-13 22:59:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 22:59:53 INFO: 88.83\t81.59\t82.92\n",
            "2023-05-13 22:59:53 INFO: step 5400: train_loss = 1.423706, dev_score = 0.8883\n",
            "2023-05-13 22:59:54 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 22:59:54 INFO: new best model saved.\n",
            "2023-05-13 23:00:03 INFO: Finished STEP 5420/10000, loss = 1.456496 (0.338 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:00:15 INFO: Finished STEP 5440/10000, loss = 1.601120 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:00:23 INFO: Finished STEP 5460/10000, loss = 1.738177 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:00:33 INFO: Finished STEP 5480/10000, loss = 1.075371 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:00:43 INFO: Finished STEP 5500/10000, loss = 1.800695 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:00:43 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:00:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:00:47 INFO: 88.90\t81.64\t82.95\n",
            "2023-05-13 23:00:47 INFO: step 5500: train_loss = 1.346404, dev_score = 0.8890\n",
            "2023-05-13 23:00:47 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:00:47 INFO: new best model saved.\n",
            "2023-05-13 23:00:57 INFO: Finished STEP 5520/10000, loss = 1.319936 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:01:06 INFO: Finished STEP 5540/10000, loss = 0.904520 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:01:17 INFO: Finished STEP 5560/10000, loss = 2.285442 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:01:27 INFO: Finished STEP 5580/10000, loss = 1.379875 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:01:36 INFO: Finished STEP 5600/10000, loss = 0.947783 (0.451 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:01:36 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:01:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:01:41 INFO: 88.72\t81.44\t82.75\n",
            "2023-05-13 23:01:41 INFO: step 5600: train_loss = 1.362073, dev_score = 0.8872\n",
            "2023-05-13 23:01:50 INFO: Finished STEP 5620/10000, loss = 2.238482 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:01:59 INFO: Finished STEP 5640/10000, loss = 0.954497 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:02:10 INFO: Finished STEP 5660/10000, loss = 1.458724 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:02:20 INFO: Finished STEP 5680/10000, loss = 1.500347 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:02:29 INFO: Finished STEP 5700/10000, loss = 1.411220 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:02:29 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:02:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:02:34 INFO: 88.72\t81.48\t82.76\n",
            "2023-05-13 23:02:34 INFO: step 5700: train_loss = 1.391551, dev_score = 0.8872\n",
            "2023-05-13 23:02:43 INFO: Finished STEP 5720/10000, loss = 1.964026 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:02:53 INFO: Finished STEP 5740/10000, loss = 1.639991 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:03:04 INFO: Finished STEP 5760/10000, loss = 1.375194 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:03:13 INFO: Finished STEP 5780/10000, loss = 1.579433 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:03:23 INFO: Finished STEP 5800/10000, loss = 1.013098 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:03:23 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:03:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:03:28 INFO: 88.68\t81.29\t82.63\n",
            "2023-05-13 23:03:28 INFO: step 5800: train_loss = 1.376355, dev_score = 0.8868\n",
            "2023-05-13 23:03:37 INFO: Finished STEP 5820/10000, loss = 1.865021 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:03:47 INFO: Finished STEP 5840/10000, loss = 0.892977 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:03:58 INFO: Finished STEP 5860/10000, loss = 0.798428 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:04:07 INFO: Finished STEP 5880/10000, loss = 1.653535 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:04:16 INFO: Finished STEP 5900/10000, loss = 0.981031 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:04:16 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:04:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:04:20 INFO: 88.78\t81.52\t82.81\n",
            "2023-05-13 23:04:20 INFO: step 5900: train_loss = 1.350857, dev_score = 0.8878\n",
            "2023-05-13 23:04:30 INFO: Finished STEP 5920/10000, loss = 3.852606 (0.447 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:04:39 INFO: Finished STEP 5940/10000, loss = 1.341837 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:04:50 INFO: Finished STEP 5960/10000, loss = 1.297378 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:05:00 INFO: Finished STEP 5980/10000, loss = 1.806365 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:05:09 INFO: Finished STEP 6000/10000, loss = 0.730388 (0.044 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:05:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:05:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:05:13 INFO: 88.57\t81.09\t82.41\n",
            "2023-05-13 23:05:13 INFO: step 6000: train_loss = 1.380054, dev_score = 0.8857\n",
            "2023-05-13 23:05:23 INFO: Finished STEP 6020/10000, loss = 1.560890 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:05:32 INFO: Finished STEP 6040/10000, loss = 1.455534 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:05:43 INFO: Finished STEP 6060/10000, loss = 1.411995 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:05:52 INFO: Finished STEP 6080/10000, loss = 1.308354 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:06:01 INFO: Finished STEP 6100/10000, loss = 1.382305 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:06:01 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:06:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:06:06 INFO: 88.81\t81.50\t82.82\n",
            "2023-05-13 23:06:06 INFO: step 6100: train_loss = 1.346745, dev_score = 0.8881\n",
            "2023-05-13 23:06:15 INFO: Finished STEP 6120/10000, loss = 1.421401 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:06:25 INFO: Finished STEP 6140/10000, loss = 1.063547 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:06:34 INFO: Finished STEP 6160/10000, loss = 1.159951 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:06:45 INFO: Finished STEP 6180/10000, loss = 2.187064 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:06:54 INFO: Finished STEP 6200/10000, loss = 1.495246 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:06:54 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:07:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:07:00 INFO: 88.79\t81.49\t82.77\n",
            "2023-05-13 23:07:00 INFO: step 6200: train_loss = 1.351400, dev_score = 0.8879\n",
            "2023-05-13 23:07:09 INFO: Finished STEP 6220/10000, loss = 1.285446 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:07:19 INFO: Finished STEP 6240/10000, loss = 1.321166 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:07:28 INFO: Finished STEP 6260/10000, loss = 1.390549 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:07:39 INFO: Finished STEP 6280/10000, loss = 1.514393 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:07:48 INFO: Finished STEP 6300/10000, loss = 1.370595 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:07:48 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:07:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:07:53 INFO: 88.91\t81.75\t83.03\n",
            "2023-05-13 23:07:53 INFO: step 6300: train_loss = 1.353918, dev_score = 0.8891\n",
            "2023-05-13 23:07:53 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:07:53 INFO: new best model saved.\n",
            "2023-05-13 23:08:03 INFO: Finished STEP 6320/10000, loss = 1.052935 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:08:12 INFO: Finished STEP 6340/10000, loss = 1.201707 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:08:21 INFO: Finished STEP 6360/10000, loss = 1.272059 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:08:31 INFO: Finished STEP 6380/10000, loss = 2.148809 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:08:40 INFO: Finished STEP 6400/10000, loss = 0.904637 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:08:40 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:08:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:08:46 INFO: 88.83\t81.60\t82.86\n",
            "2023-05-13 23:08:46 INFO: step 6400: train_loss = 1.331561, dev_score = 0.8883\n",
            "2023-05-13 23:08:56 INFO: Finished STEP 6420/10000, loss = 1.540963 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:09:05 INFO: Finished STEP 6440/10000, loss = 1.200120 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:09:14 INFO: Finished STEP 6460/10000, loss = 1.709841 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:09:23 INFO: Finished STEP 6480/10000, loss = 1.921632 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:09:35 INFO: Finished STEP 6500/10000, loss = 1.529297 (0.339 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:09:35 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:09:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:09:39 INFO: 88.84\t81.58\t82.89\n",
            "2023-05-13 23:09:39 INFO: step 6500: train_loss = 1.360643, dev_score = 0.8884\n",
            "2023-05-13 23:09:48 INFO: Finished STEP 6520/10000, loss = 1.143749 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:09:57 INFO: Finished STEP 6540/10000, loss = 1.058377 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:10:07 INFO: Finished STEP 6560/10000, loss = 3.761158 (0.447 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:10:16 INFO: Finished STEP 6580/10000, loss = 0.846773 (0.421 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:10:27 INFO: Finished STEP 6600/10000, loss = 1.777173 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:10:27 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:10:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:10:32 INFO: 88.93\t81.74\t83.07\n",
            "2023-05-13 23:10:32 INFO: step 6600: train_loss = 1.333081, dev_score = 0.8893\n",
            "2023-05-13 23:10:33 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:10:33 INFO: new best model saved.\n",
            "2023-05-13 23:10:42 INFO: Finished STEP 6620/10000, loss = 1.205105 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:10:51 INFO: Finished STEP 6640/10000, loss = 1.510122 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:11:00 INFO: Finished STEP 6660/10000, loss = 1.415460 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:11:10 INFO: Finished STEP 6680/10000, loss = 1.513316 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:11:21 INFO: Finished STEP 6700/10000, loss = 0.657619 (0.044 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:11:21 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:11:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:11:27 INFO: 88.90\t81.76\t83.03\n",
            "2023-05-13 23:11:27 INFO: step 6700: train_loss = 1.318219, dev_score = 0.8890\n",
            "2023-05-13 23:11:36 INFO: Finished STEP 6720/10000, loss = 1.001349 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:11:45 INFO: Finished STEP 6740/10000, loss = 1.373715 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:11:55 INFO: Finished STEP 6760/10000, loss = 1.198138 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:12:04 INFO: Finished STEP 6780/10000, loss = 1.338212 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:12:15 INFO: Finished STEP 6800/10000, loss = 1.371842 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:12:15 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:12:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:12:20 INFO: 88.90\t81.73\t82.99\n",
            "2023-05-13 23:12:20 INFO: step 6800: train_loss = 1.357918, dev_score = 0.8890\n",
            "2023-05-13 23:12:29 INFO: Finished STEP 6820/10000, loss = 1.385345 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:12:39 INFO: Finished STEP 6840/10000, loss = 1.026720 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:12:48 INFO: Finished STEP 6860/10000, loss = 0.869855 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:12:57 INFO: Finished STEP 6880/10000, loss = 1.362882 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:13:06 INFO: Finished STEP 6900/10000, loss = 1.261206 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:13:06 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:13:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:13:12 INFO: 89.03\t81.94\t83.18\n",
            "2023-05-13 23:13:12 INFO: step 6900: train_loss = 1.339929, dev_score = 0.8903\n",
            "2023-05-13 23:13:12 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:13:12 INFO: new best model saved.\n",
            "2023-05-13 23:13:22 INFO: Finished STEP 6920/10000, loss = 1.399949 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:13:32 INFO: Finished STEP 6940/10000, loss = 1.338627 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:13:41 INFO: Finished STEP 6960/10000, loss = 1.414585 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:13:50 INFO: Finished STEP 6980/10000, loss = 0.878559 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:14:01 INFO: Finished STEP 7000/10000, loss = 1.734892 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:14:01 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:14:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:14:06 INFO: 88.85\t81.65\t82.91\n",
            "2023-05-13 23:14:06 INFO: step 7000: train_loss = 1.321158, dev_score = 0.8885\n",
            "2023-05-13 23:14:15 INFO: Finished STEP 7020/10000, loss = 1.464446 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:14:24 INFO: Finished STEP 7040/10000, loss = 1.292184 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:14:33 INFO: Finished STEP 7060/10000, loss = 1.160979 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:14:43 INFO: Finished STEP 7080/10000, loss = 1.060183 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:14:53 INFO: Finished STEP 7100/10000, loss = 1.017455 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:14:53 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:14:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:14:58 INFO: 88.95\t81.79\t83.05\n",
            "2023-05-13 23:14:58 INFO: step 7100: train_loss = 1.364445, dev_score = 0.8895\n",
            "2023-05-13 23:15:07 INFO: Finished STEP 7120/10000, loss = 1.287117 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:15:17 INFO: Finished STEP 7140/10000, loss = 1.162509 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:15:26 INFO: Finished STEP 7160/10000, loss = 1.294048 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:15:37 INFO: Finished STEP 7180/10000, loss = 1.636533 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:15:46 INFO: Finished STEP 7200/10000, loss = 1.204006 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:15:46 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:15:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:15:52 INFO: 88.83\t81.65\t82.93\n",
            "2023-05-13 23:15:52 INFO: step 7200: train_loss = 1.286548, dev_score = 0.8883\n",
            "2023-05-13 23:16:01 INFO: Finished STEP 7220/10000, loss = 1.290855 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:16:10 INFO: Finished STEP 7240/10000, loss = 0.993232 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:16:19 INFO: Finished STEP 7260/10000, loss = 1.048675 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:16:30 INFO: Finished STEP 7280/10000, loss = 1.261165 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:16:40 INFO: Finished STEP 7300/10000, loss = 0.918662 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:16:40 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:16:44 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:16:44 INFO: 88.95\t81.83\t83.09\n",
            "2023-05-13 23:16:44 INFO: step 7300: train_loss = 1.362965, dev_score = 0.8895\n",
            "2023-05-13 23:16:53 INFO: Finished STEP 7320/10000, loss = 1.267205 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:17:02 INFO: Finished STEP 7340/10000, loss = 1.536452 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:17:12 INFO: Finished STEP 7360/10000, loss = 1.245156 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:17:21 INFO: Finished STEP 7380/10000, loss = 1.324340 (0.338 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:17:32 INFO: Finished STEP 7400/10000, loss = 1.062687 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:17:32 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:17:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:17:37 INFO: 88.91\t81.73\t83.04\n",
            "2023-05-13 23:17:37 INFO: step 7400: train_loss = 1.327408, dev_score = 0.8891\n",
            "2023-05-13 23:17:46 INFO: Finished STEP 7420/10000, loss = 1.343674 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:17:55 INFO: Finished STEP 7440/10000, loss = 1.296702 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:18:04 INFO: Finished STEP 7460/10000, loss = 1.219053 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:18:14 INFO: Finished STEP 7480/10000, loss = 0.878402 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:18:25 INFO: Finished STEP 7500/10000, loss = 1.058510 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:18:25 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:18:29 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:18:29 INFO: 88.95\t81.88\t83.12\n",
            "2023-05-13 23:18:29 INFO: step 7500: train_loss = 1.314387, dev_score = 0.8895\n",
            "2023-05-13 23:18:38 INFO: Finished STEP 7520/10000, loss = 1.285115 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:18:47 INFO: Finished STEP 7540/10000, loss = 1.415076 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:18:56 INFO: Finished STEP 7560/10000, loss = 1.534357 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:19:08 INFO: Finished STEP 7580/10000, loss = 1.769079 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:19:16 INFO: Finished STEP 7600/10000, loss = 1.407526 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:19:16 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:19:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:19:22 INFO: 88.91\t81.68\t82.98\n",
            "2023-05-13 23:19:22 INFO: step 7600: train_loss = 1.319149, dev_score = 0.8891\n",
            "2023-05-13 23:19:31 INFO: Finished STEP 7620/10000, loss = 1.255515 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:19:40 INFO: Finished STEP 7640/10000, loss = 1.033497 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:19:49 INFO: Finished STEP 7660/10000, loss = 0.880917 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:20:00 INFO: Finished STEP 7680/10000, loss = 1.357028 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:20:09 INFO: Finished STEP 7700/10000, loss = 0.993305 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:20:09 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:20:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:20:15 INFO: 88.92\t81.84\t83.09\n",
            "2023-05-13 23:20:15 INFO: step 7700: train_loss = 1.318825, dev_score = 0.8892\n",
            "2023-05-13 23:20:24 INFO: Finished STEP 7720/10000, loss = 1.441908 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:20:33 INFO: Finished STEP 7740/10000, loss = 1.222488 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:20:43 INFO: Finished STEP 7760/10000, loss = 1.472437 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:20:54 INFO: Finished STEP 7780/10000, loss = 1.203492 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:21:03 INFO: Finished STEP 7800/10000, loss = 3.665891 (0.449 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:21:03 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:21:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:21:08 INFO: 88.92\t81.85\t83.08\n",
            "2023-05-13 23:21:08 INFO: step 7800: train_loss = 1.318592, dev_score = 0.8892\n",
            "2023-05-13 23:21:16 INFO: Finished STEP 7820/10000, loss = 1.233279 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:21:26 INFO: Finished STEP 7840/10000, loss = 1.136349 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:21:35 INFO: Finished STEP 7860/10000, loss = 1.263613 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:21:46 INFO: Finished STEP 7880/10000, loss = 2.201205 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:21:55 INFO: Finished STEP 7900/10000, loss = 1.123894 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:21:55 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:22:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:22:00 INFO: 88.90\t81.68\t83.02\n",
            "2023-05-13 23:22:00 INFO: step 7900: train_loss = 1.276255, dev_score = 0.8890\n",
            "2023-05-13 23:22:09 INFO: Finished STEP 7920/10000, loss = 1.543027 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:22:18 INFO: Finished STEP 7940/10000, loss = 0.832121 (0.434 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:22:27 INFO: Finished STEP 7960/10000, loss = 0.787374 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:22:38 INFO: Finished STEP 7980/10000, loss = 1.375544 (0.338 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:22:48 INFO: Finished STEP 8000/10000, loss = 1.063791 (0.354 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:22:48 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:22:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:22:52 INFO: 88.94\t81.83\t83.09\n",
            "2023-05-13 23:22:52 INFO: step 8000: train_loss = 1.313636, dev_score = 0.8894\n",
            "2023-05-13 23:23:01 INFO: Finished STEP 8020/10000, loss = 0.964588 (0.358 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:23:10 INFO: Finished STEP 8040/10000, loss = 1.400862 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:23:19 INFO: Finished STEP 8060/10000, loss = 1.422524 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:23:30 INFO: Finished STEP 8080/10000, loss = 1.264946 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:23:39 INFO: Finished STEP 8100/10000, loss = 1.314133 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:23:39 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:23:44 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:23:44 INFO: 89.02\t81.83\t83.14\n",
            "2023-05-13 23:23:44 INFO: step 8100: train_loss = 1.308045, dev_score = 0.8902\n",
            "2023-05-13 23:23:53 INFO: Finished STEP 8120/10000, loss = 1.439171 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:24:03 INFO: Finished STEP 8140/10000, loss = 2.371780 (0.097 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:24:12 INFO: Finished STEP 8160/10000, loss = 1.301794 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:24:21 INFO: Finished STEP 8180/10000, loss = 1.165780 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:24:32 INFO: Finished STEP 8200/10000, loss = 1.335435 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:24:32 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:24:38 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:24:38 INFO: 88.98\t81.86\t83.09\n",
            "2023-05-13 23:24:38 INFO: step 8200: train_loss = 1.340773, dev_score = 0.8898\n",
            "2023-05-13 23:24:47 INFO: Finished STEP 8220/10000, loss = 1.373367 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:24:56 INFO: Finished STEP 8240/10000, loss = 0.960105 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:25:05 INFO: Finished STEP 8260/10000, loss = 1.175023 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:25:14 INFO: Finished STEP 8280/10000, loss = 1.679111 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:25:25 INFO: Finished STEP 8300/10000, loss = 1.095226 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:25:25 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:25:30 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:25:30 INFO: 88.97\t81.87\t83.12\n",
            "2023-05-13 23:25:30 INFO: step 8300: train_loss = 1.310044, dev_score = 0.8897\n",
            "2023-05-13 23:25:39 INFO: Finished STEP 8320/10000, loss = 0.883619 (0.432 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:25:49 INFO: Finished STEP 8340/10000, loss = 1.105287 (0.345 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:25:57 INFO: Finished STEP 8360/10000, loss = 1.207811 (0.333 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:26:07 INFO: Finished STEP 8380/10000, loss = 1.377949 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:26:16 INFO: Finished STEP 8400/10000, loss = 0.506454 (0.045 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:26:16 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:26:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:26:22 INFO: 88.91\t81.73\t82.98\n",
            "2023-05-13 23:26:22 INFO: step 8400: train_loss = 1.290301, dev_score = 0.8891\n",
            "2023-05-13 23:26:31 INFO: Finished STEP 8420/10000, loss = 1.113595 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:26:40 INFO: Finished STEP 8440/10000, loss = 1.064413 (0.412 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:26:50 INFO: Finished STEP 8460/10000, loss = 3.654304 (0.450 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:26:59 INFO: Finished STEP 8480/10000, loss = 1.282418 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:27:08 INFO: Finished STEP 8500/10000, loss = 1.637412 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:27:08 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:27:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:27:15 INFO: 88.85\t81.61\t82.87\n",
            "2023-05-13 23:27:15 INFO: step 8500: train_loss = 1.294912, dev_score = 0.8885\n",
            "2023-05-13 23:27:24 INFO: Finished STEP 8520/10000, loss = 1.312352 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:27:33 INFO: Finished STEP 8540/10000, loss = 1.525249 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:27:42 INFO: Finished STEP 8560/10000, loss = 1.337558 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:27:51 INFO: Finished STEP 8580/10000, loss = 1.108899 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:28:00 INFO: Finished STEP 8600/10000, loss = 1.520285 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:28:00 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:28:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:28:08 INFO: 89.03\t81.94\t83.16\n",
            "2023-05-13 23:28:08 INFO: step 8600: train_loss = 1.263379, dev_score = 0.8903\n",
            "2023-05-13 23:28:08 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:28:08 INFO: new best model saved.\n",
            "2023-05-13 23:28:17 INFO: Finished STEP 8620/10000, loss = 1.350501 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:28:26 INFO: Finished STEP 8640/10000, loss = 1.112660 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:28:35 INFO: Finished STEP 8660/10000, loss = 1.582356 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:28:45 INFO: Finished STEP 8680/10000, loss = 1.471547 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:28:54 INFO: Finished STEP 8700/10000, loss = 1.144026 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:28:54 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:29:01 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:29:01 INFO: 89.05\t81.94\t83.25\n",
            "2023-05-13 23:29:01 INFO: step 8700: train_loss = 1.303085, dev_score = 0.8905\n",
            "2023-05-13 23:29:01 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:29:01 INFO: new best model saved.\n",
            "2023-05-13 23:29:10 INFO: Finished STEP 8720/10000, loss = 1.367396 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:29:19 INFO: Finished STEP 8740/10000, loss = 1.275578 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:29:29 INFO: Finished STEP 8760/10000, loss = 1.475770 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:29:38 INFO: Finished STEP 8780/10000, loss = 1.120224 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:29:48 INFO: Finished STEP 8800/10000, loss = 1.238920 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:29:48 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:29:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:29:54 INFO: 89.19\t82.24\t83.47\n",
            "2023-05-13 23:29:54 INFO: step 8800: train_loss = 1.304811, dev_score = 0.8919\n",
            "2023-05-13 23:29:54 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:29:54 INFO: new best model saved.\n",
            "2023-05-13 23:30:04 INFO: Finished STEP 8820/10000, loss = 1.080501 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:30:14 INFO: Finished STEP 8840/10000, loss = 1.029506 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:30:23 INFO: Finished STEP 8860/10000, loss = 1.501680 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:30:32 INFO: Finished STEP 8880/10000, loss = 1.266690 (0.357 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:30:41 INFO: Finished STEP 8900/10000, loss = 1.266751 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:30:41 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:30:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:30:47 INFO: 89.09\t81.98\t83.28\n",
            "2023-05-13 23:30:47 INFO: step 8900: train_loss = 1.284002, dev_score = 0.8909\n",
            "2023-05-13 23:30:57 INFO: Finished STEP 8920/10000, loss = 1.747361 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:31:06 INFO: Finished STEP 8940/10000, loss = 1.547031 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:31:15 INFO: Finished STEP 8960/10000, loss = 1.552245 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:31:25 INFO: Finished STEP 8980/10000, loss = 0.914566 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:31:34 INFO: Finished STEP 9000/10000, loss = 1.726761 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:31:34 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:31:38 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:31:38 INFO: 89.12\t82.11\t83.33\n",
            "2023-05-13 23:31:38 INFO: step 9000: train_loss = 1.301864, dev_score = 0.8912\n",
            "2023-05-13 23:31:50 INFO: Finished STEP 9020/10000, loss = 1.097979 (0.342 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:31:59 INFO: Finished STEP 9040/10000, loss = 1.454555 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:32:08 INFO: Finished STEP 9060/10000, loss = 1.171976 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:32:18 INFO: Finished STEP 9080/10000, loss = 0.997500 (0.340 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:32:27 INFO: Finished STEP 9100/10000, loss = 1.569825 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:32:27 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:32:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:32:32 INFO: 89.04\t81.97\t83.24\n",
            "2023-05-13 23:32:32 INFO: step 9100: train_loss = 1.294223, dev_score = 0.8904\n",
            "2023-05-13 23:32:43 INFO: Finished STEP 9120/10000, loss = 0.823016 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:32:52 INFO: Finished STEP 9140/10000, loss = 1.422228 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:33:01 INFO: Finished STEP 9160/10000, loss = 1.470017 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:33:11 INFO: Finished STEP 9180/10000, loss = 0.871564 (0.458 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:33:20 INFO: Finished STEP 9200/10000, loss = 3.570217 (0.445 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:33:20 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:33:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:33:27 INFO: 89.14\t82.14\t83.39\n",
            "2023-05-13 23:33:27 INFO: step 9200: train_loss = 1.280000, dev_score = 0.8914\n",
            "2023-05-13 23:33:36 INFO: Finished STEP 9220/10000, loss = 0.922088 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:33:46 INFO: Finished STEP 9240/10000, loss = 0.989780 (0.360 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:33:55 INFO: Finished STEP 9260/10000, loss = 1.240053 (0.346 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:34:04 INFO: Finished STEP 9280/10000, loss = 0.979021 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:34:13 INFO: Finished STEP 9300/10000, loss = 3.464580 (0.447 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:34:13 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:34:18 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:34:18 INFO: 89.14\t82.15\t83.38\n",
            "2023-05-13 23:34:18 INFO: step 9300: train_loss = 1.279138, dev_score = 0.8914\n",
            "2023-05-13 23:34:29 INFO: Finished STEP 9320/10000, loss = 1.089600 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:34:38 INFO: Finished STEP 9340/10000, loss = 1.076975 (0.352 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:34:48 INFO: Finished STEP 9360/10000, loss = 1.000311 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:34:57 INFO: Finished STEP 9380/10000, loss = 0.816689 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:35:06 INFO: Finished STEP 9400/10000, loss = 1.181316 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:35:06 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:35:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:35:10 INFO: 89.09\t82.07\t83.33\n",
            "2023-05-13 23:35:10 INFO: step 9400: train_loss = 1.287976, dev_score = 0.8909\n",
            "2023-05-13 23:35:22 INFO: Finished STEP 9420/10000, loss = 1.339114 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:35:31 INFO: Finished STEP 9440/10000, loss = 3.488264 (0.445 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:35:40 INFO: Finished STEP 9460/10000, loss = 1.791284 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:35:50 INFO: Finished STEP 9480/10000, loss = 1.280637 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:35:59 INFO: Finished STEP 9500/10000, loss = 1.385815 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:35:59 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:36:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:36:05 INFO: 89.02\t81.93\t83.21\n",
            "2023-05-13 23:36:05 INFO: step 9500: train_loss = 1.281910, dev_score = 0.8902\n",
            "2023-05-13 23:36:14 INFO: Finished STEP 9520/10000, loss = 1.411014 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:36:23 INFO: Finished STEP 9540/10000, loss = 3.695554 (0.460 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:36:32 INFO: Finished STEP 9560/10000, loss = 1.212400 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:36:42 INFO: Finished STEP 9580/10000, loss = 1.093425 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:36:51 INFO: Finished STEP 9600/10000, loss = 1.177617 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:36:51 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:36:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:36:56 INFO: 89.04\t81.99\t83.28\n",
            "2023-05-13 23:36:56 INFO: step 9600: train_loss = 1.285489, dev_score = 0.8904\n",
            "2023-05-13 23:37:08 INFO: Finished STEP 9620/10000, loss = 0.944949 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:37:17 INFO: Finished STEP 9640/10000, loss = 1.298909 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:37:26 INFO: Finished STEP 9660/10000, loss = 1.088308 (0.350 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:37:35 INFO: Finished STEP 9680/10000, loss = 1.263735 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:37:44 INFO: Finished STEP 9700/10000, loss = 1.084846 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:37:44 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:37:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:37:50 INFO: 88.93\t81.73\t83.07\n",
            "2023-05-13 23:37:50 INFO: step 9700: train_loss = 1.266084, dev_score = 0.8893\n",
            "2023-05-13 23:37:59 INFO: Finished STEP 9720/10000, loss = 1.381368 (0.344 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:38:10 INFO: Finished STEP 9740/10000, loss = 1.284865 (0.353 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:38:20 INFO: Finished STEP 9760/10000, loss = 1.105955 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:38:29 INFO: Finished STEP 9780/10000, loss = 1.069830 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:38:38 INFO: Finished STEP 9800/10000, loss = 0.976699 (0.356 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:38:38 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:38:42 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:38:42 INFO: 89.06\t81.94\t83.25\n",
            "2023-05-13 23:38:42 INFO: step 9800: train_loss = 1.277899, dev_score = 0.8906\n",
            "2023-05-13 23:38:52 INFO: Finished STEP 9820/10000, loss = 1.408282 (0.338 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:39:01 INFO: Finished STEP 9840/10000, loss = 1.289086 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:39:12 INFO: Finished STEP 9860/10000, loss = 1.497764 (0.349 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:39:21 INFO: Finished STEP 9880/10000, loss = 1.211425 (0.341 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:39:31 INFO: Finished STEP 9900/10000, loss = 0.922247 (0.351 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:39:31 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:39:35 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:39:35 INFO: 89.13\t82.10\t83.39\n",
            "2023-05-13 23:39:35 INFO: step 9900: train_loss = 1.300975, dev_score = 0.8913\n",
            "2023-05-13 23:39:44 INFO: Finished STEP 9920/10000, loss = 1.804937 (0.355 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:39:56 INFO: Finished STEP 9940/10000, loss = 1.020990 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:40:04 INFO: Finished STEP 9960/10000, loss = 1.269479 (0.348 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:40:14 INFO: Finished STEP 9980/10000, loss = 1.566315 (0.343 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:40:23 INFO: Finished STEP 10000/10000, loss = 1.331725 (0.347 sec/batch), lr: 0.003000\n",
            "2023-05-13 23:40:23 INFO: Evaluating on dev set...\n",
            "2023-05-13 23:40:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:40:27 INFO: 89.20\t82.18\t83.50\n",
            "2023-05-13 23:40:27 INFO: step 10000: train_loss = 1.261195, dev_score = 0.8920\n",
            "2023-05-13 23:40:28 INFO: Model saved to ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:40:28 INFO: new best model saved.\n",
            "2023-05-13 23:40:28 INFO: Training ended with 10000 steps.\n",
            "2023-05-13 23:40:28 INFO: Best dev F1 = 89.20, at iteration = 10000\n",
            "2023-05-13 23:40:28 INFO: Using default pretrain for es:gsd, found in /root/stanza_resources/es/pretrain/gsd.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-13 23:40:28 INFO: Running dev depparse for UD_Spanish-GSD with args ['--wordvec_dir', 'extern_data/wordvec', '--eval_file', 'data/depparse/es_gsd.dev.in.conllu', '--output_file', '/tmp/tmpx9o7p3ki', '--gold_file', 'data/depparse/es_gsd.dev.gold.conllu', '--lang', 'es', '--shorthand', 'es_gsd', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/es/pretrain/gsd.pt', '--max_steps', '10000', '--cuda', '--save_dir', './output_stanza_es', '--save_name', 'es_gsd_parser.pt']\n",
            "2023-05-13 23:40:28 INFO: Running parser in predict mode\n",
            "2023-05-13 23:40:28 INFO: Loading model from: ./output_stanza_es/es_gsd_parser.pt\n",
            "2023-05-13 23:40:28 DEBUG: Loaded pretrain from /root/stanza_resources/es/pretrain/gsd.pt\n",
            "2023-05-13 23:40:28 INFO: Loading data with batch size 5000...\n",
            "2023-05-13 23:40:31 DEBUG: 8 batches created.\n",
            "2023-05-13 23:40:31 INFO: Start evaluation...\n",
            "2023-05-13 23:40:37 INFO: F1 scores for each dependency:\n",
            "  Note that unlabeled attachment errors hurt the labeled attachment scores\n",
            "       acl: p 0.7563 r 0.6950 f1 0.7243 (259 actual)\n",
            " acl:relcl: p 0.7549 r 0.8080 f1 0.7805 (427 actual)\n",
            "     advcl: p 0.6879 r 0.6768 f1 0.6823 (622 actual)\n",
            "    advmod: p 0.8696 r 0.8325 f1 0.8506 (961 actual)\n",
            "      amod: p 0.9114 r 0.8985 f1 0.9049 (2050 actual)\n",
            "     appos: p 0.6928 r 0.6184 f1 0.6535 (773 actual)\n",
            "       aux: p 0.9831 r 0.9062 f1 0.9431 (256 actual)\n",
            "  aux:pass: p 0.8385 r 0.9641 f1 0.8969 (167 actual)\n",
            "      case: p 0.9611 r 0.9694 f1 0.9652 (5856 actual)\n",
            "        cc: p 0.9298 r 0.9273 f1 0.9285 (1128 actual)\n",
            "     ccomp: p 0.8557 r 0.6803 f1 0.7580 (122 actual)\n",
            "  compound: p 0.0000 r 0.0000 f1 0.0000 (30 actual)\n",
            "      conj: p 0.6928 r 0.7070 f1 0.6998 (1464 actual)\n",
            "       cop: p 0.8908 r 0.9238 f1 0.9070 (512 actual)\n",
            "     csubj: p 0.6792 r 0.6207 f1 0.6486 (58 actual)\n",
            "csubj:pass: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "       dep: p 0.7692 r 0.4000 f1 0.5263 (100 actual)\n",
            "       det: p 0.9830 r 0.9854 f1 0.9842 (5274 actual)\n",
            " discourse: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "dislocated: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "   expl:pv: p 0.9830 r 0.9768 f1 0.9799 (474 actual)\n",
            "     fixed: p 0.8661 r 0.7729 f1 0.8168 (251 actual)\n",
            "      flat: p 0.7642 r 0.8832 f1 0.8194 (668 actual)\n",
            "      mark: p 0.8744 r 0.9262 f1 0.8995 (962 actual)\n",
            "      nmod: p 0.8544 r 0.8244 f1 0.8391 (3416 actual)\n",
            "     nsubj: p 0.8967 r 0.8683 f1 0.8823 (1390 actual)\n",
            "nsubj:pass: p 0.8000 r 0.8800 f1 0.8381 (100 actual)\n",
            "    nummod: p 0.8981 r 0.9291 f1 0.9133 (550 actual)\n",
            "       obj: p 0.8648 r 0.8656 f1 0.8652 (1116 actual)\n",
            "       obl: p 0.8072 r 0.8668 f1 0.8359 (2034 actual)\n",
            " obl:agent: p 0.8889 r 0.9275 f1 0.9078 (138 actual)\n",
            "   obl:arg: p 0.7212 r 0.7000 f1 0.7104 (170 actual)\n",
            " parataxis: p 0.5510 r 0.3830 f1 0.4519 (141 actual)\n",
            "     punct: p 0.9094 r 0.9101 f1 0.9098 (4038 actual)\n",
            "      root: p 0.9679 r 0.9679 f1 0.9679 (1400 actual)\n",
            "     xcomp: p 0.7323 r 0.8208 f1 0.7741 (240 actual)\n",
            "2023-05-13 23:40:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-13 23:40:39 INFO: 89.20\t82.18\t83.50\n",
            "2023-05-13 23:40:39 INFO: Parser score:\n",
            "2023-05-13 23:40:39 INFO: es_gsd 89.20\n",
            "2023-05-13 23:40:41 INFO: Finished running dev set on\n",
            "UD_Spanish-GSD\n",
            "  UAS   LAS  CLAS  MLAS  BLEX\n",
            "91.84 89.20 83.50 82.18 83.50\n",
            "5315.057620048523\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "!python3 -m stanza.utils.training.run_depparse --train UD_Spanish-GSD --save_dir ./output_stanza_es --max_steps 10000 --cuda\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Turkish"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paJWKdm-xQrz",
        "outputId": "93f514da-9181-4478-f757-39be884c2b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-14 20:44:21 INFO: Datasets program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/datasets/prepare_depparse_treebank.py UD_Turkish-BOUN\n",
            "2023-05-14 20:44:21 DEBUG: Downloading resource file...\n",
            "\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0% 0.00/30.0k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 75.8MB/s]        \n",
            "2023-05-14 20:44:21 DEBUG: Processing parameter \"processors\"...\n",
            "2023-05-14 20:44:21 DEBUG: Found pos: boun.\n",
            "2023-05-14 20:44:21 DEBUG: Find dependency pretrain: boun.\n",
            "2023-05-14 20:44:21 INFO: Downloading these customized packages for language: tr (Turkish)...\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| pos       | boun    |\n",
            "| pretrain  | boun    |\n",
            "=======================\n",
            "\n",
            "Downloading https://huggingface.co/stanfordnlp/stanza-tr/resolve/v1.5.0/models/pos/boun.pt: 100% 20.9M/20.9M [00:02<00:00, 8.95MB/s]\n",
            "Downloading https://huggingface.co/stanfordnlp/stanza-tr/resolve/v1.5.0/models/pretrain/boun.pt: 100% 107M/107M [00:07<00:00, 15.2MB/s]\n",
            "2023-05-14 20:44:33 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2023-05-14 20:44:33 INFO: Using default pretrain for tr:boun, found in /root/stanza_resources/tr/pretrain/boun.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "Preparing data for UD_Turkish-BOUN: tr_boun, tr\n",
            "Reading from ./UD_Turkish-BOUN/tr_boun-ud-train.conllu and writing to /tmp/tmph3sp83__/tr_boun.train.gold.conllu\n",
            "Augmented 87 quotes: Counter({'„“': 13, '““': 12, '「」': 11, '„”': 10, '\"\"': 9, '″″': 8, '»«': 8, '«»': 7, '《》': 6, '””': 3})\n",
            "Swapped 'w1, w2' for 'w1 ,w2' 67 times\n",
            "Added 31 new sentences with asdf, zzzz -> asdf,zzzz\n",
            "Reading from ./UD_Turkish-BOUN/tr_boun-ud-dev.conllu and writing to /tmp/tmph3sp83__/tr_boun.dev.gold.conllu\n",
            "Reading from ./UD_Turkish-BOUN/tr_boun-ud-test.conllu and writing to /tmp/tmph3sp83__/tr_boun.test.gold.conllu\n",
            "2023-05-14 20:44:35 INFO: Running tagger to retag /tmp/tmph3sp83__/tr_boun.train.gold.conllu to data/depparse/tr_boun.train.in.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'tr', '--shorthand', 'tr_boun', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/tr/pos', '--save_name', 'boun.pt', '--wordvec_pretrain_file', '/root/stanza_resources/tr/pretrain/boun.pt', '--eval_file', '/tmp/tmph3sp83__/tr_boun.train.gold.conllu', '--gold_file', '/tmp/tmph3sp83__/tr_boun.train.gold.conllu', '--output_file', 'data/depparse/tr_boun.train.in.conllu']\n",
            "2023-05-14 20:44:35 INFO: Running tagger in predict mode\n",
            "2023-05-14 20:44:35 INFO: Loading model from: /root/stanza_resources/tr/pos/boun.pt\n",
            "2023-05-14 20:44:35 DEBUG: Loaded pretrain from /root/stanza_resources/tr/pretrain/boun.pt\n",
            "2023-05-14 20:44:42 INFO: Loading data with batch size 5000...\n",
            "2023-05-14 20:44:46 DEBUG: 21 batches created.\n",
            "2023-05-14 20:44:46 INFO: Start evaluation...\n",
            "2023-05-14 20:44:59 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-14 20:44:59 INFO: 87.84\t17.95\t79.62\t12.83\n",
            "2023-05-14 20:44:59 INFO: Tagger score:\n",
            "2023-05-14 20:44:59 INFO: tr_boun 12.83\n",
            "2023-05-14 20:44:59 INFO: Running tagger to retag /tmp/tmph3sp83__/tr_boun.dev.gold.conllu to data/depparse/tr_boun.dev.gold.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'tr', '--shorthand', 'tr_boun', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/tr/pos', '--save_name', 'boun.pt', '--wordvec_pretrain_file', '/root/stanza_resources/tr/pretrain/boun.pt', '--eval_file', '/tmp/tmph3sp83__/tr_boun.dev.gold.conllu', '--gold_file', '/tmp/tmph3sp83__/tr_boun.dev.gold.conllu', '--output_file', 'data/depparse/tr_boun.dev.gold.conllu']\n",
            "2023-05-14 20:44:59 INFO: Running tagger in predict mode\n",
            "2023-05-14 20:44:59 INFO: Loading model from: /root/stanza_resources/tr/pos/boun.pt\n",
            "2023-05-14 20:44:59 DEBUG: Loaded pretrain from /root/stanza_resources/tr/pretrain/boun.pt\n",
            "2023-05-14 20:44:59 INFO: Loading data with batch size 5000...\n",
            "2023-05-14 20:45:00 DEBUG: 3 batches created.\n",
            "2023-05-14 20:45:00 INFO: Start evaluation...\n",
            "2023-05-14 20:45:01 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-14 20:45:01 INFO: 89.12\t21.44\t85.01\t18.60\n",
            "2023-05-14 20:45:01 INFO: Tagger score:\n",
            "2023-05-14 20:45:01 INFO: tr_boun 18.60\n",
            "Copying from data/depparse/tr_boun.dev.gold.conllu to data/depparse/tr_boun.dev.in.conllu\n",
            "2023-05-14 20:45:01 INFO: Running tagger to retag /tmp/tmph3sp83__/tr_boun.test.gold.conllu to data/depparse/tr_boun.test.gold.conllu\n",
            "  Args: ['--wordvec_dir', 'extern_data/wordvec', '--lang', 'tr', '--shorthand', 'tr_boun', '--batch_size', '5000', '--mode', 'predict', '--save_dir', '/root/stanza_resources/tr/pos', '--save_name', 'boun.pt', '--wordvec_pretrain_file', '/root/stanza_resources/tr/pretrain/boun.pt', '--eval_file', '/tmp/tmph3sp83__/tr_boun.test.gold.conllu', '--gold_file', '/tmp/tmph3sp83__/tr_boun.test.gold.conllu', '--output_file', 'data/depparse/tr_boun.test.gold.conllu']\n",
            "2023-05-14 20:45:01 INFO: Running tagger in predict mode\n",
            "2023-05-14 20:45:01 INFO: Loading model from: /root/stanza_resources/tr/pos/boun.pt\n",
            "2023-05-14 20:45:01 DEBUG: Loaded pretrain from /root/stanza_resources/tr/pretrain/boun.pt\n",
            "2023-05-14 20:45:01 INFO: Loading data with batch size 5000...\n",
            "2023-05-14 20:45:03 DEBUG: 3 batches created.\n",
            "2023-05-14 20:45:03 INFO: Start evaluation...\n",
            "2023-05-14 20:45:05 INFO: UPOS\tXPOS\tUFeats\tAllTags\n",
            "2023-05-14 20:45:05 INFO: 88.65\t20.85\t87.77\t18.49\n",
            "2023-05-14 20:45:05 INFO: Tagger score:\n",
            "2023-05-14 20:45:05 INFO: tr_boun 18.49\n",
            "Copying from data/depparse/tr_boun.test.gold.conllu to data/depparse/tr_boun.test.in.conllu\n"
          ]
        }
      ],
      "source": [
        "!python3 -m stanza.utils.datasets.prepare_depparse_treebank UD_Turkish-BOUN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOkeRvHqxaju",
        "outputId": "a5208ac5-5b7a-4d52-d628-42d54ef9b6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-14 20:45:08 INFO: Training program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/training/run_depparse.py --train UD_Turkish-BOUN --save_dir ./output_stanza_tr --max_steps 10000 --cuda\n",
            "2023-05-14 20:45:08 DEBUG: UD_Turkish-BOUN: tr_boun\n",
            "2023-05-14 20:45:08 INFO: Save file for tr_boun model: tr_boun_parser.pt\n",
            "2023-05-14 20:45:08 INFO: UD_Turkish-BOUN: ./output_stanza_tr/tr_boun_parser.pt does not exist, training new model\n",
            "2023-05-14 20:45:08 INFO: Using default pretrain for tr:boun, found in /root/stanza_resources/tr/pretrain/boun.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-14 20:45:08 INFO: Running train depparse for UD_Turkish-BOUN with args ['--wordvec_dir', 'extern_data/wordvec', '--train_file', 'data/depparse/tr_boun.train.in.conllu', '--eval_file', 'data/depparse/tr_boun.dev.in.conllu', '--output_file', '/tmp/tmp3w_wxwok', '--gold_file', 'data/depparse/tr_boun.dev.gold.conllu', '--batch_size', '5000', '--lang', 'tr', '--shorthand', 'tr_boun', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/tr/pretrain/boun.pt', '--max_steps', '10000', '--cuda', '--save_dir', './output_stanza_tr', '--save_name', 'tr_boun_parser.pt']\n",
            "2023-05-14 20:45:09 INFO: Running parser in train mode\n",
            "2023-05-14 20:45:09 INFO: Directory ./output_stanza_tr does not exist; creating...\n",
            "2023-05-14 20:45:09 INFO: Loading data with batch size 5000...\n",
            "2023-05-14 20:45:09 INFO: Original data size: 7834\n",
            "2023-05-14 20:45:09 INFO: Augmented data size: 8091\n",
            "2023-05-14 20:45:11 INFO: Original length = 8091\n",
            "2023-05-14 20:45:11 INFO: Filtered length = 8091\n",
            "2023-05-14 20:45:13 DEBUG: Loaded pretrain from /root/stanza_resources/tr/pretrain/boun.pt\n",
            "2023-05-14 20:45:15 DEBUG: 23 batches created.\n",
            "2023-05-14 20:45:15 DEBUG: 3 batches created.\n",
            "2023-05-14 20:45:15 INFO: Training parser...\n",
            "2023-05-14 20:45:29 INFO: Finished STEP 20/10000, loss = 5.470449 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:45:40 INFO: Finished STEP 40/10000, loss = 17.698328 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:45:50 INFO: Finished STEP 60/10000, loss = 4.514178 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:46:00 INFO: Finished STEP 80/10000, loss = 5.480583 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:46:10 INFO: Finished STEP 100/10000, loss = 3.872870 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:46:10 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:46:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:46:15 INFO: 37.77\t26.44\t30.21\n",
            "2023-05-14 20:46:15 INFO: step 100: train_loss = 11.197813, dev_score = 0.3777\n",
            "2023-05-14 20:46:15 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:46:15 INFO: new best model saved.\n",
            "2023-05-14 20:46:25 INFO: Finished STEP 120/10000, loss = 3.710126 (0.413 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:46:36 INFO: Finished STEP 140/10000, loss = 2.416668 (0.424 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:46:46 INFO: Finished STEP 160/10000, loss = 4.952653 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:46:57 INFO: Finished STEP 180/10000, loss = 3.764920 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:47:07 INFO: Finished STEP 200/10000, loss = 16.451157 (0.639 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:47:07 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:47:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:47:10 INFO: 49.54\t40.76\t43.06\n",
            "2023-05-14 20:47:10 INFO: step 200: train_loss = 4.460129, dev_score = 0.4954\n",
            "2023-05-14 20:47:10 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:47:10 INFO: new best model saved.\n",
            "2023-05-14 20:47:20 INFO: Finished STEP 220/10000, loss = 2.763810 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:47:31 INFO: Finished STEP 240/10000, loss = 3.573970 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:47:41 INFO: Finished STEP 260/10000, loss = 3.064597 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:47:52 INFO: Finished STEP 280/10000, loss = 2.309022 (0.413 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:48:03 INFO: Finished STEP 300/10000, loss = 13.679876 (0.402 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:48:03 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:48:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:48:05 INFO: 55.99\t48.27\t50.63\n",
            "2023-05-14 20:48:05 INFO: step 300: train_loss = 3.790204, dev_score = 0.5599\n",
            "2023-05-14 20:48:05 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:48:05 INFO: new best model saved.\n",
            "2023-05-14 20:48:16 INFO: Finished STEP 320/10000, loss = 3.130615 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:48:26 INFO: Finished STEP 340/10000, loss = 2.975991 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:48:37 INFO: Finished STEP 360/10000, loss = 3.299308 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:48:48 INFO: Finished STEP 380/10000, loss = 2.997347 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:48:58 INFO: Finished STEP 400/10000, loss = 2.262907 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:48:58 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:49:01 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:49:01 INFO: 62.89\t56.85\t59.25\n",
            "2023-05-14 20:49:01 INFO: step 400: train_loss = 3.282704, dev_score = 0.6289\n",
            "2023-05-14 20:49:01 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:49:01 INFO: new best model saved.\n",
            "2023-05-14 20:49:11 INFO: Finished STEP 420/10000, loss = 2.943842 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:49:21 INFO: Finished STEP 440/10000, loss = 2.578704 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:49:32 INFO: Finished STEP 460/10000, loss = 2.932871 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:49:43 INFO: Finished STEP 480/10000, loss = 1.304969 (0.499 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:49:53 INFO: Finished STEP 500/10000, loss = 1.463153 (0.462 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:49:53 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:49:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:49:56 INFO: 64.92\t59.50\t61.68\n",
            "2023-05-14 20:49:56 INFO: step 500: train_loss = 3.163751, dev_score = 0.6492\n",
            "2023-05-14 20:49:56 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:49:56 INFO: new best model saved.\n",
            "2023-05-14 20:50:06 INFO: Finished STEP 520/10000, loss = 3.301775 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:50:16 INFO: Finished STEP 540/10000, loss = 4.094412 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:50:27 INFO: Finished STEP 560/10000, loss = 1.587278 (0.431 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:50:38 INFO: Finished STEP 580/10000, loss = 4.165825 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:50:48 INFO: Finished STEP 600/10000, loss = 2.851105 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:50:48 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:50:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:50:51 INFO: 65.67\t60.25\t62.60\n",
            "2023-05-14 20:50:51 INFO: step 600: train_loss = 2.906954, dev_score = 0.6567\n",
            "2023-05-14 20:50:51 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:50:51 INFO: new best model saved.\n",
            "2023-05-14 20:51:01 INFO: Finished STEP 620/10000, loss = 1.749288 (0.402 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:51:11 INFO: Finished STEP 640/10000, loss = 1.348123 (0.424 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:51:22 INFO: Finished STEP 660/10000, loss = 2.948143 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:51:33 INFO: Finished STEP 680/10000, loss = 2.360883 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:51:43 INFO: Finished STEP 700/10000, loss = 2.168665 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:51:43 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:51:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:51:46 INFO: 66.80\t61.82\t64.11\n",
            "2023-05-14 20:51:46 INFO: step 700: train_loss = 2.871088, dev_score = 0.6680\n",
            "2023-05-14 20:51:46 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:51:46 INFO: new best model saved.\n",
            "2023-05-14 20:51:56 INFO: Finished STEP 720/10000, loss = 3.142266 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:52:06 INFO: Finished STEP 740/10000, loss = 2.829775 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:52:17 INFO: Finished STEP 760/10000, loss = 2.099719 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:52:28 INFO: Finished STEP 780/10000, loss = 2.661348 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:52:38 INFO: Finished STEP 800/10000, loss = 0.946115 (0.285 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:52:38 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:52:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:52:41 INFO: 67.10\t61.97\t64.24\n",
            "2023-05-14 20:52:41 INFO: step 800: train_loss = 2.877614, dev_score = 0.6710\n",
            "2023-05-14 20:52:41 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:52:41 INFO: new best model saved.\n",
            "2023-05-14 20:52:51 INFO: Finished STEP 820/10000, loss = 2.375470 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:53:01 INFO: Finished STEP 840/10000, loss = 2.050774 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:53:12 INFO: Finished STEP 860/10000, loss = 2.161969 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:53:23 INFO: Finished STEP 880/10000, loss = 2.243065 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:53:33 INFO: Finished STEP 900/10000, loss = 1.843913 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:53:33 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:53:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:53:36 INFO: 66.78\t61.48\t63.70\n",
            "2023-05-14 20:53:36 INFO: step 900: train_loss = 2.689117, dev_score = 0.6678\n",
            "2023-05-14 20:53:46 INFO: Finished STEP 920/10000, loss = 2.767716 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:53:56 INFO: Finished STEP 940/10000, loss = 1.941249 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:54:07 INFO: Finished STEP 960/10000, loss = 1.603696 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:54:18 INFO: Finished STEP 980/10000, loss = 1.423168 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:54:28 INFO: Finished STEP 1000/10000, loss = 1.197142 (0.457 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:54:28 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:54:30 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:54:30 INFO: 67.45\t62.44\t64.81\n",
            "2023-05-14 20:54:30 INFO: step 1000: train_loss = 2.657293, dev_score = 0.6745\n",
            "2023-05-14 20:54:31 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:54:31 INFO: new best model saved.\n",
            "2023-05-14 20:54:41 INFO: Finished STEP 1020/10000, loss = 2.331150 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:54:52 INFO: Finished STEP 1040/10000, loss = 1.911808 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:55:02 INFO: Finished STEP 1060/10000, loss = 2.762334 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:55:13 INFO: Finished STEP 1080/10000, loss = 2.829529 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:55:23 INFO: Finished STEP 1100/10000, loss = 12.639705 (0.653 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:55:23 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:55:25 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:55:25 INFO: 67.13\t61.88\t64.09\n",
            "2023-05-14 20:55:25 INFO: step 1100: train_loss = 2.674193, dev_score = 0.6713\n",
            "2023-05-14 20:55:36 INFO: Finished STEP 1120/10000, loss = 2.519087 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:55:47 INFO: Finished STEP 1140/10000, loss = 1.039455 (0.501 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:55:57 INFO: Finished STEP 1160/10000, loss = 2.482865 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:56:07 INFO: Finished STEP 1180/10000, loss = 1.786042 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:56:18 INFO: Finished STEP 1200/10000, loss = 3.032991 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:56:18 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:56:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:56:20 INFO: 68.48\t63.64\t65.89\n",
            "2023-05-14 20:56:20 INFO: step 1200: train_loss = 2.529581, dev_score = 0.6848\n",
            "2023-05-14 20:56:21 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:56:21 INFO: new best model saved.\n",
            "2023-05-14 20:56:31 INFO: Finished STEP 1220/10000, loss = 2.428026 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:56:42 INFO: Finished STEP 1240/10000, loss = 1.929304 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:56:52 INFO: Finished STEP 1260/10000, loss = 3.377287 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:57:03 INFO: Finished STEP 1280/10000, loss = 2.122885 (0.367 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:57:13 INFO: Finished STEP 1300/10000, loss = 1.367567 (0.428 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:57:13 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:57:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:57:15 INFO: 68.84\t64.17\t66.37\n",
            "2023-05-14 20:57:15 INFO: step 1300: train_loss = 2.469383, dev_score = 0.6884\n",
            "2023-05-14 20:57:16 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:57:16 INFO: new best model saved.\n",
            "2023-05-14 20:57:26 INFO: Finished STEP 1320/10000, loss = 2.219299 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:57:36 INFO: Finished STEP 1340/10000, loss = 2.231485 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:57:47 INFO: Finished STEP 1360/10000, loss = 2.234023 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:57:58 INFO: Finished STEP 1380/10000, loss = 3.642326 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:58:08 INFO: Finished STEP 1400/10000, loss = 2.530294 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:58:08 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:58:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:58:11 INFO: 68.88\t64.04\t66.32\n",
            "2023-05-14 20:58:11 INFO: step 1400: train_loss = 2.558708, dev_score = 0.6888\n",
            "2023-05-14 20:58:11 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:58:11 INFO: new best model saved.\n",
            "2023-05-14 20:58:21 INFO: Finished STEP 1420/10000, loss = 2.946272 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:58:32 INFO: Finished STEP 1440/10000, loss = 2.348015 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:58:42 INFO: Finished STEP 1460/10000, loss = 2.043164 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:58:53 INFO: Finished STEP 1480/10000, loss = 3.012045 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:59:03 INFO: Finished STEP 1500/10000, loss = 1.609744 (0.414 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:59:03 INFO: Evaluating on dev set...\n",
            "2023-05-14 20:59:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 20:59:06 INFO: 69.34\t64.61\t66.83\n",
            "2023-05-14 20:59:06 INFO: step 1500: train_loss = 2.397611, dev_score = 0.6934\n",
            "2023-05-14 20:59:06 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 20:59:06 INFO: new best model saved.\n",
            "2023-05-14 20:59:16 INFO: Finished STEP 1520/10000, loss = 1.649583 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:59:27 INFO: Finished STEP 1540/10000, loss = 1.871503 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:59:37 INFO: Finished STEP 1560/10000, loss = 2.301882 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:59:48 INFO: Finished STEP 1580/10000, loss = 2.077231 (0.362 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:59:58 INFO: Finished STEP 1600/10000, loss = 1.731315 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-14 20:59:58 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:00:01 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:00:01 INFO: 68.94\t64.28\t66.47\n",
            "2023-05-14 21:00:01 INFO: step 1600: train_loss = 2.530606, dev_score = 0.6894\n",
            "2023-05-14 21:00:11 INFO: Finished STEP 1620/10000, loss = 2.899044 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:00:21 INFO: Finished STEP 1640/10000, loss = 2.389329 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:00:32 INFO: Finished STEP 1660/10000, loss = 1.261821 (0.424 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:00:43 INFO: Finished STEP 1680/10000, loss = 1.948973 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:00:53 INFO: Finished STEP 1700/10000, loss = 1.482229 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:00:53 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:00:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:00:56 INFO: 69.42\t64.79\t66.93\n",
            "2023-05-14 21:00:56 INFO: step 1700: train_loss = 2.410935, dev_score = 0.6942\n",
            "2023-05-14 21:00:56 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:00:56 INFO: new best model saved.\n",
            "2023-05-14 21:01:06 INFO: Finished STEP 1720/10000, loss = 1.374725 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:01:17 INFO: Finished STEP 1740/10000, loss = 2.211364 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:01:27 INFO: Finished STEP 1760/10000, loss = 2.361688 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:01:38 INFO: Finished STEP 1780/10000, loss = 1.698183 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:01:48 INFO: Finished STEP 1800/10000, loss = 2.337851 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:01:48 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:01:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:01:51 INFO: 69.84\t65.22\t67.48\n",
            "2023-05-14 21:01:51 INFO: step 1800: train_loss = 2.346852, dev_score = 0.6984\n",
            "2023-05-14 21:01:51 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:01:51 INFO: new best model saved.\n",
            "2023-05-14 21:02:01 INFO: Finished STEP 1820/10000, loss = 1.392981 (0.416 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:02:12 INFO: Finished STEP 1840/10000, loss = 1.351003 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:02:22 INFO: Finished STEP 1860/10000, loss = 2.452110 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:02:33 INFO: Finished STEP 1880/10000, loss = 1.118984 (0.425 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:02:43 INFO: Finished STEP 1900/10000, loss = 1.588550 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:02:43 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:02:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:02:46 INFO: 69.51\t64.69\t66.98\n",
            "2023-05-14 21:02:46 INFO: step 1900: train_loss = 2.336853, dev_score = 0.6951\n",
            "2023-05-14 21:02:56 INFO: Finished STEP 1920/10000, loss = 1.426711 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:03:06 INFO: Finished STEP 1940/10000, loss = 1.804585 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:03:17 INFO: Finished STEP 1960/10000, loss = 0.890284 (0.493 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:03:28 INFO: Finished STEP 1980/10000, loss = 1.879417 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:03:38 INFO: Finished STEP 2000/10000, loss = 1.675523 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:03:38 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:03:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:03:41 INFO: 69.85\t65.16\t67.44\n",
            "2023-05-14 21:03:41 INFO: step 2000: train_loss = 2.398827, dev_score = 0.6985\n",
            "2023-05-14 21:03:41 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:03:41 INFO: new best model saved.\n",
            "2023-05-14 21:03:51 INFO: Finished STEP 2020/10000, loss = 2.703395 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:04:02 INFO: Finished STEP 2040/10000, loss = 1.982498 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:04:13 INFO: Finished STEP 2060/10000, loss = 1.266283 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:04:23 INFO: Finished STEP 2080/10000, loss = 2.586047 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:04:33 INFO: Finished STEP 2100/10000, loss = 9.581307 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:04:33 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:04:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:04:36 INFO: 69.83\t65.05\t67.46\n",
            "2023-05-14 21:04:36 INFO: step 2100: train_loss = 2.344729, dev_score = 0.6983\n",
            "2023-05-14 21:04:46 INFO: Finished STEP 2120/10000, loss = 2.075992 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:04:57 INFO: Finished STEP 2140/10000, loss = 1.258459 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:05:08 INFO: Finished STEP 2160/10000, loss = 1.660646 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:05:18 INFO: Finished STEP 2180/10000, loss = 10.838283 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:05:28 INFO: Finished STEP 2200/10000, loss = 2.788924 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:05:28 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:05:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:05:31 INFO: 70.03\t65.61\t67.69\n",
            "2023-05-14 21:05:31 INFO: step 2200: train_loss = 2.208696, dev_score = 0.7003\n",
            "2023-05-14 21:05:31 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:05:31 INFO: new best model saved.\n",
            "2023-05-14 21:05:41 INFO: Finished STEP 2220/10000, loss = 1.234924 (0.420 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:05:52 INFO: Finished STEP 2240/10000, loss = 2.013776 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:06:03 INFO: Finished STEP 2260/10000, loss = 2.151339 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:06:13 INFO: Finished STEP 2280/10000, loss = 1.452624 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:06:23 INFO: Finished STEP 2300/10000, loss = 2.166359 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:06:23 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:06:26 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:06:26 INFO: 70.02\t65.17\t67.45\n",
            "2023-05-14 21:06:26 INFO: step 2300: train_loss = 2.372671, dev_score = 0.7002\n",
            "2023-05-14 21:06:36 INFO: Finished STEP 2320/10000, loss = 2.237765 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:06:47 INFO: Finished STEP 2340/10000, loss = 1.616243 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:06:57 INFO: Finished STEP 2360/10000, loss = 1.380587 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:07:08 INFO: Finished STEP 2380/10000, loss = 2.026080 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:07:18 INFO: Finished STEP 2400/10000, loss = 1.666417 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:07:18 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:07:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:07:21 INFO: 69.87\t65.09\t67.31\n",
            "2023-05-14 21:07:21 INFO: step 2400: train_loss = 2.307443, dev_score = 0.6987\n",
            "2023-05-14 21:07:31 INFO: Finished STEP 2420/10000, loss = 3.118694 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:07:41 INFO: Finished STEP 2440/10000, loss = 1.838746 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:07:52 INFO: Finished STEP 2460/10000, loss = 1.362615 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:08:03 INFO: Finished STEP 2480/10000, loss = 1.928590 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:08:13 INFO: Finished STEP 2500/10000, loss = 2.382706 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:08:13 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:08:16 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:08:16 INFO: 69.90\t65.14\t67.30\n",
            "2023-05-14 21:08:16 INFO: step 2500: train_loss = 2.246862, dev_score = 0.6990\n",
            "2023-05-14 21:08:26 INFO: Finished STEP 2520/10000, loss = 1.724693 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:08:37 INFO: Finished STEP 2540/10000, loss = 1.472684 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:08:47 INFO: Finished STEP 2560/10000, loss = 1.715272 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:08:58 INFO: Finished STEP 2580/10000, loss = 2.015159 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:09:08 INFO: Finished STEP 2600/10000, loss = 1.450053 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:09:08 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:09:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:09:11 INFO: 70.20\t65.45\t67.69\n",
            "2023-05-14 21:09:11 INFO: step 2600: train_loss = 2.168670, dev_score = 0.7020\n",
            "2023-05-14 21:09:11 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:09:11 INFO: new best model saved.\n",
            "2023-05-14 21:09:21 INFO: Finished STEP 2620/10000, loss = 2.649769 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:09:32 INFO: Finished STEP 2640/10000, loss = 2.532732 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:09:42 INFO: Finished STEP 2660/10000, loss = 2.652889 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:09:53 INFO: Finished STEP 2680/10000, loss = 1.063953 (0.429 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:10:03 INFO: Finished STEP 2700/10000, loss = 2.721624 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:10:03 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:10:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:10:06 INFO: 70.38\t65.56\t67.84\n",
            "2023-05-14 21:10:06 INFO: step 2700: train_loss = 2.301106, dev_score = 0.7038\n",
            "2023-05-14 21:10:06 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:10:06 INFO: new best model saved.\n",
            "2023-05-14 21:10:17 INFO: Finished STEP 2720/10000, loss = 2.107197 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:10:27 INFO: Finished STEP 2740/10000, loss = 1.480780 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:10:37 INFO: Finished STEP 2760/10000, loss = 0.700002 (0.278 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:10:48 INFO: Finished STEP 2780/10000, loss = 1.207423 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:10:58 INFO: Finished STEP 2800/10000, loss = 1.716182 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:10:58 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:11:01 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:11:01 INFO: 70.54\t65.82\t68.11\n",
            "2023-05-14 21:11:01 INFO: step 2800: train_loss = 2.249011, dev_score = 0.7054\n",
            "2023-05-14 21:11:02 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:11:02 INFO: new best model saved.\n",
            "2023-05-14 21:11:12 INFO: Finished STEP 2820/10000, loss = 1.986602 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:11:22 INFO: Finished STEP 2840/10000, loss = 2.609516 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:11:32 INFO: Finished STEP 2860/10000, loss = 1.602085 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:11:43 INFO: Finished STEP 2880/10000, loss = 9.448394 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:11:54 INFO: Finished STEP 2900/10000, loss = 2.311957 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:11:54 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:11:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:11:57 INFO: 70.01\t65.27\t67.42\n",
            "2023-05-14 21:11:57 INFO: step 2900: train_loss = 2.161245, dev_score = 0.7001\n",
            "2023-05-14 21:12:07 INFO: Finished STEP 2920/10000, loss = 1.805376 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:12:17 INFO: Finished STEP 2940/10000, loss = 1.509142 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:12:28 INFO: Finished STEP 2960/10000, loss = 1.036524 (0.425 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:12:38 INFO: Finished STEP 2980/10000, loss = 1.522796 (0.402 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:12:48 INFO: Finished STEP 3000/10000, loss = 2.267240 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:12:48 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:12:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:12:51 INFO: 70.23\t65.59\t67.77\n",
            "2023-05-14 21:12:51 INFO: step 3000: train_loss = 2.221758, dev_score = 0.7023\n",
            "2023-05-14 21:13:02 INFO: Finished STEP 3020/10000, loss = 1.651289 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:13:12 INFO: Finished STEP 3040/10000, loss = 2.682068 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:13:22 INFO: Finished STEP 3060/10000, loss = 1.890958 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:13:34 INFO: Finished STEP 3080/10000, loss = 1.766276 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:13:44 INFO: Finished STEP 3100/10000, loss = 1.459101 (0.411 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:13:44 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:13:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:13:46 INFO: 70.16\t65.73\t67.79\n",
            "2023-05-14 21:13:46 INFO: step 3100: train_loss = 2.256457, dev_score = 0.7016\n",
            "2023-05-14 21:13:57 INFO: Finished STEP 3120/10000, loss = 3.060891 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:14:07 INFO: Finished STEP 3140/10000, loss = 1.903588 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:14:17 INFO: Finished STEP 3160/10000, loss = 1.286340 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:14:28 INFO: Finished STEP 3180/10000, loss = 0.800346 (0.503 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:14:38 INFO: Finished STEP 3200/10000, loss = 1.612496 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:14:38 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:14:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:14:41 INFO: 70.38\t65.94\t68.17\n",
            "2023-05-14 21:14:41 INFO: step 3200: train_loss = 2.120308, dev_score = 0.7038\n",
            "2023-05-14 21:14:52 INFO: Finished STEP 3220/10000, loss = 2.541523 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:15:02 INFO: Finished STEP 3240/10000, loss = 1.751432 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:15:13 INFO: Finished STEP 3260/10000, loss = 1.301484 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:15:23 INFO: Finished STEP 3280/10000, loss = 1.676892 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:15:33 INFO: Finished STEP 3300/10000, loss = 9.440289 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:15:33 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:15:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:15:36 INFO: 70.49\t65.92\t68.23\n",
            "2023-05-14 21:15:36 INFO: step 3300: train_loss = 2.194743, dev_score = 0.7049\n",
            "2023-05-14 21:15:46 INFO: Finished STEP 3320/10000, loss = 2.164742 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:15:57 INFO: Finished STEP 3340/10000, loss = 2.159995 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:16:07 INFO: Finished STEP 3360/10000, loss = 1.801957 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:16:18 INFO: Finished STEP 3380/10000, loss = 2.212873 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:16:29 INFO: Finished STEP 3400/10000, loss = 2.331758 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:16:29 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:16:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:16:32 INFO: 70.61\t66.06\t68.19\n",
            "2023-05-14 21:16:32 INFO: step 3400: train_loss = 2.134782, dev_score = 0.7061\n",
            "2023-05-14 21:16:32 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:16:32 INFO: new best model saved.\n",
            "2023-05-14 21:16:42 INFO: Finished STEP 3420/10000, loss = 1.805892 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:16:52 INFO: Finished STEP 3440/10000, loss = 2.590325 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:17:03 INFO: Finished STEP 3460/10000, loss = 1.385952 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:17:14 INFO: Finished STEP 3480/10000, loss = 2.114809 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:17:24 INFO: Finished STEP 3500/10000, loss = 9.218737 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:17:24 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:17:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:17:27 INFO: 70.84\t66.11\t68.33\n",
            "2023-05-14 21:17:27 INFO: step 3500: train_loss = 2.185660, dev_score = 0.7084\n",
            "2023-05-14 21:17:27 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:17:27 INFO: new best model saved.\n",
            "2023-05-14 21:17:37 INFO: Finished STEP 3520/10000, loss = 1.744705 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:17:48 INFO: Finished STEP 3540/10000, loss = 2.379717 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:17:58 INFO: Finished STEP 3560/10000, loss = 1.940726 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:18:09 INFO: Finished STEP 3580/10000, loss = 1.721019 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:18:19 INFO: Finished STEP 3600/10000, loss = 9.291925 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:18:19 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:18:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:18:22 INFO: 70.69\t66.03\t68.31\n",
            "2023-05-14 21:18:22 INFO: step 3600: train_loss = 2.125229, dev_score = 0.7069\n",
            "2023-05-14 21:18:32 INFO: Finished STEP 3620/10000, loss = 0.718717 (0.274 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:18:43 INFO: Finished STEP 3640/10000, loss = 2.128943 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:18:53 INFO: Finished STEP 3660/10000, loss = 1.540716 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:19:04 INFO: Finished STEP 3680/10000, loss = 1.829163 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:19:14 INFO: Finished STEP 3700/10000, loss = 1.801241 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:19:14 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:19:17 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:19:17 INFO: 70.30\t65.66\t67.97\n",
            "2023-05-14 21:19:17 INFO: step 3700: train_loss = 2.081327, dev_score = 0.7030\n",
            "2023-05-14 21:19:27 INFO: Finished STEP 3720/10000, loss = 1.537642 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:19:37 INFO: Finished STEP 3740/10000, loss = 10.570957 (0.636 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:19:47 INFO: Finished STEP 3760/10000, loss = 2.409810 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:19:59 INFO: Finished STEP 3780/10000, loss = 1.828082 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:20:09 INFO: Finished STEP 3800/10000, loss = 1.283083 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:20:09 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:20:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:20:12 INFO: 70.40\t65.73\t68.03\n",
            "2023-05-14 21:20:12 INFO: step 3800: train_loss = 2.033562, dev_score = 0.7040\n",
            "2023-05-14 21:20:22 INFO: Finished STEP 3820/10000, loss = 1.427298 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:20:32 INFO: Finished STEP 3840/10000, loss = 2.095366 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:20:43 INFO: Finished STEP 3860/10000, loss = 2.639041 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:20:54 INFO: Finished STEP 3880/10000, loss = 1.839658 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:21:04 INFO: Finished STEP 3900/10000, loss = 0.839764 (0.506 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:21:04 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:21:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:21:07 INFO: 70.46\t65.92\t68.09\n",
            "2023-05-14 21:21:07 INFO: step 3900: train_loss = 2.173757, dev_score = 0.7046\n",
            "2023-05-14 21:21:17 INFO: Finished STEP 3920/10000, loss = 1.862413 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:21:27 INFO: Finished STEP 3940/10000, loss = 1.704102 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:21:39 INFO: Finished STEP 3960/10000, loss = 1.067315 (0.426 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:21:49 INFO: Finished STEP 3980/10000, loss = 2.462187 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:21:59 INFO: Finished STEP 4000/10000, loss = 2.055634 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:21:59 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:22:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:22:02 INFO: 70.61\t65.98\t68.17\n",
            "2023-05-14 21:22:02 INFO: step 4000: train_loss = 1.946351, dev_score = 0.7061\n",
            "2023-05-14 21:22:12 INFO: Finished STEP 4020/10000, loss = 1.584043 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:22:23 INFO: Finished STEP 4040/10000, loss = 1.834223 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:22:33 INFO: Finished STEP 4060/10000, loss = 1.544237 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:22:44 INFO: Finished STEP 4080/10000, loss = 2.349725 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:22:54 INFO: Finished STEP 4100/10000, loss = 1.092598 (0.441 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:22:54 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:22:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:22:57 INFO: 70.43\t65.86\t68.03\n",
            "2023-05-14 21:22:57 INFO: step 4100: train_loss = 2.151318, dev_score = 0.7043\n",
            "2023-05-14 21:23:07 INFO: Finished STEP 4120/10000, loss = 2.682845 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:23:18 INFO: Finished STEP 4140/10000, loss = 1.981885 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:23:28 INFO: Finished STEP 4160/10000, loss = 1.722249 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:23:39 INFO: Finished STEP 4180/10000, loss = 1.118168 (0.430 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:23:49 INFO: Finished STEP 4200/10000, loss = 0.789566 (0.502 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:23:49 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:23:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:23:52 INFO: 70.74\t66.21\t68.29\n",
            "2023-05-14 21:23:52 INFO: step 4200: train_loss = 2.173953, dev_score = 0.7074\n",
            "2023-05-14 21:24:02 INFO: Finished STEP 4220/10000, loss = 1.410632 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:24:13 INFO: Finished STEP 4240/10000, loss = 1.115492 (0.413 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:24:23 INFO: Finished STEP 4260/10000, loss = 2.775025 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:24:33 INFO: Finished STEP 4280/10000, loss = 2.262163 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:24:44 INFO: Finished STEP 4300/10000, loss = 1.255904 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:24:44 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:24:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:24:46 INFO: 70.35\t65.71\t67.89\n",
            "2023-05-14 21:24:46 INFO: step 4300: train_loss = 2.024195, dev_score = 0.7035\n",
            "2023-05-14 21:24:57 INFO: Finished STEP 4320/10000, loss = 1.585711 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:25:07 INFO: Finished STEP 4340/10000, loss = 1.945471 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:25:18 INFO: Finished STEP 4360/10000, loss = 1.376884 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:25:28 INFO: Finished STEP 4380/10000, loss = 1.822397 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:25:39 INFO: Finished STEP 4400/10000, loss = 3.063729 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:25:39 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:25:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:25:41 INFO: 70.87\t66.30\t68.54\n",
            "2023-05-14 21:25:41 INFO: step 4400: train_loss = 2.063947, dev_score = 0.7087\n",
            "2023-05-14 21:25:41 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:25:41 INFO: new best model saved.\n",
            "2023-05-14 21:25:52 INFO: Finished STEP 4420/10000, loss = 2.648552 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:26:03 INFO: Finished STEP 4440/10000, loss = 1.137522 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:26:13 INFO: Finished STEP 4460/10000, loss = 1.967711 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:26:24 INFO: Finished STEP 4480/10000, loss = 1.453469 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:26:34 INFO: Finished STEP 4500/10000, loss = 1.990023 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:26:34 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:26:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:26:37 INFO: 70.84\t66.29\t68.34\n",
            "2023-05-14 21:26:37 INFO: step 4500: train_loss = 2.114662, dev_score = 0.7084\n",
            "2023-05-14 21:26:47 INFO: Finished STEP 4520/10000, loss = 2.322526 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:26:58 INFO: Finished STEP 4540/10000, loss = 1.779978 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:27:08 INFO: Finished STEP 4560/10000, loss = 2.798944 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:27:19 INFO: Finished STEP 4580/10000, loss = 0.755332 (0.517 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:27:29 INFO: Finished STEP 4600/10000, loss = 0.936440 (0.422 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:27:29 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:27:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:27:31 INFO: 70.92\t66.41\t68.46\n",
            "2023-05-14 21:27:31 INFO: step 4600: train_loss = 1.991088, dev_score = 0.7092\n",
            "2023-05-14 21:27:32 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:27:32 INFO: new best model saved.\n",
            "2023-05-14 21:27:43 INFO: Finished STEP 4620/10000, loss = 2.968967 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:27:53 INFO: Finished STEP 4640/10000, loss = 1.802559 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:28:03 INFO: Finished STEP 4660/10000, loss = 1.594432 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:28:14 INFO: Finished STEP 4680/10000, loss = 2.808560 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:28:25 INFO: Finished STEP 4700/10000, loss = 0.859075 (0.502 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:28:25 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:28:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:28:27 INFO: 70.61\t66.07\t68.18\n",
            "2023-05-14 21:28:27 INFO: step 4700: train_loss = 1.994135, dev_score = 0.7061\n",
            "2023-05-14 21:28:38 INFO: Finished STEP 4720/10000, loss = 1.544762 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:28:48 INFO: Finished STEP 4740/10000, loss = 2.151581 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:28:58 INFO: Finished STEP 4760/10000, loss = 1.298968 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:29:09 INFO: Finished STEP 4780/10000, loss = 10.946879 (0.650 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:29:19 INFO: Finished STEP 4800/10000, loss = 2.601369 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:29:19 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:29:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:29:22 INFO: 70.64\t65.98\t68.12\n",
            "2023-05-14 21:29:22 INFO: step 4800: train_loss = 2.045641, dev_score = 0.7064\n",
            "2023-05-14 21:29:32 INFO: Finished STEP 4820/10000, loss = 1.716361 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:29:43 INFO: Finished STEP 4840/10000, loss = 1.708355 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:29:53 INFO: Finished STEP 4860/10000, loss = 2.523743 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:30:04 INFO: Finished STEP 4880/10000, loss = 1.742433 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:30:14 INFO: Finished STEP 4900/10000, loss = 1.147838 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:30:14 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:30:17 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:30:17 INFO: 70.81\t66.14\t68.36\n",
            "2023-05-14 21:30:17 INFO: step 4900: train_loss = 2.072528, dev_score = 0.7081\n",
            "2023-05-14 21:30:27 INFO: Finished STEP 4920/10000, loss = 1.709265 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:30:38 INFO: Finished STEP 4940/10000, loss = 1.087355 (0.421 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:30:48 INFO: Finished STEP 4960/10000, loss = 1.780819 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:30:59 INFO: Finished STEP 4980/10000, loss = 1.453962 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:31:09 INFO: Finished STEP 5000/10000, loss = 10.286760 (0.645 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:31:09 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:31:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:31:12 INFO: 70.75\t66.17\t68.39\n",
            "2023-05-14 21:31:12 INFO: step 5000: train_loss = 2.066739, dev_score = 0.7075\n",
            "2023-05-14 21:31:22 INFO: Finished STEP 5020/10000, loss = 2.061337 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:31:33 INFO: Finished STEP 5040/10000, loss = 2.941394 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:31:43 INFO: Finished STEP 5060/10000, loss = 2.096484 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:31:54 INFO: Finished STEP 5080/10000, loss = 0.776227 (0.516 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:32:04 INFO: Finished STEP 5100/10000, loss = 2.199922 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:32:04 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:32:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:32:05 INFO: 70.59\t66.16\t68.19\n",
            "2023-05-14 21:32:05 INFO: step 5100: train_loss = 1.902490, dev_score = 0.7059\n",
            "2023-05-14 21:32:16 INFO: Finished STEP 5120/10000, loss = 2.918929 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:32:27 INFO: Finished STEP 5140/10000, loss = 1.344457 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:32:37 INFO: Finished STEP 5160/10000, loss = 1.490333 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:32:48 INFO: Finished STEP 5180/10000, loss = 2.180264 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:32:58 INFO: Finished STEP 5200/10000, loss = 1.369576 (0.405 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:32:58 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:33:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:33:00 INFO: 70.86\t66.37\t68.55\n",
            "2023-05-14 21:33:00 INFO: step 5200: train_loss = 2.070764, dev_score = 0.7086\n",
            "2023-05-14 21:33:11 INFO: Finished STEP 5220/10000, loss = 2.130693 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:33:21 INFO: Finished STEP 5240/10000, loss = 0.948200 (0.421 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:33:31 INFO: Finished STEP 5260/10000, loss = 1.435372 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:33:42 INFO: Finished STEP 5280/10000, loss = 1.779217 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:33:53 INFO: Finished STEP 5300/10000, loss = 1.041174 (0.422 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:33:53 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:33:55 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:33:55 INFO: 70.67\t66.08\t68.30\n",
            "2023-05-14 21:33:55 INFO: step 5300: train_loss = 2.064018, dev_score = 0.7067\n",
            "2023-05-14 21:34:05 INFO: Finished STEP 5320/10000, loss = 2.125275 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:34:16 INFO: Finished STEP 5340/10000, loss = 1.497199 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:34:26 INFO: Finished STEP 5360/10000, loss = 1.359034 (0.416 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:34:36 INFO: Finished STEP 5380/10000, loss = 1.284132 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:34:47 INFO: Finished STEP 5400/10000, loss = 1.553900 (0.366 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:34:47 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:34:49 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:34:49 INFO: 70.49\t66.05\t68.14\n",
            "2023-05-14 21:34:49 INFO: step 5400: train_loss = 1.948080, dev_score = 0.7049\n",
            "2023-05-14 21:34:59 INFO: Finished STEP 5420/10000, loss = 1.594199 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:35:10 INFO: Finished STEP 5440/10000, loss = 1.979364 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:35:20 INFO: Finished STEP 5460/10000, loss = 0.693935 (0.285 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:35:31 INFO: Finished STEP 5480/10000, loss = 1.796933 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:35:41 INFO: Finished STEP 5500/10000, loss = 0.832985 (0.442 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:35:41 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:35:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:35:43 INFO: 70.76\t66.20\t68.38\n",
            "2023-05-14 21:35:43 INFO: step 5500: train_loss = 1.988658, dev_score = 0.7076\n",
            "2023-05-14 21:35:54 INFO: Finished STEP 5520/10000, loss = 2.011170 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:36:04 INFO: Finished STEP 5540/10000, loss = 2.126457 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:36:14 INFO: Finished STEP 5560/10000, loss = 9.286976 (0.410 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:36:25 INFO: Finished STEP 5580/10000, loss = 1.825530 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:36:36 INFO: Finished STEP 5600/10000, loss = 2.375554 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:36:36 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:36:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:36:37 INFO: 70.93\t66.35\t68.57\n",
            "2023-05-14 21:36:37 INFO: step 5600: train_loss = 2.036304, dev_score = 0.7093\n",
            "2023-05-14 21:36:37 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:36:37 INFO: new best model saved.\n",
            "2023-05-14 21:36:48 INFO: Finished STEP 5620/10000, loss = 1.312793 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:36:59 INFO: Finished STEP 5640/10000, loss = 2.195290 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:37:09 INFO: Finished STEP 5660/10000, loss = 1.468313 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:37:20 INFO: Finished STEP 5680/10000, loss = 1.276514 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:37:30 INFO: Finished STEP 5700/10000, loss = 1.747291 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:37:30 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:37:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:37:32 INFO: 71.03\t66.65\t68.79\n",
            "2023-05-14 21:37:32 INFO: step 5700: train_loss = 1.954161, dev_score = 0.7103\n",
            "2023-05-14 21:37:32 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:37:32 INFO: new best model saved.\n",
            "2023-05-14 21:37:43 INFO: Finished STEP 5720/10000, loss = 2.176990 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:37:53 INFO: Finished STEP 5740/10000, loss = 1.312609 (0.399 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:38:04 INFO: Finished STEP 5760/10000, loss = 10.001751 (0.645 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:38:14 INFO: Finished STEP 5780/10000, loss = 2.822745 (0.391 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:38:25 INFO: Finished STEP 5800/10000, loss = 1.360124 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:38:25 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:38:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:38:27 INFO: 70.87\t66.48\t68.59\n",
            "2023-05-14 21:38:27 INFO: step 5800: train_loss = 1.934599, dev_score = 0.7087\n",
            "2023-05-14 21:38:37 INFO: Finished STEP 5820/10000, loss = 1.145621 (0.399 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:38:47 INFO: Finished STEP 5840/10000, loss = 2.129840 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:38:58 INFO: Finished STEP 5860/10000, loss = 1.670059 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:39:09 INFO: Finished STEP 5880/10000, loss = 1.510715 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:39:19 INFO: Finished STEP 5900/10000, loss = 1.354874 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:39:19 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:39:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:39:21 INFO: 70.67\t66.20\t68.46\n",
            "2023-05-14 21:39:21 INFO: step 5900: train_loss = 1.948886, dev_score = 0.7067\n",
            "2023-05-14 21:39:32 INFO: Finished STEP 5920/10000, loss = 1.884747 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:39:42 INFO: Finished STEP 5940/10000, loss = 1.975984 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:39:52 INFO: Finished STEP 5960/10000, loss = 1.541381 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:40:03 INFO: Finished STEP 5980/10000, loss = 1.159245 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:40:13 INFO: Finished STEP 6000/10000, loss = 0.930370 (0.425 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:40:13 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:40:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:40:15 INFO: 71.17\t66.71\t68.99\n",
            "2023-05-14 21:40:15 INFO: step 6000: train_loss = 1.992130, dev_score = 0.7117\n",
            "2023-05-14 21:40:16 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:40:16 INFO: new best model saved.\n",
            "2023-05-14 21:40:26 INFO: Finished STEP 6020/10000, loss = 2.168256 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:40:36 INFO: Finished STEP 6040/10000, loss = 1.420807 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:40:47 INFO: Finished STEP 6060/10000, loss = 8.942604 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:40:57 INFO: Finished STEP 6080/10000, loss = 1.659178 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:41:08 INFO: Finished STEP 6100/10000, loss = 1.673078 (0.365 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:41:08 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:41:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:41:10 INFO: 71.05\t66.53\t68.69\n",
            "2023-05-14 21:41:10 INFO: step 6100: train_loss = 1.948624, dev_score = 0.7105\n",
            "2023-05-14 21:41:20 INFO: Finished STEP 6120/10000, loss = 1.382358 (0.403 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:41:31 INFO: Finished STEP 6140/10000, loss = 1.880085 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:41:42 INFO: Finished STEP 6160/10000, loss = 1.038454 (0.413 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:41:52 INFO: Finished STEP 6180/10000, loss = 2.277659 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:42:02 INFO: Finished STEP 6200/10000, loss = 1.633492 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:42:02 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:42:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:42:04 INFO: 70.27\t65.63\t67.91\n",
            "2023-05-14 21:42:04 INFO: step 6200: train_loss = 2.006236, dev_score = 0.7027\n",
            "2023-05-14 21:42:15 INFO: Finished STEP 6220/10000, loss = 1.162713 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:42:25 INFO: Finished STEP 6240/10000, loss = 2.784791 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:42:36 INFO: Finished STEP 6260/10000, loss = 1.279788 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:42:46 INFO: Finished STEP 6280/10000, loss = 1.658052 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:42:57 INFO: Finished STEP 6300/10000, loss = 1.572914 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:42:57 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:42:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:42:59 INFO: 70.54\t65.98\t68.03\n",
            "2023-05-14 21:42:59 INFO: step 6300: train_loss = 1.910579, dev_score = 0.7054\n",
            "2023-05-14 21:43:09 INFO: Finished STEP 6320/10000, loss = 1.844533 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:43:19 INFO: Finished STEP 6340/10000, loss = 1.414956 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:43:30 INFO: Finished STEP 6360/10000, loss = 1.454806 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:43:40 INFO: Finished STEP 6380/10000, loss = 1.670436 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:43:51 INFO: Finished STEP 6400/10000, loss = 1.648857 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:43:51 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:43:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:43:53 INFO: 70.77\t66.22\t68.28\n",
            "2023-05-14 21:43:53 INFO: step 6400: train_loss = 1.933384, dev_score = 0.7077\n",
            "2023-05-14 21:44:03 INFO: Finished STEP 6420/10000, loss = 2.297189 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:44:13 INFO: Finished STEP 6440/10000, loss = 2.155445 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:44:24 INFO: Finished STEP 6460/10000, loss = 1.679697 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:44:35 INFO: Finished STEP 6480/10000, loss = 1.702213 (0.359 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:44:45 INFO: Finished STEP 6500/10000, loss = 2.314570 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:44:45 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:44:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:44:47 INFO: 70.75\t66.41\t68.56\n",
            "2023-05-14 21:44:47 INFO: step 6500: train_loss = 1.974397, dev_score = 0.7075\n",
            "2023-05-14 21:44:58 INFO: Finished STEP 6520/10000, loss = 0.964493 (0.421 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:45:08 INFO: Finished STEP 6540/10000, loss = 2.305136 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:45:19 INFO: Finished STEP 6560/10000, loss = 0.885185 (0.448 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:45:29 INFO: Finished STEP 6580/10000, loss = 2.062598 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:45:39 INFO: Finished STEP 6600/10000, loss = 2.078934 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:45:39 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:45:42 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:45:42 INFO: 70.70\t66.35\t68.54\n",
            "2023-05-14 21:45:42 INFO: step 6600: train_loss = 1.908627, dev_score = 0.7070\n",
            "2023-05-14 21:45:53 INFO: Finished STEP 6620/10000, loss = 1.675894 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:46:03 INFO: Finished STEP 6640/10000, loss = 2.334661 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:46:14 INFO: Finished STEP 6660/10000, loss = 1.177961 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:46:24 INFO: Finished STEP 6680/10000, loss = 0.611378 (0.270 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:46:34 INFO: Finished STEP 6700/10000, loss = 1.050416 (0.430 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:46:34 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:46:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:46:37 INFO: 70.54\t66.06\t68.19\n",
            "2023-05-14 21:46:37 INFO: step 6700: train_loss = 1.911423, dev_score = 0.7054\n",
            "2023-05-14 21:46:47 INFO: Finished STEP 6720/10000, loss = 1.335400 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:46:58 INFO: Finished STEP 6740/10000, loss = 2.007305 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:47:08 INFO: Finished STEP 6760/10000, loss = 2.103508 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:47:19 INFO: Finished STEP 6780/10000, loss = 1.178606 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:47:29 INFO: Finished STEP 6800/10000, loss = 1.383114 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:47:29 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:47:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:47:32 INFO: 70.50\t66.04\t68.08\n",
            "2023-05-14 21:47:32 INFO: step 6800: train_loss = 1.990847, dev_score = 0.7050\n",
            "2023-05-14 21:47:42 INFO: Finished STEP 6820/10000, loss = 2.483727 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:47:53 INFO: Finished STEP 6840/10000, loss = 1.398854 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:48:03 INFO: Finished STEP 6860/10000, loss = 1.864690 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:48:14 INFO: Finished STEP 6880/10000, loss = 0.739534 (0.505 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:48:24 INFO: Finished STEP 6900/10000, loss = 1.347799 (0.408 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:48:24 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:48:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:48:27 INFO: 70.61\t65.94\t68.18\n",
            "2023-05-14 21:48:27 INFO: step 6900: train_loss = 1.891890, dev_score = 0.7061\n",
            "2023-05-14 21:48:37 INFO: Finished STEP 6920/10000, loss = 1.691843 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:48:48 INFO: Finished STEP 6940/10000, loss = 1.349375 (0.407 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:48:58 INFO: Finished STEP 6960/10000, loss = 1.600448 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:49:09 INFO: Finished STEP 6980/10000, loss = 1.611334 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:49:19 INFO: Finished STEP 7000/10000, loss = 1.740954 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:49:19 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:49:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:49:22 INFO: 70.73\t66.28\t68.46\n",
            "2023-05-14 21:49:22 INFO: step 7000: train_loss = 1.879116, dev_score = 0.7073\n",
            "2023-05-14 21:49:32 INFO: Finished STEP 7020/10000, loss = 1.504435 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:49:42 INFO: Finished STEP 7040/10000, loss = 1.610961 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:49:53 INFO: Finished STEP 7060/10000, loss = 1.372270 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:50:04 INFO: Finished STEP 7080/10000, loss = 1.813472 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:50:14 INFO: Finished STEP 7100/10000, loss = 1.328957 (0.416 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:50:14 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:50:16 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:50:16 INFO: 71.14\t66.69\t68.89\n",
            "2023-05-14 21:50:16 INFO: step 7100: train_loss = 1.957453, dev_score = 0.7114\n",
            "2023-05-14 21:50:27 INFO: Finished STEP 7120/10000, loss = 1.860752 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:50:37 INFO: Finished STEP 7140/10000, loss = 0.916326 (0.427 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:50:48 INFO: Finished STEP 7160/10000, loss = 1.694466 (0.364 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:50:59 INFO: Finished STEP 7180/10000, loss = 1.484422 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:51:09 INFO: Finished STEP 7200/10000, loss = 1.274891 (0.402 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:51:09 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:51:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:51:11 INFO: 70.81\t66.29\t68.47\n",
            "2023-05-14 21:51:11 INFO: step 7200: train_loss = 1.886438, dev_score = 0.7081\n",
            "2023-05-14 21:51:22 INFO: Finished STEP 7220/10000, loss = 2.211352 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:51:33 INFO: Finished STEP 7240/10000, loss = 0.794490 (0.499 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:51:43 INFO: Finished STEP 7260/10000, loss = 1.354005 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:51:53 INFO: Finished STEP 7280/10000, loss = 1.330621 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:52:04 INFO: Finished STEP 7300/10000, loss = 1.365277 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:52:04 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:52:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:52:06 INFO: 71.01\t66.51\t68.74\n",
            "2023-05-14 21:52:06 INFO: step 7300: train_loss = 1.878443, dev_score = 0.7101\n",
            "2023-05-14 21:52:17 INFO: Finished STEP 7320/10000, loss = 1.797855 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:52:27 INFO: Finished STEP 7340/10000, loss = 1.308913 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:52:38 INFO: Finished STEP 7360/10000, loss = 1.839977 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:52:48 INFO: Finished STEP 7380/10000, loss = 1.797927 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:52:59 INFO: Finished STEP 7400/10000, loss = 1.874303 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:52:59 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:53:01 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:53:01 INFO: 71.09\t66.62\t68.82\n",
            "2023-05-14 21:53:01 INFO: step 7400: train_loss = 1.941853, dev_score = 0.7109\n",
            "2023-05-14 21:53:12 INFO: Finished STEP 7420/10000, loss = 1.520163 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:53:22 INFO: Finished STEP 7440/10000, loss = 2.012609 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:53:33 INFO: Finished STEP 7460/10000, loss = 0.888922 (0.422 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:53:43 INFO: Finished STEP 7480/10000, loss = 1.424776 (0.421 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:53:54 INFO: Finished STEP 7500/10000, loss = 1.332486 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:53:54 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:53:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:53:56 INFO: 70.77\t66.23\t68.35\n",
            "2023-05-14 21:53:56 INFO: step 7500: train_loss = 1.897536, dev_score = 0.7077\n",
            "2023-05-14 21:54:07 INFO: Finished STEP 7520/10000, loss = 1.792943 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:54:17 INFO: Finished STEP 7540/10000, loss = 1.536564 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:54:28 INFO: Finished STEP 7560/10000, loss = 1.331380 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:54:39 INFO: Finished STEP 7580/10000, loss = 1.233038 (0.412 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:54:48 INFO: Finished STEP 7600/10000, loss = 1.147097 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:54:48 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:54:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:54:51 INFO: 71.20\t66.60\t68.68\n",
            "2023-05-14 21:54:51 INFO: step 7600: train_loss = 1.878983, dev_score = 0.7120\n",
            "2023-05-14 21:54:51 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:54:51 INFO: new best model saved.\n",
            "2023-05-14 21:55:02 INFO: Finished STEP 7620/10000, loss = 1.300052 (0.397 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:55:12 INFO: Finished STEP 7640/10000, loss = 1.500340 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:55:23 INFO: Finished STEP 7660/10000, loss = 1.091972 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:55:34 INFO: Finished STEP 7680/10000, loss = 1.704032 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:55:44 INFO: Finished STEP 7700/10000, loss = 1.274015 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:55:44 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:55:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:55:47 INFO: 71.06\t66.58\t68.63\n",
            "2023-05-14 21:55:47 INFO: step 7700: train_loss = 1.886549, dev_score = 0.7106\n",
            "2023-05-14 21:55:57 INFO: Finished STEP 7720/10000, loss = 1.269027 (0.398 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:56:07 INFO: Finished STEP 7740/10000, loss = 10.319777 (0.634 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:56:18 INFO: Finished STEP 7760/10000, loss = 1.498081 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:56:28 INFO: Finished STEP 7780/10000, loss = 1.368503 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:56:38 INFO: Finished STEP 7800/10000, loss = 1.550052 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:56:38 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:56:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:56:41 INFO: 71.11\t66.53\t68.73\n",
            "2023-05-14 21:56:41 INFO: step 7800: train_loss = 1.915613, dev_score = 0.7111\n",
            "2023-05-14 21:56:51 INFO: Finished STEP 7820/10000, loss = 0.780042 (0.498 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:57:01 INFO: Finished STEP 7840/10000, loss = 1.588669 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:57:12 INFO: Finished STEP 7860/10000, loss = 1.773387 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:57:23 INFO: Finished STEP 7880/10000, loss = 1.491524 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:57:33 INFO: Finished STEP 7900/10000, loss = 1.967810 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:57:33 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:57:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:57:34 INFO: 71.30\t66.77\t68.96\n",
            "2023-05-14 21:57:34 INFO: step 7900: train_loss = 1.931557, dev_score = 0.7130\n",
            "2023-05-14 21:57:35 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 21:57:35 INFO: new best model saved.\n",
            "2023-05-14 21:57:46 INFO: Finished STEP 7920/10000, loss = 0.751793 (0.501 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:57:56 INFO: Finished STEP 7940/10000, loss = 2.061693 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:58:07 INFO: Finished STEP 7960/10000, loss = 1.205912 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:58:17 INFO: Finished STEP 7980/10000, loss = 0.706374 (0.521 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:58:28 INFO: Finished STEP 8000/10000, loss = 1.746293 (0.368 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:58:28 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:58:30 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:58:30 INFO: 71.28\t66.76\t68.98\n",
            "2023-05-14 21:58:30 INFO: step 8000: train_loss = 1.780871, dev_score = 0.7128\n",
            "2023-05-14 21:58:40 INFO: Finished STEP 8020/10000, loss = 1.686238 (0.363 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:58:51 INFO: Finished STEP 8040/10000, loss = 0.981520 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:59:02 INFO: Finished STEP 8060/10000, loss = 0.697886 (0.497 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:59:12 INFO: Finished STEP 8080/10000, loss = 2.246268 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:59:22 INFO: Finished STEP 8100/10000, loss = 1.743061 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:59:22 INFO: Evaluating on dev set...\n",
            "2023-05-14 21:59:24 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 21:59:24 INFO: 71.17\t66.64\t68.75\n",
            "2023-05-14 21:59:24 INFO: step 8100: train_loss = 1.929344, dev_score = 0.7117\n",
            "2023-05-14 21:59:34 INFO: Finished STEP 8120/10000, loss = 1.557594 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:59:45 INFO: Finished STEP 8140/10000, loss = 1.657720 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-14 21:59:56 INFO: Finished STEP 8160/10000, loss = 1.642776 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:00:06 INFO: Finished STEP 8180/10000, loss = 1.062787 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:00:16 INFO: Finished STEP 8200/10000, loss = 2.837309 (0.394 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:00:16 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:00:18 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:00:18 INFO: 71.19\t66.82\t68.99\n",
            "2023-05-14 22:00:18 INFO: step 8200: train_loss = 1.925599, dev_score = 0.7119\n",
            "2023-05-14 22:00:29 INFO: Finished STEP 8220/10000, loss = 1.640021 (0.377 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:00:40 INFO: Finished STEP 8240/10000, loss = 1.393304 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:00:50 INFO: Finished STEP 8260/10000, loss = 1.415074 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:01:00 INFO: Finished STEP 8280/10000, loss = 1.793631 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:01:11 INFO: Finished STEP 8300/10000, loss = 1.665797 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:01:11 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:01:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:01:13 INFO: 71.09\t66.74\t68.83\n",
            "2023-05-14 22:01:13 INFO: step 8300: train_loss = 1.853754, dev_score = 0.7109\n",
            "2023-05-14 22:01:23 INFO: Finished STEP 8320/10000, loss = 0.950093 (0.422 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:01:34 INFO: Finished STEP 8340/10000, loss = 1.434064 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:01:45 INFO: Finished STEP 8360/10000, loss = 1.380582 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:01:55 INFO: Finished STEP 8380/10000, loss = 1.479472 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:02:05 INFO: Finished STEP 8400/10000, loss = 1.464942 (0.387 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:02:05 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:02:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:02:07 INFO: 71.48\t66.93\t69.09\n",
            "2023-05-14 22:02:07 INFO: step 8400: train_loss = 1.834765, dev_score = 0.7148\n",
            "2023-05-14 22:02:07 INFO: Model saved to ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 22:02:07 INFO: new best model saved.\n",
            "2023-05-14 22:02:18 INFO: Finished STEP 8420/10000, loss = 0.701494 (0.502 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:02:28 INFO: Finished STEP 8440/10000, loss = 2.211804 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:02:39 INFO: Finished STEP 8460/10000, loss = 1.595977 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:02:49 INFO: Finished STEP 8480/10000, loss = 1.483631 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:03:00 INFO: Finished STEP 8500/10000, loss = 1.776870 (0.370 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:03:00 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:03:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:03:02 INFO: 70.78\t66.23\t68.40\n",
            "2023-05-14 22:03:02 INFO: step 8500: train_loss = 1.846667, dev_score = 0.7078\n",
            "2023-05-14 22:03:12 INFO: Finished STEP 8520/10000, loss = 1.258819 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:03:23 INFO: Finished STEP 8540/10000, loss = 1.025594 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:03:33 INFO: Finished STEP 8560/10000, loss = 2.034792 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:03:44 INFO: Finished STEP 8580/10000, loss = 10.057602 (0.639 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:03:55 INFO: Finished STEP 8600/10000, loss = 1.496550 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:03:55 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:03:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:03:56 INFO: 70.78\t66.11\t68.30\n",
            "2023-05-14 22:03:56 INFO: step 8600: train_loss = 1.906284, dev_score = 0.7078\n",
            "2023-05-14 22:04:07 INFO: Finished STEP 8620/10000, loss = 0.727570 (0.498 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:04:17 INFO: Finished STEP 8640/10000, loss = 0.988819 (0.420 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:04:27 INFO: Finished STEP 8660/10000, loss = 1.722059 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:04:38 INFO: Finished STEP 8680/10000, loss = 1.674703 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:04:49 INFO: Finished STEP 8700/10000, loss = 1.740717 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:04:49 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:04:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:04:50 INFO: 71.03\t66.52\t68.62\n",
            "2023-05-14 22:04:50 INFO: step 8700: train_loss = 1.844776, dev_score = 0.7103\n",
            "2023-05-14 22:05:01 INFO: Finished STEP 8720/10000, loss = 1.568809 (0.374 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:05:12 INFO: Finished STEP 8740/10000, loss = 1.295821 (0.409 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:05:22 INFO: Finished STEP 8760/10000, loss = 2.609264 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:05:32 INFO: Finished STEP 8780/10000, loss = 2.409791 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:05:43 INFO: Finished STEP 8800/10000, loss = 1.708121 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:05:43 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:05:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:05:45 INFO: 70.75\t66.24\t68.26\n",
            "2023-05-14 22:05:45 INFO: step 8800: train_loss = 1.909006, dev_score = 0.7075\n",
            "2023-05-14 22:05:55 INFO: Finished STEP 8820/10000, loss = 1.653586 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:06:06 INFO: Finished STEP 8840/10000, loss = 1.789520 (0.388 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:06:16 INFO: Finished STEP 8860/10000, loss = 1.504275 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:06:27 INFO: Finished STEP 8880/10000, loss = 1.293003 (0.406 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:06:37 INFO: Finished STEP 8900/10000, loss = 1.630695 (0.372 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:06:37 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:06:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:06:39 INFO: 71.00\t66.36\t68.51\n",
            "2023-05-14 22:06:39 INFO: step 8900: train_loss = 1.832184, dev_score = 0.7100\n",
            "2023-05-14 22:06:50 INFO: Finished STEP 8920/10000, loss = 1.235118 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:07:00 INFO: Finished STEP 8940/10000, loss = 1.090377 (0.402 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:07:10 INFO: Finished STEP 8960/10000, loss = 1.907161 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:07:21 INFO: Finished STEP 8980/10000, loss = 2.146331 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:07:32 INFO: Finished STEP 9000/10000, loss = 1.460322 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:07:32 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:07:33 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:07:33 INFO: 71.12\t66.71\t68.72\n",
            "2023-05-14 22:07:33 INFO: step 9000: train_loss = 1.886809, dev_score = 0.7112\n",
            "2023-05-14 22:07:44 INFO: Finished STEP 9020/10000, loss = 2.417269 (0.390 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:07:54 INFO: Finished STEP 9040/10000, loss = 0.917226 (0.424 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:08:04 INFO: Finished STEP 9060/10000, loss = 1.341789 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:08:15 INFO: Finished STEP 9080/10000, loss = 1.486344 (0.361 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:08:26 INFO: Finished STEP 9100/10000, loss = 1.367226 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:08:26 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:08:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:08:28 INFO: 71.45\t67.08\t69.13\n",
            "2023-05-14 22:08:28 INFO: step 9100: train_loss = 1.816465, dev_score = 0.7145\n",
            "2023-05-14 22:08:38 INFO: Finished STEP 9120/10000, loss = 1.090799 (0.404 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:08:48 INFO: Finished STEP 9140/10000, loss = 8.625459 (0.396 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:08:59 INFO: Finished STEP 9160/10000, loss = 1.877497 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:09:10 INFO: Finished STEP 9180/10000, loss = 1.630733 (0.371 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:09:20 INFO: Finished STEP 9200/10000, loss = 0.851729 (0.430 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:09:20 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:09:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:09:22 INFO: 71.10\t66.66\t68.54\n",
            "2023-05-14 22:09:22 INFO: step 9200: train_loss = 1.812993, dev_score = 0.7110\n",
            "2023-05-14 22:09:33 INFO: Finished STEP 9220/10000, loss = 0.872906 (0.435 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:09:43 INFO: Finished STEP 9240/10000, loss = 1.064051 (0.399 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:09:53 INFO: Finished STEP 9260/10000, loss = 1.171322 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:10:04 INFO: Finished STEP 9280/10000, loss = 1.099941 (0.395 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:10:14 INFO: Finished STEP 9300/10000, loss = 1.031068 (0.417 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:10:14 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:10:17 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:10:17 INFO: 71.07\t66.50\t68.60\n",
            "2023-05-14 22:10:17 INFO: step 9300: train_loss = 1.863947, dev_score = 0.7107\n",
            "2023-05-14 22:10:27 INFO: Finished STEP 9320/10000, loss = 1.498874 (0.389 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:10:37 INFO: Finished STEP 9340/10000, loss = 1.888036 (0.378 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:10:48 INFO: Finished STEP 9360/10000, loss = 1.429189 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:10:58 INFO: Finished STEP 9380/10000, loss = 1.759346 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:11:09 INFO: Finished STEP 9400/10000, loss = 1.684839 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:11:09 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:11:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:11:11 INFO: 70.97\t66.42\t68.40\n",
            "2023-05-14 22:11:11 INFO: step 9400: train_loss = 1.806043, dev_score = 0.7097\n",
            "2023-05-14 22:11:21 INFO: Finished STEP 9420/10000, loss = 1.137771 (0.393 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:11:31 INFO: Finished STEP 9440/10000, loss = 1.717635 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:11:42 INFO: Finished STEP 9460/10000, loss = 1.942544 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:11:53 INFO: Finished STEP 9480/10000, loss = 1.280075 (0.386 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:12:03 INFO: Finished STEP 9500/10000, loss = 0.884341 (0.437 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:12:03 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:12:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:12:06 INFO: 71.18\t66.46\t68.65\n",
            "2023-05-14 22:12:06 INFO: step 9500: train_loss = 1.808482, dev_score = 0.7118\n",
            "2023-05-14 22:12:16 INFO: Finished STEP 9520/10000, loss = 1.273954 (0.415 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:12:26 INFO: Finished STEP 9540/10000, loss = 1.404609 (0.381 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:12:37 INFO: Finished STEP 9560/10000, loss = 1.108110 (0.400 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:12:47 INFO: Finished STEP 9580/10000, loss = 1.659324 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:12:57 INFO: Finished STEP 9600/10000, loss = 2.395026 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:12:57 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:13:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:13:00 INFO: 71.06\t66.56\t68.53\n",
            "2023-05-14 22:13:00 INFO: step 9600: train_loss = 1.814815, dev_score = 0.7106\n",
            "2023-05-14 22:13:10 INFO: Finished STEP 9620/10000, loss = 1.606829 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:13:21 INFO: Finished STEP 9640/10000, loss = 0.586996 (0.271 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:13:31 INFO: Finished STEP 9660/10000, loss = 1.540367 (0.369 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:13:42 INFO: Finished STEP 9680/10000, loss = 1.959764 (0.384 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:13:52 INFO: Finished STEP 9700/10000, loss = 0.787037 (0.292 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:13:52 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:13:55 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:13:55 INFO: 71.36\t66.92\t68.89\n",
            "2023-05-14 22:13:55 INFO: step 9700: train_loss = 1.878297, dev_score = 0.7136\n",
            "2023-05-14 22:14:06 INFO: Finished STEP 9720/10000, loss = 1.714458 (0.383 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:14:16 INFO: Finished STEP 9740/10000, loss = 1.306792 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:14:27 INFO: Finished STEP 9760/10000, loss = 1.438897 (0.385 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:14:37 INFO: Finished STEP 9780/10000, loss = 1.772825 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:14:47 INFO: Finished STEP 9800/10000, loss = 0.686095 (0.286 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:14:47 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:14:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:14:51 INFO: 71.06\t66.46\t68.45\n",
            "2023-05-14 22:14:51 INFO: step 9800: train_loss = 1.762389, dev_score = 0.7106\n",
            "2023-05-14 22:15:01 INFO: Finished STEP 9820/10000, loss = 2.095508 (0.375 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:15:11 INFO: Finished STEP 9840/10000, loss = 1.076583 (0.392 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:15:22 INFO: Finished STEP 9860/10000, loss = 1.234946 (0.401 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:15:33 INFO: Finished STEP 9880/10000, loss = 1.757650 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:15:43 INFO: Finished STEP 9900/10000, loss = 1.622362 (0.376 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:15:43 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:15:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:15:46 INFO: 71.14\t66.66\t68.69\n",
            "2023-05-14 22:15:46 INFO: step 9900: train_loss = 1.796586, dev_score = 0.7114\n",
            "2023-05-14 22:15:56 INFO: Finished STEP 9920/10000, loss = 0.804210 (0.440 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:16:06 INFO: Finished STEP 9940/10000, loss = 1.678633 (0.379 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:16:17 INFO: Finished STEP 9960/10000, loss = 1.650061 (0.373 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:16:27 INFO: Finished STEP 9980/10000, loss = 1.752096 (0.380 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:16:37 INFO: Finished STEP 10000/10000, loss = 1.639349 (0.382 sec/batch), lr: 0.003000\n",
            "2023-05-14 22:16:37 INFO: Evaluating on dev set...\n",
            "2023-05-14 22:16:40 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:16:40 INFO: 71.40\t66.71\t68.87\n",
            "2023-05-14 22:16:40 INFO: step 10000: train_loss = 1.867568, dev_score = 0.7140\n",
            "2023-05-14 22:16:40 INFO: Training ended with 10000 steps.\n",
            "2023-05-14 22:16:40 INFO: Best dev F1 = 71.48, at iteration = 8400\n",
            "2023-05-14 22:16:41 INFO: Using default pretrain for tr:boun, found in /root/stanza_resources/tr/pretrain/boun.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-05-14 22:16:41 INFO: Running dev depparse for UD_Turkish-BOUN with args ['--wordvec_dir', 'extern_data/wordvec', '--eval_file', 'data/depparse/tr_boun.dev.in.conllu', '--output_file', '/tmp/tmp3w_wxwok', '--gold_file', 'data/depparse/tr_boun.dev.gold.conllu', '--lang', 'tr', '--shorthand', 'tr_boun', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/tr/pretrain/boun.pt', '--max_steps', '10000', '--cuda', '--save_dir', './output_stanza_tr', '--save_name', 'tr_boun_parser.pt']\n",
            "2023-05-14 22:16:41 INFO: Running parser in predict mode\n",
            "2023-05-14 22:16:41 INFO: Loading model from: ./output_stanza_tr/tr_boun_parser.pt\n",
            "2023-05-14 22:16:41 DEBUG: Loaded pretrain from /root/stanza_resources/tr/pretrain/boun.pt\n",
            "2023-05-14 22:16:41 INFO: Loading data with batch size 5000...\n",
            "2023-05-14 22:16:41 DEBUG: 3 batches created.\n",
            "2023-05-14 22:16:41 INFO: Start evaluation...\n",
            "2023-05-14 22:16:43 INFO: F1 scores for each dependency:\n",
            "  Note that unlabeled attachment errors hurt the labeled attachment scores\n",
            "           acl: p 0.7069 r 0.7214 f1 0.7141 (341 actual)\n",
            "         advcl: p 0.5599 r 0.6505 f1 0.6018 (309 actual)\n",
            "        advmod: p 0.6472 r 0.6698 f1 0.6583 (430 actual)\n",
            "   advmod:emph: p 0.8870 r 0.8771 f1 0.8820 (179 actual)\n",
            "          amod: p 0.7241 r 0.6917 f1 0.7075 (759 actual)\n",
            "         appos: p 0.6000 r 0.1765 f1 0.2727 (34 actual)\n",
            "           aux: p 0.2969 r 0.7308 f1 0.4222 (26 actual)\n",
            "          case: p 0.8450 r 0.8044 f1 0.8242 (271 actual)\n",
            "            cc: p 0.7261 r 0.7403 f1 0.7331 (308 actual)\n",
            "    cc:preconj: p 0.4091 r 0.5000 f1 0.4500 (18 actual)\n",
            "         ccomp: p 0.5942 r 0.7069 f1 0.6457 (174 actual)\n",
            "           clf: p 0.0000 r 0.0000 f1 0.0000 (13 actual)\n",
            "      compound: p 0.5164 r 0.3198 f1 0.3950 (197 actual)\n",
            "  compound:lvc: p 0.7778 r 0.8296 f1 0.8029 (135 actual)\n",
            "compound:redup: p 0.4667 r 0.2059 f1 0.2857 (34 actual)\n",
            "          conj: p 0.5900 r 0.5283 f1 0.5574 (689 actual)\n",
            "           cop: p 0.9307 r 0.8206 f1 0.8722 (262 actual)\n",
            "         csubj: p 0.4889 r 0.5116 f1 0.5000 (43 actual)\n",
            "           dep: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "       dep:der: p 0.8462 r 0.9167 f1 0.8800 (36 actual)\n",
            "           det: p 0.8743 r 0.9213 f1 0.8972 (483 actual)\n",
            "     discourse: p 0.3061 r 0.3571 f1 0.3297 (42 actual)\n",
            "   discourse:q: p 0.8621 r 0.9259 f1 0.8929 (27 actual)\n",
            "    dislocated: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n",
            "         fixed: p 0.5714 r 0.3077 f1 0.4000 (13 actual)\n",
            "          flat: p 0.7771 r 0.7861 f1 0.7816 (173 actual)\n",
            "          iobj: p 0.0000 r 0.0000 f1 0.0000 (20 actual)\n",
            "          list: p 0.3333 r 0.5000 f1 0.4000 (2 actual)\n",
            "          mark: p 0.3125 r 0.5556 f1 0.4000 (9 actual)\n",
            "          nmod: p 0.0636 r 0.0593 f1 0.0614 (118 actual)\n",
            "     nmod:part: p 0.0000 r 0.0000 f1 0.0000 (0 actual)\n",
            "     nmod:poss: p 0.8047 r 0.8161 f1 0.8104 (1055 actual)\n",
            "         nsubj: p 0.6092 r 0.6342 f1 0.6215 (831 actual)\n",
            "   nsubj:outer: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "        nummod: p 0.8092 r 0.8601 f1 0.8339 (143 actual)\n",
            "           obj: p 0.6975 r 0.6715 f1 0.6843 (752 actual)\n",
            "           obl: p 0.6435 r 0.6719 f1 0.6574 (1268 actual)\n",
            "      obl:tmod: p 0.0833 r 0.0909 f1 0.0870 (11 actual)\n",
            "        orphan: p 0.0000 r 0.0000 f1 0.0000 (5 actual)\n",
            "     parataxis: p 0.3333 r 0.2727 f1 0.3000 (22 actual)\n",
            "         punct: p 0.7482 r 0.7489 f1 0.7485 (2039 actual)\n",
            "          root: p 0.8509 r 0.8509 f1 0.8509 (979 actual)\n",
            "      vocative: p 0.2000 r 0.3000 f1 0.2400 (10 actual)\n",
            "         xcomp: p 0.6000 r 0.7826 f1 0.6792 (23 actual)\n",
            "2023-05-14 22:16:44 INFO: LAS\tMLAS\tBLEX\n",
            "2023-05-14 22:16:44 INFO: 71.48\t66.93\t69.09\n",
            "2023-05-14 22:16:44 INFO: Parser score:\n",
            "2023-05-14 22:16:44 INFO: tr_boun 71.48\n",
            "2023-05-14 22:16:45 INFO: Finished running dev set on\n",
            "UD_Turkish-BOUN\n",
            "  UAS   LAS  CLAS  MLAS  BLEX\n",
            "78.35 71.48 69.09 66.93 69.09\n",
            "5498.5102388858795\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "!python3 -m stanza.utils.training.run_depparse --train UD_Turkish-BOUN --save_dir ./output_stanza_tr --max_steps 10000 --cuda\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "065f0aa230124936a200540fb3db9dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b794350fab52426dbf237c34f3c73c35",
            "placeholder": "​",
            "style": "IPY_MODEL_a4355184cd314916a38032d317bfe747",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-tr/resolve/v1.5.0/models/default.zip: 100%"
          }
        },
        "1207be12c24846e0911e39bd70f67d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18b5952091a84edab95e3245a9c9fd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab7949216f94ec19b9b709ad9905ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f6afb609f348ee8388cd1c6203284b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f3f24e68b44f08b7ab42a557ca981d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5202fef1902e4d6b8fe827dad5063700": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b5952091a84edab95e3245a9c9fd7c",
            "placeholder": "​",
            "style": "IPY_MODEL_634d3f9b2a1d44b78eb51de637b1010d",
            "value": " 440M/440M [00:26&lt;00:00, 18.1MB/s]"
          }
        },
        "602531fb53ec4904a559f93c968848a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_989e7c16f9834aa2ad6e602d2b068799",
              "IPY_MODEL_fbf96632060c4e8a83945556b9649051",
              "IPY_MODEL_ea28a235f4fe4b32afbc044d7b699c68"
            ],
            "layout": "IPY_MODEL_1ab7949216f94ec19b9b709ad9905ecb"
          }
        },
        "634d3f9b2a1d44b78eb51de637b1010d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b25204023a542a2890fd3a21dc29b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_065f0aa230124936a200540fb3db9dd0",
              "IPY_MODEL_785a37bfe75e4027b0fc7c5c926c9014",
              "IPY_MODEL_5202fef1902e4d6b8fe827dad5063700"
            ],
            "layout": "IPY_MODEL_49f3f24e68b44f08b7ab42a557ca981d"
          }
        },
        "785a37bfe75e4027b0fc7c5c926c9014": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74f9f96ee3346d8931bad9619e41cb2",
            "max": 439509888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d00c5b8cbacc4d6dabc21179470a2092",
            "value": 439509888
          }
        },
        "7c25c66eac8e48c897d72e2b736f969d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989e7c16f9834aa2ad6e602d2b068799": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f6afb609f348ee8388cd1c6203284b",
            "placeholder": "​",
            "style": "IPY_MODEL_9e02dd9ed90847c58d486732a1061a81",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
          }
        },
        "9e02dd9ed90847c58d486732a1061a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4355184cd314916a38032d317bfe747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b794350fab52426dbf237c34f3c73c35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2acfc7550f448ce886089ba3c10875c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd0b3d913d648bf9f03cb1d1139ca4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d00c5b8cbacc4d6dabc21179470a2092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea28a235f4fe4b32afbc044d7b699c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c25c66eac8e48c897d72e2b736f969d",
            "placeholder": "​",
            "style": "IPY_MODEL_ccd0b3d913d648bf9f03cb1d1139ca4e",
            "value": " 216k/? [00:00&lt;00:00, 5.04MB/s]"
          }
        },
        "f74f9f96ee3346d8931bad9619e41cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf96632060c4e8a83945556b9649051": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2acfc7550f448ce886089ba3c10875c",
            "max": 30022,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1207be12c24846e0911e39bd70f67d56",
            "value": 30022
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
